{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07324f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define data path\n",
    "DATA_PATH = \"data/\"\n",
    "CHECKPOINT_PATH = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1156a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = pickle.load(open(os.path.join(DATA_PATH,'pids.pkl'), 'rb'))\n",
    "vids = pickle.load(open(os.path.join(DATA_PATH,'vids.pkl'), 'rb'))\n",
    "targets = pickle.load(open(os.path.join(DATA_PATH,'targets.pkl'), 'rb'))\n",
    "prob_targets = pickle.load(open(os.path.join(DATA_PATH,'prob_targets.pkl'), 'rb'))\n",
    "prob_targets_allvisits = pickle.load(open(os.path.join(DATA_PATH,'prob_targets_allvisits.pkl'), 'rb'))\n",
    "seqs = pickle.load(open(os.path.join(DATA_PATH,'seqs.pkl'), 'rb'))\n",
    "diags = pickle.load(open(os.path.join(DATA_PATH,'diags.pkl'), 'rb'))\n",
    "categories = pickle.load(open(os.path.join(DATA_PATH,'categories.pkl'), 'rb'))\n",
    "sub_categories = pickle.load(open(os.path.join(DATA_PATH,'subcategories.pkl'), 'rb'))\n",
    "codes = pickle.load(open(os.path.join(DATA_PATH,'icd9.pkl'), 'rb'))\n",
    "assert len(pids) == len(vids) == len(targets) == len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4bc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, targets):\n",
    "        self.x = seqs\n",
    "        self.y = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.x))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206aa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(seqs, prob_targets_allvisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b5cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# total visits excluding last visit per patient, max # diagnosis codes)\n",
    "            of type torch.long\n",
    "        x_masks: a tensor of shape (# total visits excluding last visit per patient, max # diagnosis codes)\n",
    "            of type torch.bool\n",
    "        y: a tensor of shape (# total visits excluding first visit per patient, num higher level categories\n",
    "            to predict) of type torch.float\n",
    "    \"\"\"\n",
    "    sequences, targets = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "    num_categories = len(targets[0][0])\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    sum_visits = sum(num_visits)\n",
    "    \n",
    "    x = torch.zeros((sum_visits - num_patients, max_num_codes), dtype=torch.int)\n",
    "    y = torch.zeros((sum_visits - num_patients, num_categories), dtype=torch.float32)\n",
    "    x_masks = torch.zeros((sum_visits - num_patients, max_num_codes), dtype=torch.bool)\n",
    "\n",
    "    n = 0\n",
    "    for i,patient in enumerate(sequences):\n",
    "        for j,visit in enumerate(patient):\n",
    "            if j == len(patient) - 1:\n",
    "                break\n",
    "            for k,code in enumerate(visit):\n",
    "                x[n,k] = code\n",
    "                x_masks[n,k] = 1\n",
    "            n+=1\n",
    "    n = 0\n",
    "    for i,patient in enumerate(targets):\n",
    "        for j,visit in enumerate(patient):\n",
    "            if j == len(patient) - 1:\n",
    "                break\n",
    "            y[n] = torch.tensor(patient[j+1])\n",
    "            n += 1\n",
    "    \n",
    "    return x, x_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7834769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(len(dataset)*0.75)\n",
    "test_split = int(len(dataset)*0.15)\n",
    "val_split = int(len(dataset)*0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e400730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6561\n",
      "Length of test dataset: 1312\n",
      "Length of val dataset: 875\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_split = int(len(dataset)*0.75)\n",
    "test_split = int(len(dataset)*0.15)\n",
    "\n",
    "lengths = [train_split, test_split, len(dataset) - (train_split + test_split)]\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of test dataset:\", len(test_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e1a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dataset, test_dataset, val_dataset, collate_fn):\n",
    "    '''\n",
    "    Arguments:\n",
    "        train_dataset: train dataset of type `CustomDataset`\n",
    "        test_dataset: train dataset of type `CustomDataset`\n",
    "        val_dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, test_loader, val_loader: train and validation dataloaders\n",
    "    '''\n",
    "    \n",
    "    batch_size = 100\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               collate_fn=collate_fn,\n",
    "                                               shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             collate_fn=collate_fn,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader, val_loader = load_data(train_dataset, test_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d1d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_multihot(indices, masks, dim):\n",
    "    multihot = torch.zeros((indices.shape[0], dim), dtype=torch.int)\n",
    "    for idx, row in enumerate(indices):\n",
    "        y_idx = row[masks[idx]].unique()\n",
    "        multihot[idx] = F.one_hot(y_idx.to(torch.int64), multihot.shape[1]).sum(0)\n",
    "    return multihot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "637c36f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineMLP(\n",
       "  (embedding): Embedding(4903, 180, padding_idx=0)\n",
       "  (fc): Linear(in_features=180, out_features=184, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BaselineMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, num_categories):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            num_codes: total number of diagnosis codes\n",
    "            num_categories: number of higher level categories to predict\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(num_codes, embedding_dim=180, padding_idx=0)\n",
    "        self.fc = nn.Linear(180, num_categories)\n",
    "        \n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: the diagnosis sequence of shape (batch_size, # visits, # diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "        Outputs:\n",
    "            logits: probabilities of shape (batch_size)\n",
    "        \"\"\"\n",
    "        x[masks] += 1  # Increment values by 1 to make use of padding_idx == 0\n",
    "        x = self.embedding(x)\n",
    "        x = x.sum(dim=1)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "baseline_mlp = BaselineMLP(num_codes = len(codes), num_categories=len(sub_categories))\n",
    "baseline_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375a279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(baseline_mlp.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adadelta(baseline_mlp.parameters(), weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, k=15, n=-1):  \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model: the BaselineMLP model\n",
    "        test_loader: validation dataloader\n",
    "        k: value for top k predictions\n",
    "        n: num of records to evaluate in the batch, value -1 evaulates all records\n",
    "        \n",
    "    Outputs:\n",
    "        precision_k: visit-level precison@k\n",
    "        accuracy_k: code-level accuracy@k\n",
    "    \"\"\"\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    all_precision = []\n",
    "    all_accuracy = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, masks, y in test_loader:\n",
    "            n_eval = y.shape[0] - 1 if n == -1 else n\n",
    "            y_hat = model(x, masks)\n",
    "            y_hat = F.softmax(y_hat, dim=-1)\n",
    "            nz_rows, nz_cols = torch.nonzero(y, as_tuple=True)\n",
    "            k_correct = 0\n",
    "            total_precision = 0\n",
    "            total_accuracy = 0\n",
    "            for i in range(n_eval):\n",
    "                visit_correct = 0\n",
    "                y_true = nz_cols[nz_rows == i]\n",
    "                _, y_pred = torch.topk(y_hat[i], k)\n",
    "\n",
    "                for v in y_true:\n",
    "                    if v in y_pred:\n",
    "                        visit_correct += 1\n",
    "                        \n",
    "                visit_precision = visit_correct / min(k, len(y_true))\n",
    "                visit_accuracy = visit_correct / len(y_true)\n",
    "                k_correct += visit_correct\n",
    "                total_precision += visit_precision\n",
    "                total_accuracy += visit_accuracy\n",
    "\n",
    "            precision_k = total_precision / n_eval\n",
    "            accuracy_k = total_accuracy / n_eval\n",
    "            all_precision.append(precision_k)\n",
    "            all_accuracy.append(accuracy_k)\n",
    "            \n",
    "    total_precision_k = np.mean(all_precision)\n",
    "    total_accuracy_k = np.mean(all_accuracy)\n",
    "    return total_precision_k, total_accuracy_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a85ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model: the BaselineMLP model\n",
    "        train_loader: training dataloader\n",
    "        test_loader: validation dataloader\n",
    "        n_epochs: num epochs to train\n",
    "    \"\"\"\n",
    "    max_cpu, max_ram = print_cpu_usage()\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, y in train_loader:\n",
    "            y_hat = model(x, masks)\n",
    "            loss = criterion(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        cpu, ram = print_cpu_usage()\n",
    "        max_cpu = cpu if cpu > max_cpu else max_cpu\n",
    "        max_ram = ram if ram > max_ram else max_ram\n",
    "        print(f'Epoch: {epoch+1} \\t Training Loss: {train_loss:.6f}')\n",
    "        for k in range(5, 31, 5):\n",
    "            precision_k, accuracy_k = eval_model(model, test_loader, k=k)\n",
    "            print(f'Epoch: {epoch+1} \\t Validation precision@k{k}: {precision_k:.4f}, accuracy@k{k}: {accuracy_k:.4f}')\n",
    "    final_cpu, final_ram = print_cpu_usage()\n",
    "    print(f\"Max CPU usage: {max_cpu:.3f}\\tMax RAM % usage: {max_ram}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3097025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cpu_usage():\n",
    "    load = psutil.getloadavg()[2]\n",
    "    cpu_usage = (load/os.cpu_count()) * 100\n",
    "    ram = psutil.virtual_memory()[2]\n",
    "    print(f\"CPU: {cpu_usage:0.2f}\")\n",
    "    print(f\"RAM %: {ram}\")\n",
    "    return cpu_usage, ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1800d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 19.43\n",
      "RAM %: 57.1\n",
      "CPU: 19.43\n",
      "RAM %: 57.1\n",
      "Epoch: 1 \t Training Loss: 4.667513\n",
      "Epoch: 1 \t Validation precision@k5: 0.5627, accuracy@k5: 0.2918\n",
      "Epoch: 1 \t Validation precision@k10: 0.5338, accuracy@k10: 0.4476\n",
      "Epoch: 1 \t Validation precision@k15: 0.5769, accuracy@k15: 0.5549\n",
      "Epoch: 1 \t Validation precision@k20: 0.6368, accuracy@k20: 0.6330\n",
      "Epoch: 1 \t Validation precision@k25: 0.6990, accuracy@k25: 0.6987\n",
      "Epoch: 1 \t Validation precision@k30: 0.7470, accuracy@k30: 0.7470\n",
      "CPU: 19.43\n",
      "RAM %: 57.1\n",
      "Epoch: 2 \t Training Loss: 3.860909\n",
      "Epoch: 2 \t Validation precision@k5: 0.6123, accuracy@k5: 0.3186\n",
      "Epoch: 2 \t Validation precision@k10: 0.5756, accuracy@k10: 0.4848\n",
      "Epoch: 2 \t Validation precision@k15: 0.6197, accuracy@k15: 0.5966\n",
      "Epoch: 2 \t Validation precision@k20: 0.6815, accuracy@k20: 0.6774\n",
      "Epoch: 2 \t Validation precision@k25: 0.7380, accuracy@k25: 0.7377\n",
      "Epoch: 2 \t Validation precision@k30: 0.7824, accuracy@k30: 0.7824\n",
      "CPU: 19.64\n",
      "RAM %: 56.7\n",
      "Epoch: 3 \t Training Loss: 3.749623\n",
      "Epoch: 3 \t Validation precision@k5: 0.6244, accuracy@k5: 0.3264\n",
      "Epoch: 3 \t Validation precision@k10: 0.5908, accuracy@k10: 0.4979\n",
      "Epoch: 3 \t Validation precision@k15: 0.6318, accuracy@k15: 0.6083\n",
      "Epoch: 3 \t Validation precision@k20: 0.6915, accuracy@k20: 0.6874\n",
      "Epoch: 3 \t Validation precision@k25: 0.7475, accuracy@k25: 0.7472\n",
      "Epoch: 3 \t Validation precision@k30: 0.7936, accuracy@k30: 0.7936\n",
      "CPU: 19.78\n",
      "RAM %: 56.8\n",
      "Epoch: 4 \t Training Loss: 3.711073\n",
      "Epoch: 4 \t Validation precision@k5: 0.6381, accuracy@k5: 0.3342\n",
      "Epoch: 4 \t Validation precision@k10: 0.5943, accuracy@k10: 0.4992\n",
      "Epoch: 4 \t Validation precision@k15: 0.6399, accuracy@k15: 0.6157\n",
      "Epoch: 4 \t Validation precision@k20: 0.6996, accuracy@k20: 0.6954\n",
      "Epoch: 4 \t Validation precision@k25: 0.7542, accuracy@k25: 0.7539\n",
      "Epoch: 4 \t Validation precision@k30: 0.8000, accuracy@k30: 0.8000\n",
      "CPU: 20.00\n",
      "RAM %: 56.7\n",
      "Epoch: 5 \t Training Loss: 3.683914\n",
      "Epoch: 5 \t Validation precision@k5: 0.6428, accuracy@k5: 0.3356\n",
      "Epoch: 5 \t Validation precision@k10: 0.6018, accuracy@k10: 0.5070\n",
      "Epoch: 5 \t Validation precision@k15: 0.6421, accuracy@k15: 0.6182\n",
      "Epoch: 5 \t Validation precision@k20: 0.7047, accuracy@k20: 0.7006\n",
      "Epoch: 5 \t Validation precision@k25: 0.7574, accuracy@k25: 0.7571\n",
      "Epoch: 5 \t Validation precision@k30: 0.8024, accuracy@k30: 0.8024\n",
      "CPU: 20.06\n",
      "RAM %: 57.0\n",
      "Epoch: 6 \t Training Loss: 3.666553\n",
      "Epoch: 6 \t Validation precision@k5: 0.6446, accuracy@k5: 0.3364\n",
      "Epoch: 6 \t Validation precision@k10: 0.6098, accuracy@k10: 0.5130\n",
      "Epoch: 6 \t Validation precision@k15: 0.6476, accuracy@k15: 0.6237\n",
      "Epoch: 6 \t Validation precision@k20: 0.7066, accuracy@k20: 0.7025\n",
      "Epoch: 6 \t Validation precision@k25: 0.7618, accuracy@k25: 0.7615\n",
      "Epoch: 6 \t Validation precision@k30: 0.8085, accuracy@k30: 0.8085\n",
      "CPU: 20.09\n",
      "RAM %: 57.0\n",
      "Epoch: 7 \t Training Loss: 3.649440\n",
      "Epoch: 7 \t Validation precision@k5: 0.6512, accuracy@k5: 0.3405\n",
      "Epoch: 7 \t Validation precision@k10: 0.6068, accuracy@k10: 0.5116\n",
      "Epoch: 7 \t Validation precision@k15: 0.6489, accuracy@k15: 0.6247\n",
      "Epoch: 7 \t Validation precision@k20: 0.7095, accuracy@k20: 0.7052\n",
      "Epoch: 7 \t Validation precision@k25: 0.7653, accuracy@k25: 0.7650\n",
      "Epoch: 7 \t Validation precision@k30: 0.8125, accuracy@k30: 0.8125\n",
      "CPU: 20.11\n",
      "RAM %: 56.8\n",
      "Epoch: 8 \t Training Loss: 3.636912\n",
      "Epoch: 8 \t Validation precision@k5: 0.6498, accuracy@k5: 0.3403\n",
      "Epoch: 8 \t Validation precision@k10: 0.6072, accuracy@k10: 0.5110\n",
      "Epoch: 8 \t Validation precision@k15: 0.6518, accuracy@k15: 0.6276\n",
      "Epoch: 8 \t Validation precision@k20: 0.7111, accuracy@k20: 0.7068\n",
      "Epoch: 8 \t Validation precision@k25: 0.7655, accuracy@k25: 0.7652\n",
      "Epoch: 8 \t Validation precision@k30: 0.8134, accuracy@k30: 0.8134\n",
      "CPU: 20.14\n",
      "RAM %: 56.7\n",
      "Epoch: 9 \t Training Loss: 3.624380\n",
      "Epoch: 9 \t Validation precision@k5: 0.6489, accuracy@k5: 0.3392\n",
      "Epoch: 9 \t Validation precision@k10: 0.6106, accuracy@k10: 0.5147\n",
      "Epoch: 9 \t Validation precision@k15: 0.6552, accuracy@k15: 0.6308\n",
      "Epoch: 9 \t Validation precision@k20: 0.7137, accuracy@k20: 0.7095\n",
      "Epoch: 9 \t Validation precision@k25: 0.7671, accuracy@k25: 0.7668\n",
      "Epoch: 9 \t Validation precision@k30: 0.8131, accuracy@k30: 0.8131\n",
      "CPU: 20.17\n",
      "RAM %: 57.4\n",
      "Epoch: 10 \t Training Loss: 3.614787\n",
      "Epoch: 10 \t Validation precision@k5: 0.6518, accuracy@k5: 0.3411\n",
      "Epoch: 10 \t Validation precision@k10: 0.6113, accuracy@k10: 0.5141\n",
      "Epoch: 10 \t Validation precision@k15: 0.6572, accuracy@k15: 0.6323\n",
      "Epoch: 10 \t Validation precision@k20: 0.7167, accuracy@k20: 0.7124\n",
      "Epoch: 10 \t Validation precision@k25: 0.7738, accuracy@k25: 0.7735\n",
      "Epoch: 10 \t Validation precision@k30: 0.8167, accuracy@k30: 0.8167\n",
      "CPU: 20.20\n",
      "RAM %: 57.6\n",
      "Epoch: 11 \t Training Loss: 3.606021\n",
      "Epoch: 11 \t Validation precision@k5: 0.6536, accuracy@k5: 0.3417\n",
      "Epoch: 11 \t Validation precision@k10: 0.6197, accuracy@k10: 0.5216\n",
      "Epoch: 11 \t Validation precision@k15: 0.6600, accuracy@k15: 0.6356\n",
      "Epoch: 11 \t Validation precision@k20: 0.7173, accuracy@k20: 0.7130\n",
      "Epoch: 11 \t Validation precision@k25: 0.7725, accuracy@k25: 0.7722\n",
      "Epoch: 11 \t Validation precision@k30: 0.8177, accuracy@k30: 0.8177\n",
      "CPU: 20.22\n",
      "RAM %: 57.3\n",
      "Epoch: 12 \t Training Loss: 3.596245\n",
      "Epoch: 12 \t Validation precision@k5: 0.6650, accuracy@k5: 0.3464\n",
      "Epoch: 12 \t Validation precision@k10: 0.6199, accuracy@k10: 0.5220\n",
      "Epoch: 12 \t Validation precision@k15: 0.6625, accuracy@k15: 0.6379\n",
      "Epoch: 12 \t Validation precision@k20: 0.7198, accuracy@k20: 0.7155\n",
      "Epoch: 12 \t Validation precision@k25: 0.7748, accuracy@k25: 0.7746\n",
      "Epoch: 12 \t Validation precision@k30: 0.8195, accuracy@k30: 0.8195\n",
      "CPU: 20.22\n",
      "RAM %: 57.4\n",
      "Epoch: 13 \t Training Loss: 3.588887\n",
      "Epoch: 13 \t Validation precision@k5: 0.6635, accuracy@k5: 0.3465\n",
      "Epoch: 13 \t Validation precision@k10: 0.6187, accuracy@k10: 0.5204\n",
      "Epoch: 13 \t Validation precision@k15: 0.6624, accuracy@k15: 0.6377\n",
      "Epoch: 13 \t Validation precision@k20: 0.7225, accuracy@k20: 0.7182\n",
      "Epoch: 13 \t Validation precision@k25: 0.7764, accuracy@k25: 0.7761\n",
      "Epoch: 13 \t Validation precision@k30: 0.8219, accuracy@k30: 0.8219\n",
      "CPU: 20.29\n",
      "RAM %: 57.4\n",
      "Epoch: 14 \t Training Loss: 3.581962\n",
      "Epoch: 14 \t Validation precision@k5: 0.6596, accuracy@k5: 0.3444\n",
      "Epoch: 14 \t Validation precision@k10: 0.6221, accuracy@k10: 0.5230\n",
      "Epoch: 14 \t Validation precision@k15: 0.6647, accuracy@k15: 0.6396\n",
      "Epoch: 14 \t Validation precision@k20: 0.7237, accuracy@k20: 0.7193\n",
      "Epoch: 14 \t Validation precision@k25: 0.7780, accuracy@k25: 0.7777\n",
      "Epoch: 14 \t Validation precision@k30: 0.8213, accuracy@k30: 0.8213\n",
      "CPU: 20.32\n",
      "RAM %: 57.0\n",
      "Epoch: 15 \t Training Loss: 3.575743\n",
      "Epoch: 15 \t Validation precision@k5: 0.6594, accuracy@k5: 0.3435\n",
      "Epoch: 15 \t Validation precision@k10: 0.6270, accuracy@k10: 0.5273\n",
      "Epoch: 15 \t Validation precision@k15: 0.6662, accuracy@k15: 0.6414\n",
      "Epoch: 15 \t Validation precision@k20: 0.7258, accuracy@k20: 0.7215\n",
      "Epoch: 15 \t Validation precision@k25: 0.7814, accuracy@k25: 0.7811\n",
      "Epoch: 15 \t Validation precision@k30: 0.8233, accuracy@k30: 0.8233\n",
      "CPU: 20.41\n",
      "RAM %: 57.3\n",
      "Epoch: 16 \t Training Loss: 3.569139\n",
      "Epoch: 16 \t Validation precision@k5: 0.6613, accuracy@k5: 0.3457\n",
      "Epoch: 16 \t Validation precision@k10: 0.6269, accuracy@k10: 0.5277\n",
      "Epoch: 16 \t Validation precision@k15: 0.6668, accuracy@k15: 0.6419\n",
      "Epoch: 16 \t Validation precision@k20: 0.7273, accuracy@k20: 0.7230\n",
      "Epoch: 16 \t Validation precision@k25: 0.7819, accuracy@k25: 0.7817\n",
      "Epoch: 16 \t Validation precision@k30: 0.8257, accuracy@k30: 0.8257\n",
      "CPU: 20.44\n",
      "RAM %: 57.1\n",
      "Epoch: 17 \t Training Loss: 3.563350\n",
      "Epoch: 17 \t Validation precision@k5: 0.6684, accuracy@k5: 0.3476\n",
      "Epoch: 17 \t Validation precision@k10: 0.6307, accuracy@k10: 0.5303\n",
      "Epoch: 17 \t Validation precision@k15: 0.6681, accuracy@k15: 0.6429\n",
      "Epoch: 17 \t Validation precision@k20: 0.7277, accuracy@k20: 0.7234\n",
      "Epoch: 17 \t Validation precision@k25: 0.7835, accuracy@k25: 0.7833\n",
      "Epoch: 17 \t Validation precision@k30: 0.8269, accuracy@k30: 0.8269\n",
      "CPU: 20.43\n",
      "RAM %: 57.1\n",
      "Epoch: 18 \t Training Loss: 3.558076\n",
      "Epoch: 18 \t Validation precision@k5: 0.6676, accuracy@k5: 0.3486\n",
      "Epoch: 18 \t Validation precision@k10: 0.6311, accuracy@k10: 0.5303\n",
      "Epoch: 18 \t Validation precision@k15: 0.6691, accuracy@k15: 0.6439\n",
      "Epoch: 18 \t Validation precision@k20: 0.7288, accuracy@k20: 0.7244\n",
      "Epoch: 18 \t Validation precision@k25: 0.7825, accuracy@k25: 0.7822\n",
      "Epoch: 18 \t Validation precision@k30: 0.8271, accuracy@k30: 0.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 20.41\n",
      "RAM %: 57.1\n",
      "Epoch: 19 \t Training Loss: 3.552497\n",
      "Epoch: 19 \t Validation precision@k5: 0.6712, accuracy@k5: 0.3500\n",
      "Epoch: 19 \t Validation precision@k10: 0.6302, accuracy@k10: 0.5296\n",
      "Epoch: 19 \t Validation precision@k15: 0.6694, accuracy@k15: 0.6442\n",
      "Epoch: 19 \t Validation precision@k20: 0.7299, accuracy@k20: 0.7255\n",
      "Epoch: 19 \t Validation precision@k25: 0.7857, accuracy@k25: 0.7855\n",
      "Epoch: 19 \t Validation precision@k30: 0.8285, accuracy@k30: 0.8285\n",
      "CPU: 20.40\n",
      "RAM %: 57.1\n",
      "Epoch: 20 \t Training Loss: 3.547756\n",
      "Epoch: 20 \t Validation precision@k5: 0.6737, accuracy@k5: 0.3508\n",
      "Epoch: 20 \t Validation precision@k10: 0.6346, accuracy@k10: 0.5336\n",
      "Epoch: 20 \t Validation precision@k15: 0.6718, accuracy@k15: 0.6467\n",
      "Epoch: 20 \t Validation precision@k20: 0.7325, accuracy@k20: 0.7281\n",
      "Epoch: 20 \t Validation precision@k25: 0.7874, accuracy@k25: 0.7871\n",
      "Epoch: 20 \t Validation precision@k30: 0.8284, accuracy@k30: 0.8284\n",
      "CPU: 20.39\n",
      "RAM %: 56.7\n",
      "Epoch: 21 \t Training Loss: 3.543455\n",
      "Epoch: 21 \t Validation precision@k5: 0.6755, accuracy@k5: 0.3519\n",
      "Epoch: 21 \t Validation precision@k10: 0.6318, accuracy@k10: 0.5316\n",
      "Epoch: 21 \t Validation precision@k15: 0.6731, accuracy@k15: 0.6479\n",
      "Epoch: 21 \t Validation precision@k20: 0.7305, accuracy@k20: 0.7261\n",
      "Epoch: 21 \t Validation precision@k25: 0.7868, accuracy@k25: 0.7865\n",
      "Epoch: 21 \t Validation precision@k30: 0.8307, accuracy@k30: 0.8307\n",
      "CPU: 20.38\n",
      "RAM %: 56.7\n",
      "Epoch: 22 \t Training Loss: 3.538512\n",
      "Epoch: 22 \t Validation precision@k5: 0.6742, accuracy@k5: 0.3507\n",
      "Epoch: 22 \t Validation precision@k10: 0.6370, accuracy@k10: 0.5351\n",
      "Epoch: 22 \t Validation precision@k15: 0.6780, accuracy@k15: 0.6525\n",
      "Epoch: 22 \t Validation precision@k20: 0.7358, accuracy@k20: 0.7314\n",
      "Epoch: 22 \t Validation precision@k25: 0.7889, accuracy@k25: 0.7886\n",
      "Epoch: 22 \t Validation precision@k30: 0.8310, accuracy@k30: 0.8310\n",
      "CPU: 20.38\n",
      "RAM %: 56.7\n",
      "Epoch: 23 \t Training Loss: 3.535122\n",
      "Epoch: 23 \t Validation precision@k5: 0.6734, accuracy@k5: 0.3501\n",
      "Epoch: 23 \t Validation precision@k10: 0.6320, accuracy@k10: 0.5313\n",
      "Epoch: 23 \t Validation precision@k15: 0.6762, accuracy@k15: 0.6507\n",
      "Epoch: 23 \t Validation precision@k20: 0.7381, accuracy@k20: 0.7336\n",
      "Epoch: 23 \t Validation precision@k25: 0.7891, accuracy@k25: 0.7888\n",
      "Epoch: 23 \t Validation precision@k30: 0.8315, accuracy@k30: 0.8315\n",
      "CPU: 20.36\n",
      "RAM %: 56.6\n",
      "Epoch: 24 \t Training Loss: 3.531055\n",
      "Epoch: 24 \t Validation precision@k5: 0.6768, accuracy@k5: 0.3512\n",
      "Epoch: 24 \t Validation precision@k10: 0.6367, accuracy@k10: 0.5352\n",
      "Epoch: 24 \t Validation precision@k15: 0.6794, accuracy@k15: 0.6538\n",
      "Epoch: 24 \t Validation precision@k20: 0.7371, accuracy@k20: 0.7327\n",
      "Epoch: 24 \t Validation precision@k25: 0.7884, accuracy@k25: 0.7881\n",
      "Epoch: 24 \t Validation precision@k30: 0.8324, accuracy@k30: 0.8324\n",
      "CPU: 20.43\n",
      "RAM %: 56.7\n",
      "Epoch: 25 \t Training Loss: 3.525432\n",
      "Epoch: 25 \t Validation precision@k5: 0.6806, accuracy@k5: 0.3541\n",
      "Epoch: 25 \t Validation precision@k10: 0.6409, accuracy@k10: 0.5383\n",
      "Epoch: 25 \t Validation precision@k15: 0.6774, accuracy@k15: 0.6519\n",
      "Epoch: 25 \t Validation precision@k20: 0.7385, accuracy@k20: 0.7340\n",
      "Epoch: 25 \t Validation precision@k25: 0.7906, accuracy@k25: 0.7903\n",
      "Epoch: 25 \t Validation precision@k30: 0.8333, accuracy@k30: 0.8333\n",
      "CPU: 20.38\n",
      "RAM %: 57.0\n",
      "Epoch: 26 \t Training Loss: 3.522825\n",
      "Epoch: 26 \t Validation precision@k5: 0.6790, accuracy@k5: 0.3526\n",
      "Epoch: 26 \t Validation precision@k10: 0.6419, accuracy@k10: 0.5397\n",
      "Epoch: 26 \t Validation precision@k15: 0.6812, accuracy@k15: 0.6554\n",
      "Epoch: 26 \t Validation precision@k20: 0.7378, accuracy@k20: 0.7333\n",
      "Epoch: 26 \t Validation precision@k25: 0.7917, accuracy@k25: 0.7915\n",
      "Epoch: 26 \t Validation precision@k30: 0.8338, accuracy@k30: 0.8338\n",
      "CPU: 20.36\n",
      "RAM %: 56.9\n",
      "Epoch: 27 \t Training Loss: 3.518546\n",
      "Epoch: 27 \t Validation precision@k5: 0.6799, accuracy@k5: 0.3541\n",
      "Epoch: 27 \t Validation precision@k10: 0.6440, accuracy@k10: 0.5410\n",
      "Epoch: 27 \t Validation precision@k15: 0.6830, accuracy@k15: 0.6572\n",
      "Epoch: 27 \t Validation precision@k20: 0.7411, accuracy@k20: 0.7367\n",
      "Epoch: 27 \t Validation precision@k25: 0.7914, accuracy@k25: 0.7912\n",
      "Epoch: 27 \t Validation precision@k30: 0.8354, accuracy@k30: 0.8354\n",
      "CPU: 20.35\n",
      "RAM %: 57.2\n",
      "Epoch: 28 \t Training Loss: 3.516066\n",
      "Epoch: 28 \t Validation precision@k5: 0.6866, accuracy@k5: 0.3574\n",
      "Epoch: 28 \t Validation precision@k10: 0.6459, accuracy@k10: 0.5429\n",
      "Epoch: 28 \t Validation precision@k15: 0.6825, accuracy@k15: 0.6566\n",
      "Epoch: 28 \t Validation precision@k20: 0.7419, accuracy@k20: 0.7373\n",
      "Epoch: 28 \t Validation precision@k25: 0.7899, accuracy@k25: 0.7897\n",
      "Epoch: 28 \t Validation precision@k30: 0.8359, accuracy@k30: 0.8359\n",
      "CPU: 20.38\n",
      "RAM %: 57.3\n",
      "Epoch: 29 \t Training Loss: 3.513486\n",
      "Epoch: 29 \t Validation precision@k5: 0.6823, accuracy@k5: 0.3552\n",
      "Epoch: 29 \t Validation precision@k10: 0.6449, accuracy@k10: 0.5417\n",
      "Epoch: 29 \t Validation precision@k15: 0.6842, accuracy@k15: 0.6582\n",
      "Epoch: 29 \t Validation precision@k20: 0.7419, accuracy@k20: 0.7374\n",
      "Epoch: 29 \t Validation precision@k25: 0.7917, accuracy@k25: 0.7914\n",
      "Epoch: 29 \t Validation precision@k30: 0.8353, accuracy@k30: 0.8353\n",
      "CPU: 20.58\n",
      "RAM %: 57.3\n",
      "Epoch: 30 \t Training Loss: 3.512366\n",
      "Epoch: 30 \t Validation precision@k5: 0.6821, accuracy@k5: 0.3543\n",
      "Epoch: 30 \t Validation precision@k10: 0.6489, accuracy@k10: 0.5457\n",
      "Epoch: 30 \t Validation precision@k15: 0.6848, accuracy@k15: 0.6587\n",
      "Epoch: 30 \t Validation precision@k20: 0.7417, accuracy@k20: 0.7373\n",
      "Epoch: 30 \t Validation precision@k25: 0.7934, accuracy@k25: 0.7931\n",
      "Epoch: 30 \t Validation precision@k30: 0.8366, accuracy@k30: 0.8366\n",
      "CPU: 20.57\n",
      "RAM %: 57.3\n",
      "Epoch: 31 \t Training Loss: 3.509313\n",
      "Epoch: 31 \t Validation precision@k5: 0.6857, accuracy@k5: 0.3561\n",
      "Epoch: 31 \t Validation precision@k10: 0.6496, accuracy@k10: 0.5455\n",
      "Epoch: 31 \t Validation precision@k15: 0.6858, accuracy@k15: 0.6597\n",
      "Epoch: 31 \t Validation precision@k20: 0.7421, accuracy@k20: 0.7376\n",
      "Epoch: 31 \t Validation precision@k25: 0.7939, accuracy@k25: 0.7936\n",
      "Epoch: 31 \t Validation precision@k30: 0.8352, accuracy@k30: 0.8352\n",
      "CPU: 20.56\n",
      "RAM %: 57.2\n",
      "Epoch: 32 \t Training Loss: 3.506492\n",
      "Epoch: 32 \t Validation precision@k5: 0.6888, accuracy@k5: 0.3583\n",
      "Epoch: 32 \t Validation precision@k10: 0.6502, accuracy@k10: 0.5460\n",
      "Epoch: 32 \t Validation precision@k15: 0.6873, accuracy@k15: 0.6611\n",
      "Epoch: 32 \t Validation precision@k20: 0.7437, accuracy@k20: 0.7391\n",
      "Epoch: 32 \t Validation precision@k25: 0.7948, accuracy@k25: 0.7945\n",
      "Epoch: 32 \t Validation precision@k30: 0.8368, accuracy@k30: 0.8368\n",
      "CPU: 20.51\n",
      "RAM %: 57.2\n",
      "Epoch: 33 \t Training Loss: 3.504442\n",
      "Epoch: 33 \t Validation precision@k5: 0.6886, accuracy@k5: 0.3580\n",
      "Epoch: 33 \t Validation precision@k10: 0.6523, accuracy@k10: 0.5479\n",
      "Epoch: 33 \t Validation precision@k15: 0.6876, accuracy@k15: 0.6616\n",
      "Epoch: 33 \t Validation precision@k20: 0.7443, accuracy@k20: 0.7398\n",
      "Epoch: 33 \t Validation precision@k25: 0.7955, accuracy@k25: 0.7952\n",
      "Epoch: 33 \t Validation precision@k30: 0.8369, accuracy@k30: 0.8369\n",
      "CPU: 20.46\n",
      "RAM %: 57.2\n",
      "Epoch: 34 \t Training Loss: 3.502025\n",
      "Epoch: 34 \t Validation precision@k5: 0.6950, accuracy@k5: 0.3613\n",
      "Epoch: 34 \t Validation precision@k10: 0.6520, accuracy@k10: 0.5476\n",
      "Epoch: 34 \t Validation precision@k15: 0.6859, accuracy@k15: 0.6597\n",
      "Epoch: 34 \t Validation precision@k20: 0.7435, accuracy@k20: 0.7390\n",
      "Epoch: 34 \t Validation precision@k25: 0.7959, accuracy@k25: 0.7956\n",
      "Epoch: 34 \t Validation precision@k30: 0.8364, accuracy@k30: 0.8364\n",
      "CPU: 20.46\n",
      "RAM %: 57.0\n",
      "Epoch: 35 \t Training Loss: 3.499882\n",
      "Epoch: 35 \t Validation precision@k5: 0.6906, accuracy@k5: 0.3585\n",
      "Epoch: 35 \t Validation precision@k10: 0.6565, accuracy@k10: 0.5512\n",
      "Epoch: 35 \t Validation precision@k15: 0.6892, accuracy@k15: 0.6629\n",
      "Epoch: 35 \t Validation precision@k20: 0.7442, accuracy@k20: 0.7396\n",
      "Epoch: 35 \t Validation precision@k25: 0.7977, accuracy@k25: 0.7975\n",
      "Epoch: 35 \t Validation precision@k30: 0.8373, accuracy@k30: 0.8373\n",
      "CPU: 20.41\n",
      "RAM %: 57.1\n",
      "Epoch: 36 \t Training Loss: 3.497364\n",
      "Epoch: 36 \t Validation precision@k5: 0.6912, accuracy@k5: 0.3591\n",
      "Epoch: 36 \t Validation precision@k10: 0.6559, accuracy@k10: 0.5505\n",
      "Epoch: 36 \t Validation precision@k15: 0.6882, accuracy@k15: 0.6619\n",
      "Epoch: 36 \t Validation precision@k20: 0.7426, accuracy@k20: 0.7381\n",
      "Epoch: 36 \t Validation precision@k25: 0.7989, accuracy@k25: 0.7986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 \t Validation precision@k30: 0.8368, accuracy@k30: 0.8368\n",
      "CPU: 20.36\n",
      "RAM %: 57.1\n",
      "Epoch: 37 \t Training Loss: 3.496924\n",
      "Epoch: 37 \t Validation precision@k5: 0.6901, accuracy@k5: 0.3587\n",
      "Epoch: 37 \t Validation precision@k10: 0.6537, accuracy@k10: 0.5487\n",
      "Epoch: 37 \t Validation precision@k15: 0.6899, accuracy@k15: 0.6633\n",
      "Epoch: 37 \t Validation precision@k20: 0.7459, accuracy@k20: 0.7413\n",
      "Epoch: 37 \t Validation precision@k25: 0.7987, accuracy@k25: 0.7984\n",
      "Epoch: 37 \t Validation precision@k30: 0.8383, accuracy@k30: 0.8383\n",
      "CPU: 20.54\n",
      "RAM %: 57.1\n",
      "Epoch: 38 \t Training Loss: 3.495603\n",
      "Epoch: 38 \t Validation precision@k5: 0.6905, accuracy@k5: 0.3597\n",
      "Epoch: 38 \t Validation precision@k10: 0.6555, accuracy@k10: 0.5503\n",
      "Epoch: 38 \t Validation precision@k15: 0.6888, accuracy@k15: 0.6623\n",
      "Epoch: 38 \t Validation precision@k20: 0.7468, accuracy@k20: 0.7422\n",
      "Epoch: 38 \t Validation precision@k25: 0.7985, accuracy@k25: 0.7982\n",
      "Epoch: 38 \t Validation precision@k30: 0.8358, accuracy@k30: 0.8358\n",
      "CPU: 20.49\n",
      "RAM %: 57.0\n",
      "Epoch: 39 \t Training Loss: 3.494373\n",
      "Epoch: 39 \t Validation precision@k5: 0.6960, accuracy@k5: 0.3622\n",
      "Epoch: 39 \t Validation precision@k10: 0.6573, accuracy@k10: 0.5522\n",
      "Epoch: 39 \t Validation precision@k15: 0.6865, accuracy@k15: 0.6604\n",
      "Epoch: 39 \t Validation precision@k20: 0.7452, accuracy@k20: 0.7407\n",
      "Epoch: 39 \t Validation precision@k25: 0.7984, accuracy@k25: 0.7982\n",
      "Epoch: 39 \t Validation precision@k30: 0.8394, accuracy@k30: 0.8394\n",
      "CPU: 20.44\n",
      "RAM %: 57.1\n",
      "Epoch: 40 \t Training Loss: 3.491293\n",
      "Epoch: 40 \t Validation precision@k5: 0.6908, accuracy@k5: 0.3591\n",
      "Epoch: 40 \t Validation precision@k10: 0.6571, accuracy@k10: 0.5522\n",
      "Epoch: 40 \t Validation precision@k15: 0.6907, accuracy@k15: 0.6643\n",
      "Epoch: 40 \t Validation precision@k20: 0.7456, accuracy@k20: 0.7410\n",
      "Epoch: 40 \t Validation precision@k25: 0.7996, accuracy@k25: 0.7993\n",
      "Epoch: 40 \t Validation precision@k30: 0.8387, accuracy@k30: 0.8387\n",
      "CPU: 20.39\n",
      "RAM %: 57.0\n",
      "Epoch: 41 \t Training Loss: 3.491943\n",
      "Epoch: 41 \t Validation precision@k5: 0.6971, accuracy@k5: 0.3627\n",
      "Epoch: 41 \t Validation precision@k10: 0.6573, accuracy@k10: 0.5520\n",
      "Epoch: 41 \t Validation precision@k15: 0.6884, accuracy@k15: 0.6620\n",
      "Epoch: 41 \t Validation precision@k20: 0.7451, accuracy@k20: 0.7405\n",
      "Epoch: 41 \t Validation precision@k25: 0.7982, accuracy@k25: 0.7979\n",
      "Epoch: 41 \t Validation precision@k30: 0.8384, accuracy@k30: 0.8384\n",
      "CPU: 20.38\n",
      "RAM %: 57.1\n",
      "Epoch: 42 \t Training Loss: 3.491452\n",
      "Epoch: 42 \t Validation precision@k5: 0.6991, accuracy@k5: 0.3631\n",
      "Epoch: 42 \t Validation precision@k10: 0.6576, accuracy@k10: 0.5519\n",
      "Epoch: 42 \t Validation precision@k15: 0.6912, accuracy@k15: 0.6647\n",
      "Epoch: 42 \t Validation precision@k20: 0.7472, accuracy@k20: 0.7427\n",
      "Epoch: 42 \t Validation precision@k25: 0.8001, accuracy@k25: 0.7998\n",
      "Epoch: 42 \t Validation precision@k30: 0.8377, accuracy@k30: 0.8377\n",
      "CPU: 20.58\n",
      "RAM %: 57.1\n",
      "Epoch: 43 \t Training Loss: 3.489480\n",
      "Epoch: 43 \t Validation precision@k5: 0.6983, accuracy@k5: 0.3627\n",
      "Epoch: 43 \t Validation precision@k10: 0.6587, accuracy@k10: 0.5530\n",
      "Epoch: 43 \t Validation precision@k15: 0.6901, accuracy@k15: 0.6635\n",
      "Epoch: 43 \t Validation precision@k20: 0.7451, accuracy@k20: 0.7405\n",
      "Epoch: 43 \t Validation precision@k25: 0.8000, accuracy@k25: 0.7997\n",
      "Epoch: 43 \t Validation precision@k30: 0.8384, accuracy@k30: 0.8384\n",
      "CPU: 20.72\n",
      "RAM %: 56.8\n",
      "Epoch: 44 \t Training Loss: 3.489340\n",
      "Epoch: 44 \t Validation precision@k5: 0.6995, accuracy@k5: 0.3639\n",
      "Epoch: 44 \t Validation precision@k10: 0.6615, accuracy@k10: 0.5561\n",
      "Epoch: 44 \t Validation precision@k15: 0.6887, accuracy@k15: 0.6623\n",
      "Epoch: 44 \t Validation precision@k20: 0.7457, accuracy@k20: 0.7411\n",
      "Epoch: 44 \t Validation precision@k25: 0.8000, accuracy@k25: 0.7997\n",
      "Epoch: 44 \t Validation precision@k30: 0.8399, accuracy@k30: 0.8399\n",
      "CPU: 20.72\n",
      "RAM %: 57.0\n",
      "Epoch: 45 \t Training Loss: 3.489297\n",
      "Epoch: 45 \t Validation precision@k5: 0.6983, accuracy@k5: 0.3631\n",
      "Epoch: 45 \t Validation precision@k10: 0.6608, accuracy@k10: 0.5547\n",
      "Epoch: 45 \t Validation precision@k15: 0.6907, accuracy@k15: 0.6641\n",
      "Epoch: 45 \t Validation precision@k20: 0.7461, accuracy@k20: 0.7416\n",
      "Epoch: 45 \t Validation precision@k25: 0.7995, accuracy@k25: 0.7993\n",
      "Epoch: 45 \t Validation precision@k30: 0.8391, accuracy@k30: 0.8391\n",
      "CPU: 20.71\n",
      "RAM %: 57.2\n",
      "Epoch: 46 \t Training Loss: 3.488002\n",
      "Epoch: 46 \t Validation precision@k5: 0.6996, accuracy@k5: 0.3634\n",
      "Epoch: 46 \t Validation precision@k10: 0.6603, accuracy@k10: 0.5544\n",
      "Epoch: 46 \t Validation precision@k15: 0.6914, accuracy@k15: 0.6645\n",
      "Epoch: 46 \t Validation precision@k20: 0.7464, accuracy@k20: 0.7418\n",
      "Epoch: 46 \t Validation precision@k25: 0.8000, accuracy@k25: 0.7997\n",
      "Epoch: 46 \t Validation precision@k30: 0.8407, accuracy@k30: 0.8407\n",
      "CPU: 20.84\n",
      "RAM %: 57.2\n",
      "Epoch: 47 \t Training Loss: 3.488191\n",
      "Epoch: 47 \t Validation precision@k5: 0.7056, accuracy@k5: 0.3666\n",
      "Epoch: 47 \t Validation precision@k10: 0.6641, accuracy@k10: 0.5574\n",
      "Epoch: 47 \t Validation precision@k15: 0.6919, accuracy@k15: 0.6650\n",
      "Epoch: 47 \t Validation precision@k20: 0.7479, accuracy@k20: 0.7433\n",
      "Epoch: 47 \t Validation precision@k25: 0.7988, accuracy@k25: 0.7985\n",
      "Epoch: 47 \t Validation precision@k30: 0.8389, accuracy@k30: 0.8389\n",
      "CPU: 20.79\n",
      "RAM %: 57.3\n",
      "Epoch: 48 \t Training Loss: 3.487743\n",
      "Epoch: 48 \t Validation precision@k5: 0.7005, accuracy@k5: 0.3644\n",
      "Epoch: 48 \t Validation precision@k10: 0.6620, accuracy@k10: 0.5560\n",
      "Epoch: 48 \t Validation precision@k15: 0.6913, accuracy@k15: 0.6646\n",
      "Epoch: 48 \t Validation precision@k20: 0.7445, accuracy@k20: 0.7400\n",
      "Epoch: 48 \t Validation precision@k25: 0.7988, accuracy@k25: 0.7985\n",
      "Epoch: 48 \t Validation precision@k30: 0.8393, accuracy@k30: 0.8393\n",
      "CPU: 21.00\n",
      "RAM %: 57.1\n",
      "Epoch: 49 \t Training Loss: 3.485528\n",
      "Epoch: 49 \t Validation precision@k5: 0.7029, accuracy@k5: 0.3652\n",
      "Epoch: 49 \t Validation precision@k10: 0.6630, accuracy@k10: 0.5564\n",
      "Epoch: 49 \t Validation precision@k15: 0.6893, accuracy@k15: 0.6628\n",
      "Epoch: 49 \t Validation precision@k20: 0.7457, accuracy@k20: 0.7411\n",
      "Epoch: 49 \t Validation precision@k25: 0.8000, accuracy@k25: 0.7997\n",
      "Epoch: 49 \t Validation precision@k30: 0.8388, accuracy@k30: 0.8388\n",
      "CPU: 20.94\n",
      "RAM %: 57.3\n",
      "Epoch: 50 \t Training Loss: 3.485692\n",
      "Epoch: 50 \t Validation precision@k5: 0.7000, accuracy@k5: 0.3635\n",
      "Epoch: 50 \t Validation precision@k10: 0.6619, accuracy@k10: 0.5560\n",
      "Epoch: 50 \t Validation precision@k15: 0.6909, accuracy@k15: 0.6643\n",
      "Epoch: 50 \t Validation precision@k20: 0.7464, accuracy@k20: 0.7418\n",
      "Epoch: 50 \t Validation precision@k25: 0.7989, accuracy@k25: 0.7986\n",
      "Epoch: 50 \t Validation precision@k30: 0.8394, accuracy@k30: 0.8394\n",
      "CPU: 21.15\n",
      "RAM %: 57.1\n",
      "Epoch: 51 \t Training Loss: 3.486669\n",
      "Epoch: 51 \t Validation precision@k5: 0.7010, accuracy@k5: 0.3648\n",
      "Epoch: 51 \t Validation precision@k10: 0.6630, accuracy@k10: 0.5562\n",
      "Epoch: 51 \t Validation precision@k15: 0.6931, accuracy@k15: 0.6662\n",
      "Epoch: 51 \t Validation precision@k20: 0.7473, accuracy@k20: 0.7427\n",
      "Epoch: 51 \t Validation precision@k25: 0.8003, accuracy@k25: 0.8000\n",
      "Epoch: 51 \t Validation precision@k30: 0.8407, accuracy@k30: 0.8407\n",
      "CPU: 21.21\n",
      "RAM %: 57.2\n",
      "Epoch: 52 \t Training Loss: 3.485646\n",
      "Epoch: 52 \t Validation precision@k5: 0.7016, accuracy@k5: 0.3645\n",
      "Epoch: 52 \t Validation precision@k10: 0.6615, accuracy@k10: 0.5556\n",
      "Epoch: 52 \t Validation precision@k15: 0.6922, accuracy@k15: 0.6655\n",
      "Epoch: 52 \t Validation precision@k20: 0.7464, accuracy@k20: 0.7417\n",
      "Epoch: 52 \t Validation precision@k25: 0.7986, accuracy@k25: 0.7983\n",
      "Epoch: 52 \t Validation precision@k30: 0.8403, accuracy@k30: 0.8403\n",
      "CPU: 21.41\n",
      "RAM %: 57.1\n",
      "Epoch: 53 \t Training Loss: 3.486429\n",
      "Epoch: 53 \t Validation precision@k5: 0.7021, accuracy@k5: 0.3653\n",
      "Epoch: 53 \t Validation precision@k10: 0.6615, accuracy@k10: 0.5558\n",
      "Epoch: 53 \t Validation precision@k15: 0.6921, accuracy@k15: 0.6653\n",
      "Epoch: 53 \t Validation precision@k20: 0.7432, accuracy@k20: 0.7387\n",
      "Epoch: 53 \t Validation precision@k25: 0.7967, accuracy@k25: 0.7965\n",
      "Epoch: 53 \t Validation precision@k30: 0.8404, accuracy@k30: 0.8404\n",
      "CPU: 21.47\n",
      "RAM %: 57.2\n",
      "Epoch: 54 \t Training Loss: 3.485722\n",
      "Epoch: 54 \t Validation precision@k5: 0.6983, accuracy@k5: 0.3629\n",
      "Epoch: 54 \t Validation precision@k10: 0.6652, accuracy@k10: 0.5591\n",
      "Epoch: 54 \t Validation precision@k15: 0.6933, accuracy@k15: 0.6664\n",
      "Epoch: 54 \t Validation precision@k20: 0.7461, accuracy@k20: 0.7415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 \t Validation precision@k25: 0.7984, accuracy@k25: 0.7981\n",
      "Epoch: 54 \t Validation precision@k30: 0.8400, accuracy@k30: 0.8400\n",
      "CPU: 21.70\n",
      "RAM %: 57.1\n",
      "Epoch: 55 \t Training Loss: 3.485228\n",
      "Epoch: 55 \t Validation precision@k5: 0.7056, accuracy@k5: 0.3666\n",
      "Epoch: 55 \t Validation precision@k10: 0.6654, accuracy@k10: 0.5589\n",
      "Epoch: 55 \t Validation precision@k15: 0.6941, accuracy@k15: 0.6671\n",
      "Epoch: 55 \t Validation precision@k20: 0.7468, accuracy@k20: 0.7422\n",
      "Epoch: 55 \t Validation precision@k25: 0.7985, accuracy@k25: 0.7982\n",
      "Epoch: 55 \t Validation precision@k30: 0.8405, accuracy@k30: 0.8405\n",
      "CPU: 21.70\n",
      "RAM %: 57.1\n",
      "Epoch: 56 \t Training Loss: 3.484556\n",
      "Epoch: 56 \t Validation precision@k5: 0.7068, accuracy@k5: 0.3683\n",
      "Epoch: 56 \t Validation precision@k10: 0.6614, accuracy@k10: 0.5553\n",
      "Epoch: 56 \t Validation precision@k15: 0.6943, accuracy@k15: 0.6675\n",
      "Epoch: 56 \t Validation precision@k20: 0.7463, accuracy@k20: 0.7416\n",
      "Epoch: 56 \t Validation precision@k25: 0.7973, accuracy@k25: 0.7970\n",
      "Epoch: 56 \t Validation precision@k30: 0.8406, accuracy@k30: 0.8406\n",
      "CPU: 21.72\n",
      "RAM %: 57.1\n",
      "Epoch: 57 \t Training Loss: 3.485415\n",
      "Epoch: 57 \t Validation precision@k5: 0.7074, accuracy@k5: 0.3674\n",
      "Epoch: 57 \t Validation precision@k10: 0.6603, accuracy@k10: 0.5548\n",
      "Epoch: 57 \t Validation precision@k15: 0.6924, accuracy@k15: 0.6656\n",
      "Epoch: 57 \t Validation precision@k20: 0.7466, accuracy@k20: 0.7420\n",
      "Epoch: 57 \t Validation precision@k25: 0.7988, accuracy@k25: 0.7985\n",
      "Epoch: 57 \t Validation precision@k30: 0.8390, accuracy@k30: 0.8390\n",
      "CPU: 21.70\n",
      "RAM %: 57.0\n",
      "Epoch: 58 \t Training Loss: 3.484459\n",
      "Epoch: 58 \t Validation precision@k5: 0.7018, accuracy@k5: 0.3648\n",
      "Epoch: 58 \t Validation precision@k10: 0.6648, accuracy@k10: 0.5581\n",
      "Epoch: 58 \t Validation precision@k15: 0.6938, accuracy@k15: 0.6670\n",
      "Epoch: 58 \t Validation precision@k20: 0.7457, accuracy@k20: 0.7411\n",
      "Epoch: 58 \t Validation precision@k25: 0.7965, accuracy@k25: 0.7962\n",
      "Epoch: 58 \t Validation precision@k30: 0.8391, accuracy@k30: 0.8391\n",
      "CPU: 21.69\n",
      "RAM %: 56.9\n",
      "Epoch: 59 \t Training Loss: 3.483608\n",
      "Epoch: 59 \t Validation precision@k5: 0.7047, accuracy@k5: 0.3660\n",
      "Epoch: 59 \t Validation precision@k10: 0.6621, accuracy@k10: 0.5557\n",
      "Epoch: 59 \t Validation precision@k15: 0.6941, accuracy@k15: 0.6673\n",
      "Epoch: 59 \t Validation precision@k20: 0.7464, accuracy@k20: 0.7418\n",
      "Epoch: 59 \t Validation precision@k25: 0.7979, accuracy@k25: 0.7976\n",
      "Epoch: 59 \t Validation precision@k30: 0.8415, accuracy@k30: 0.8415\n",
      "CPU: 21.74\n",
      "RAM %: 56.9\n",
      "Epoch: 60 \t Training Loss: 3.484884\n",
      "Epoch: 60 \t Validation precision@k5: 0.7040, accuracy@k5: 0.3656\n",
      "Epoch: 60 \t Validation precision@k10: 0.6641, accuracy@k10: 0.5575\n",
      "Epoch: 60 \t Validation precision@k15: 0.6938, accuracy@k15: 0.6668\n",
      "Epoch: 60 \t Validation precision@k20: 0.7471, accuracy@k20: 0.7425\n",
      "Epoch: 60 \t Validation precision@k25: 0.7978, accuracy@k25: 0.7975\n",
      "Epoch: 60 \t Validation precision@k30: 0.8405, accuracy@k30: 0.8405\n",
      "CPU: 21.94\n",
      "RAM %: 56.9\n",
      "Epoch: 61 \t Training Loss: 3.483843\n",
      "Epoch: 61 \t Validation precision@k5: 0.7026, accuracy@k5: 0.3647\n",
      "Epoch: 61 \t Validation precision@k10: 0.6623, accuracy@k10: 0.5560\n",
      "Epoch: 61 \t Validation precision@k15: 0.6933, accuracy@k15: 0.6665\n",
      "Epoch: 61 \t Validation precision@k20: 0.7459, accuracy@k20: 0.7413\n",
      "Epoch: 61 \t Validation precision@k25: 0.7971, accuracy@k25: 0.7968\n",
      "Epoch: 61 \t Validation precision@k30: 0.8401, accuracy@k30: 0.8401\n",
      "CPU: 21.88\n",
      "RAM %: 56.9\n",
      "Epoch: 62 \t Training Loss: 3.484238\n",
      "Epoch: 62 \t Validation precision@k5: 0.7059, accuracy@k5: 0.3671\n",
      "Epoch: 62 \t Validation precision@k10: 0.6639, accuracy@k10: 0.5572\n",
      "Epoch: 62 \t Validation precision@k15: 0.6945, accuracy@k15: 0.6674\n",
      "Epoch: 62 \t Validation precision@k20: 0.7444, accuracy@k20: 0.7398\n",
      "Epoch: 62 \t Validation precision@k25: 0.7977, accuracy@k25: 0.7974\n",
      "Epoch: 62 \t Validation precision@k30: 0.8422, accuracy@k30: 0.8422\n",
      "CPU: 22.08\n",
      "RAM %: 57.0\n",
      "Epoch: 63 \t Training Loss: 3.483967\n",
      "Epoch: 63 \t Validation precision@k5: 0.7009, accuracy@k5: 0.3642\n",
      "Epoch: 63 \t Validation precision@k10: 0.6607, accuracy@k10: 0.5548\n",
      "Epoch: 63 \t Validation precision@k15: 0.6923, accuracy@k15: 0.6655\n",
      "Epoch: 63 \t Validation precision@k20: 0.7444, accuracy@k20: 0.7398\n",
      "Epoch: 63 \t Validation precision@k25: 0.7989, accuracy@k25: 0.7986\n",
      "Epoch: 63 \t Validation precision@k30: 0.8406, accuracy@k30: 0.8406\n",
      "CPU: 22.06\n",
      "RAM %: 57.0\n",
      "Epoch: 64 \t Training Loss: 3.483495\n",
      "Epoch: 64 \t Validation precision@k5: 0.7046, accuracy@k5: 0.3660\n",
      "Epoch: 64 \t Validation precision@k10: 0.6628, accuracy@k10: 0.5562\n",
      "Epoch: 64 \t Validation precision@k15: 0.6923, accuracy@k15: 0.6654\n",
      "Epoch: 64 \t Validation precision@k20: 0.7430, accuracy@k20: 0.7384\n",
      "Epoch: 64 \t Validation precision@k25: 0.7938, accuracy@k25: 0.7936\n",
      "Epoch: 64 \t Validation precision@k30: 0.8394, accuracy@k30: 0.8394\n",
      "CPU: 22.06\n",
      "RAM %: 57.0\n",
      "Epoch: 65 \t Training Loss: 3.484782\n",
      "Epoch: 65 \t Validation precision@k5: 0.7031, accuracy@k5: 0.3655\n",
      "Epoch: 65 \t Validation precision@k10: 0.6621, accuracy@k10: 0.5558\n",
      "Epoch: 65 \t Validation precision@k15: 0.6925, accuracy@k15: 0.6656\n",
      "Epoch: 65 \t Validation precision@k20: 0.7456, accuracy@k20: 0.7410\n",
      "Epoch: 65 \t Validation precision@k25: 0.7975, accuracy@k25: 0.7972\n",
      "Epoch: 65 \t Validation precision@k30: 0.8390, accuracy@k30: 0.8390\n",
      "CPU: 22.11\n",
      "RAM %: 57.1\n",
      "Epoch: 66 \t Training Loss: 3.484749\n",
      "Epoch: 66 \t Validation precision@k5: 0.7090, accuracy@k5: 0.3693\n",
      "Epoch: 66 \t Validation precision@k10: 0.6605, accuracy@k10: 0.5544\n",
      "Epoch: 66 \t Validation precision@k15: 0.6922, accuracy@k15: 0.6652\n",
      "Epoch: 66 \t Validation precision@k20: 0.7456, accuracy@k20: 0.7410\n",
      "Epoch: 66 \t Validation precision@k25: 0.7962, accuracy@k25: 0.7959\n",
      "Epoch: 66 \t Validation precision@k30: 0.8395, accuracy@k30: 0.8395\n",
      "CPU: 22.09\n",
      "RAM %: 57.2\n",
      "Epoch: 67 \t Training Loss: 3.483906\n",
      "Epoch: 67 \t Validation precision@k5: 0.7066, accuracy@k5: 0.3674\n",
      "Epoch: 67 \t Validation precision@k10: 0.6624, accuracy@k10: 0.5558\n",
      "Epoch: 67 \t Validation precision@k15: 0.6943, accuracy@k15: 0.6672\n",
      "Epoch: 67 \t Validation precision@k20: 0.7447, accuracy@k20: 0.7401\n",
      "Epoch: 67 \t Validation precision@k25: 0.7970, accuracy@k25: 0.7967\n",
      "Epoch: 67 \t Validation precision@k30: 0.8401, accuracy@k30: 0.8401\n",
      "CPU: 22.07\n",
      "RAM %: 57.3\n",
      "Epoch: 68 \t Training Loss: 3.483642\n",
      "Epoch: 68 \t Validation precision@k5: 0.7019, accuracy@k5: 0.3645\n",
      "Epoch: 68 \t Validation precision@k10: 0.6632, accuracy@k10: 0.5567\n",
      "Epoch: 68 \t Validation precision@k15: 0.6944, accuracy@k15: 0.6676\n",
      "Epoch: 68 \t Validation precision@k20: 0.7450, accuracy@k20: 0.7404\n",
      "Epoch: 68 \t Validation precision@k25: 0.7987, accuracy@k25: 0.7984\n",
      "Epoch: 68 \t Validation precision@k30: 0.8405, accuracy@k30: 0.8405\n",
      "CPU: 22.05\n",
      "RAM %: 57.5\n",
      "Epoch: 69 \t Training Loss: 3.484000\n",
      "Epoch: 69 \t Validation precision@k5: 0.7054, accuracy@k5: 0.3667\n",
      "Epoch: 69 \t Validation precision@k10: 0.6635, accuracy@k10: 0.5569\n",
      "Epoch: 69 \t Validation precision@k15: 0.6936, accuracy@k15: 0.6667\n",
      "Epoch: 69 \t Validation precision@k20: 0.7448, accuracy@k20: 0.7402\n",
      "Epoch: 69 \t Validation precision@k25: 0.7977, accuracy@k25: 0.7974\n",
      "Epoch: 69 \t Validation precision@k30: 0.8400, accuracy@k30: 0.8400\n",
      "CPU: 22.17\n",
      "RAM %: 57.6\n",
      "Epoch: 70 \t Training Loss: 3.483331\n",
      "Epoch: 70 \t Validation precision@k5: 0.7063, accuracy@k5: 0.3669\n",
      "Epoch: 70 \t Validation precision@k10: 0.6630, accuracy@k10: 0.5567\n",
      "Epoch: 70 \t Validation precision@k15: 0.6939, accuracy@k15: 0.6671\n",
      "Epoch: 70 \t Validation precision@k20: 0.7468, accuracy@k20: 0.7422\n",
      "Epoch: 70 \t Validation precision@k25: 0.7968, accuracy@k25: 0.7965\n",
      "Epoch: 70 \t Validation precision@k30: 0.8377, accuracy@k30: 0.8377\n",
      "CPU: 22.12\n",
      "RAM %: 57.5\n",
      "Epoch: 71 \t Training Loss: 3.482745\n",
      "Epoch: 71 \t Validation precision@k5: 0.7015, accuracy@k5: 0.3644\n",
      "Epoch: 71 \t Validation precision@k10: 0.6620, accuracy@k10: 0.5558\n",
      "Epoch: 71 \t Validation precision@k15: 0.6950, accuracy@k15: 0.6680\n",
      "Epoch: 71 \t Validation precision@k20: 0.7448, accuracy@k20: 0.7402\n",
      "Epoch: 71 \t Validation precision@k25: 0.7964, accuracy@k25: 0.7961\n",
      "Epoch: 71 \t Validation precision@k30: 0.8404, accuracy@k30: 0.8404\n",
      "CPU: 22.06\n",
      "RAM %: 56.9\n",
      "Epoch: 72 \t Training Loss: 3.484901\n",
      "Epoch: 72 \t Validation precision@k5: 0.7084, accuracy@k5: 0.3683\n",
      "Epoch: 72 \t Validation precision@k10: 0.6630, accuracy@k10: 0.5561\n",
      "Epoch: 72 \t Validation precision@k15: 0.6920, accuracy@k15: 0.6651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 \t Validation precision@k20: 0.7442, accuracy@k20: 0.7396\n",
      "Epoch: 72 \t Validation precision@k25: 0.7963, accuracy@k25: 0.7961\n",
      "Epoch: 72 \t Validation precision@k30: 0.8386, accuracy@k30: 0.8386\n",
      "CPU: 22.00\n",
      "RAM %: 57.0\n",
      "Epoch: 73 \t Training Loss: 3.484508\n",
      "Epoch: 73 \t Validation precision@k5: 0.7032, accuracy@k5: 0.3654\n",
      "Epoch: 73 \t Validation precision@k10: 0.6622, accuracy@k10: 0.5556\n",
      "Epoch: 73 \t Validation precision@k15: 0.6950, accuracy@k15: 0.6681\n",
      "Epoch: 73 \t Validation precision@k20: 0.7480, accuracy@k20: 0.7434\n",
      "Epoch: 73 \t Validation precision@k25: 0.7960, accuracy@k25: 0.7957\n",
      "Epoch: 73 \t Validation precision@k30: 0.8407, accuracy@k30: 0.8407\n",
      "CPU: 22.13\n",
      "RAM %: 56.9\n",
      "Epoch: 74 \t Training Loss: 3.482937\n",
      "Epoch: 74 \t Validation precision@k5: 0.7049, accuracy@k5: 0.3665\n",
      "Epoch: 74 \t Validation precision@k10: 0.6618, accuracy@k10: 0.5551\n",
      "Epoch: 74 \t Validation precision@k15: 0.6930, accuracy@k15: 0.6662\n",
      "Epoch: 74 \t Validation precision@k20: 0.7452, accuracy@k20: 0.7406\n",
      "Epoch: 74 \t Validation precision@k25: 0.7971, accuracy@k25: 0.7968\n",
      "Epoch: 74 \t Validation precision@k30: 0.8403, accuracy@k30: 0.8403\n",
      "CPU: 22.07\n",
      "RAM %: 56.9\n",
      "Epoch: 75 \t Training Loss: 3.483279\n",
      "Epoch: 75 \t Validation precision@k5: 0.7055, accuracy@k5: 0.3664\n",
      "Epoch: 75 \t Validation precision@k10: 0.6618, accuracy@k10: 0.5556\n",
      "Epoch: 75 \t Validation precision@k15: 0.6937, accuracy@k15: 0.6667\n",
      "Epoch: 75 \t Validation precision@k20: 0.7476, accuracy@k20: 0.7430\n",
      "Epoch: 75 \t Validation precision@k25: 0.7975, accuracy@k25: 0.7972\n",
      "Epoch: 75 \t Validation precision@k30: 0.8395, accuracy@k30: 0.8395\n",
      "CPU: 22.27\n",
      "RAM %: 56.7\n",
      "Epoch: 76 \t Training Loss: 3.484113\n",
      "Epoch: 76 \t Validation precision@k5: 0.7078, accuracy@k5: 0.3675\n",
      "Epoch: 76 \t Validation precision@k10: 0.6618, accuracy@k10: 0.5555\n",
      "Epoch: 76 \t Validation precision@k15: 0.6937, accuracy@k15: 0.6667\n",
      "Epoch: 76 \t Validation precision@k20: 0.7455, accuracy@k20: 0.7409\n",
      "Epoch: 76 \t Validation precision@k25: 0.7957, accuracy@k25: 0.7954\n",
      "Epoch: 76 \t Validation precision@k30: 0.8393, accuracy@k30: 0.8393\n",
      "CPU: 22.21\n",
      "RAM %: 57.2\n",
      "Epoch: 77 \t Training Loss: 3.483562\n",
      "Epoch: 77 \t Validation precision@k5: 0.7095, accuracy@k5: 0.3688\n",
      "Epoch: 77 \t Validation precision@k10: 0.6646, accuracy@k10: 0.5579\n",
      "Epoch: 77 \t Validation precision@k15: 0.6925, accuracy@k15: 0.6657\n",
      "Epoch: 77 \t Validation precision@k20: 0.7458, accuracy@k20: 0.7412\n",
      "Epoch: 77 \t Validation precision@k25: 0.7965, accuracy@k25: 0.7962\n",
      "Epoch: 77 \t Validation precision@k30: 0.8398, accuracy@k30: 0.8398\n",
      "CPU: 22.33\n",
      "RAM %: 57.3\n",
      "Epoch: 78 \t Training Loss: 3.484042\n",
      "Epoch: 78 \t Validation precision@k5: 0.7081, accuracy@k5: 0.3682\n",
      "Epoch: 78 \t Validation precision@k10: 0.6615, accuracy@k10: 0.5555\n",
      "Epoch: 78 \t Validation precision@k15: 0.6957, accuracy@k15: 0.6688\n",
      "Epoch: 78 \t Validation precision@k20: 0.7475, accuracy@k20: 0.7428\n",
      "Epoch: 78 \t Validation precision@k25: 0.7973, accuracy@k25: 0.7970\n",
      "Epoch: 78 \t Validation precision@k30: 0.8405, accuracy@k30: 0.8405\n",
      "CPU: 22.35\n",
      "RAM %: 57.1\n",
      "Epoch: 79 \t Training Loss: 3.482706\n",
      "Epoch: 79 \t Validation precision@k5: 0.7100, accuracy@k5: 0.3689\n",
      "Epoch: 79 \t Validation precision@k10: 0.6629, accuracy@k10: 0.5562\n",
      "Epoch: 79 \t Validation precision@k15: 0.6941, accuracy@k15: 0.6672\n",
      "Epoch: 79 \t Validation precision@k20: 0.7463, accuracy@k20: 0.7417\n",
      "Epoch: 79 \t Validation precision@k25: 0.7966, accuracy@k25: 0.7963\n",
      "Epoch: 79 \t Validation precision@k30: 0.8398, accuracy@k30: 0.8398\n",
      "CPU: 22.36\n",
      "RAM %: 57.0\n",
      "Epoch: 80 \t Training Loss: 3.482085\n",
      "Epoch: 80 \t Validation precision@k5: 0.7058, accuracy@k5: 0.3672\n",
      "Epoch: 80 \t Validation precision@k10: 0.6626, accuracy@k10: 0.5560\n",
      "Epoch: 80 \t Validation precision@k15: 0.6937, accuracy@k15: 0.6667\n",
      "Epoch: 80 \t Validation precision@k20: 0.7465, accuracy@k20: 0.7418\n",
      "Epoch: 80 \t Validation precision@k25: 0.7958, accuracy@k25: 0.7955\n",
      "Epoch: 80 \t Validation precision@k30: 0.8397, accuracy@k30: 0.8397\n",
      "CPU: 22.56\n",
      "RAM %: 57.5\n",
      "Epoch: 81 \t Training Loss: 3.483153\n",
      "Epoch: 81 \t Validation precision@k5: 0.7043, accuracy@k5: 0.3659\n",
      "Epoch: 81 \t Validation precision@k10: 0.6617, accuracy@k10: 0.5553\n",
      "Epoch: 81 \t Validation precision@k15: 0.6957, accuracy@k15: 0.6686\n",
      "Epoch: 81 \t Validation precision@k20: 0.7464, accuracy@k20: 0.7418\n",
      "Epoch: 81 \t Validation precision@k25: 0.7965, accuracy@k25: 0.7962\n",
      "Epoch: 81 \t Validation precision@k30: 0.8394, accuracy@k30: 0.8394\n",
      "CPU: 22.56\n",
      "RAM %: 57.3\n",
      "Epoch: 82 \t Training Loss: 3.484806\n",
      "Epoch: 82 \t Validation precision@k5: 0.7082, accuracy@k5: 0.3679\n",
      "Epoch: 82 \t Validation precision@k10: 0.6613, accuracy@k10: 0.5551\n",
      "Epoch: 82 \t Validation precision@k15: 0.6940, accuracy@k15: 0.6671\n",
      "Epoch: 82 \t Validation precision@k20: 0.7463, accuracy@k20: 0.7417\n",
      "Epoch: 82 \t Validation precision@k25: 0.7964, accuracy@k25: 0.7961\n",
      "Epoch: 82 \t Validation precision@k30: 0.8384, accuracy@k30: 0.8384\n",
      "CPU: 22.54\n",
      "RAM %: 57.1\n",
      "Epoch: 83 \t Training Loss: 3.483903\n",
      "Epoch: 83 \t Validation precision@k5: 0.7059, accuracy@k5: 0.3676\n",
      "Epoch: 83 \t Validation precision@k10: 0.6593, accuracy@k10: 0.5539\n",
      "Epoch: 83 \t Validation precision@k15: 0.6929, accuracy@k15: 0.6661\n",
      "Epoch: 83 \t Validation precision@k20: 0.7451, accuracy@k20: 0.7404\n",
      "Epoch: 83 \t Validation precision@k25: 0.7968, accuracy@k25: 0.7965\n",
      "Epoch: 83 \t Validation precision@k30: 0.8393, accuracy@k30: 0.8393\n",
      "CPU: 22.55\n",
      "RAM %: 57.0\n",
      "Epoch: 84 \t Training Loss: 3.484627\n",
      "Epoch: 84 \t Validation precision@k5: 0.7072, accuracy@k5: 0.3682\n",
      "Epoch: 84 \t Validation precision@k10: 0.6635, accuracy@k10: 0.5569\n",
      "Epoch: 84 \t Validation precision@k15: 0.6949, accuracy@k15: 0.6679\n",
      "Epoch: 84 \t Validation precision@k20: 0.7469, accuracy@k20: 0.7423\n",
      "Epoch: 84 \t Validation precision@k25: 0.7960, accuracy@k25: 0.7957\n",
      "Epoch: 84 \t Validation precision@k30: 0.8381, accuracy@k30: 0.8381\n",
      "CPU: 22.49\n",
      "RAM %: 57.0\n",
      "Epoch: 85 \t Training Loss: 3.485238\n",
      "Epoch: 85 \t Validation precision@k5: 0.7090, accuracy@k5: 0.3691\n",
      "Epoch: 85 \t Validation precision@k10: 0.6620, accuracy@k10: 0.5558\n",
      "Epoch: 85 \t Validation precision@k15: 0.6922, accuracy@k15: 0.6654\n",
      "Epoch: 85 \t Validation precision@k20: 0.7468, accuracy@k20: 0.7422\n",
      "Epoch: 85 \t Validation precision@k25: 0.7963, accuracy@k25: 0.7960\n",
      "Epoch: 85 \t Validation precision@k30: 0.8390, accuracy@k30: 0.8390\n",
      "CPU: 22.50\n",
      "RAM %: 57.6\n",
      "Epoch: 86 \t Training Loss: 3.486042\n",
      "Epoch: 86 \t Validation precision@k5: 0.7053, accuracy@k5: 0.3669\n",
      "Epoch: 86 \t Validation precision@k10: 0.6613, accuracy@k10: 0.5549\n",
      "Epoch: 86 \t Validation precision@k15: 0.6943, accuracy@k15: 0.6674\n",
      "Epoch: 86 \t Validation precision@k20: 0.7466, accuracy@k20: 0.7419\n",
      "Epoch: 86 \t Validation precision@k25: 0.7964, accuracy@k25: 0.7961\n",
      "Epoch: 86 \t Validation precision@k30: 0.8390, accuracy@k30: 0.8390\n",
      "CPU: 22.48\n",
      "RAM %: 57.6\n",
      "Epoch: 87 \t Training Loss: 3.484767\n",
      "Epoch: 87 \t Validation precision@k5: 0.7113, accuracy@k5: 0.3699\n",
      "Epoch: 87 \t Validation precision@k10: 0.6606, accuracy@k10: 0.5543\n",
      "Epoch: 87 \t Validation precision@k15: 0.6935, accuracy@k15: 0.6667\n",
      "Epoch: 87 \t Validation precision@k20: 0.7462, accuracy@k20: 0.7416\n",
      "Epoch: 87 \t Validation precision@k25: 0.7966, accuracy@k25: 0.7964\n",
      "Epoch: 87 \t Validation precision@k30: 0.8378, accuracy@k30: 0.8378\n",
      "CPU: 22.42\n",
      "RAM %: 57.5\n",
      "Epoch: 88 \t Training Loss: 3.483698\n",
      "Epoch: 88 \t Validation precision@k5: 0.7079, accuracy@k5: 0.3681\n",
      "Epoch: 88 \t Validation precision@k10: 0.6610, accuracy@k10: 0.5548\n",
      "Epoch: 88 \t Validation precision@k15: 0.6948, accuracy@k15: 0.6678\n",
      "Epoch: 88 \t Validation precision@k20: 0.7476, accuracy@k20: 0.7430\n",
      "Epoch: 88 \t Validation precision@k25: 0.7958, accuracy@k25: 0.7955\n",
      "Epoch: 88 \t Validation precision@k30: 0.8392, accuracy@k30: 0.8392\n",
      "CPU: 22.46\n",
      "RAM %: 57.7\n",
      "Epoch: 89 \t Training Loss: 3.483042\n",
      "Epoch: 89 \t Validation precision@k5: 0.7084, accuracy@k5: 0.3688\n",
      "Epoch: 89 \t Validation precision@k10: 0.6614, accuracy@k10: 0.5553\n",
      "Epoch: 89 \t Validation precision@k15: 0.6922, accuracy@k15: 0.6654\n",
      "Epoch: 89 \t Validation precision@k20: 0.7448, accuracy@k20: 0.7402\n",
      "Epoch: 89 \t Validation precision@k25: 0.7969, accuracy@k25: 0.7966\n",
      "Epoch: 89 \t Validation precision@k30: 0.8389, accuracy@k30: 0.8389\n",
      "CPU: 22.66\n",
      "RAM %: 57.8\n",
      "Epoch: 90 \t Training Loss: 3.483323\n",
      "Epoch: 90 \t Validation precision@k5: 0.7048, accuracy@k5: 0.3660\n",
      "Epoch: 90 \t Validation precision@k10: 0.6626, accuracy@k10: 0.5561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 \t Validation precision@k15: 0.6941, accuracy@k15: 0.6671\n",
      "Epoch: 90 \t Validation precision@k20: 0.7466, accuracy@k20: 0.7419\n",
      "Epoch: 90 \t Validation precision@k25: 0.7966, accuracy@k25: 0.7963\n",
      "Epoch: 90 \t Validation precision@k30: 0.8377, accuracy@k30: 0.8377\n",
      "CPU: 22.63\n",
      "RAM %: 57.7\n",
      "Epoch: 91 \t Training Loss: 3.484789\n",
      "Epoch: 91 \t Validation precision@k5: 0.7104, accuracy@k5: 0.3697\n",
      "Epoch: 91 \t Validation precision@k10: 0.6609, accuracy@k10: 0.5543\n",
      "Epoch: 91 \t Validation precision@k15: 0.6941, accuracy@k15: 0.6671\n",
      "Epoch: 91 \t Validation precision@k20: 0.7468, accuracy@k20: 0.7422\n",
      "Epoch: 91 \t Validation precision@k25: 0.7970, accuracy@k25: 0.7967\n",
      "Epoch: 91 \t Validation precision@k30: 0.8389, accuracy@k30: 0.8389\n",
      "CPU: 22.68\n",
      "RAM %: 57.8\n",
      "Epoch: 92 \t Training Loss: 3.484804\n",
      "Epoch: 92 \t Validation precision@k5: 0.7039, accuracy@k5: 0.3659\n",
      "Epoch: 92 \t Validation precision@k10: 0.6598, accuracy@k10: 0.5543\n",
      "Epoch: 92 \t Validation precision@k15: 0.6919, accuracy@k15: 0.6651\n",
      "Epoch: 92 \t Validation precision@k20: 0.7447, accuracy@k20: 0.7401\n",
      "Epoch: 92 \t Validation precision@k25: 0.7962, accuracy@k25: 0.7960\n",
      "Epoch: 92 \t Validation precision@k30: 0.8393, accuracy@k30: 0.8393\n",
      "CPU: 22.66\n",
      "RAM %: 57.7\n",
      "Epoch: 93 \t Training Loss: 3.484257\n",
      "Epoch: 93 \t Validation precision@k5: 0.7079, accuracy@k5: 0.3682\n",
      "Epoch: 93 \t Validation precision@k10: 0.6617, accuracy@k10: 0.5556\n",
      "Epoch: 93 \t Validation precision@k15: 0.6940, accuracy@k15: 0.6669\n",
      "Epoch: 93 \t Validation precision@k20: 0.7466, accuracy@k20: 0.7419\n",
      "Epoch: 93 \t Validation precision@k25: 0.7955, accuracy@k25: 0.7952\n",
      "Epoch: 93 \t Validation precision@k30: 0.8377, accuracy@k30: 0.8377\n",
      "CPU: 22.71\n",
      "RAM %: 57.8\n",
      "Epoch: 94 \t Training Loss: 3.484591\n",
      "Epoch: 94 \t Validation precision@k5: 0.7079, accuracy@k5: 0.3684\n",
      "Epoch: 94 \t Validation precision@k10: 0.6586, accuracy@k10: 0.5526\n",
      "Epoch: 94 \t Validation precision@k15: 0.6941, accuracy@k15: 0.6671\n",
      "Epoch: 94 \t Validation precision@k20: 0.7446, accuracy@k20: 0.7401\n",
      "Epoch: 94 \t Validation precision@k25: 0.7958, accuracy@k25: 0.7956\n",
      "Epoch: 94 \t Validation precision@k30: 0.8372, accuracy@k30: 0.8372\n",
      "CPU: 22.68\n",
      "RAM %: 57.7\n",
      "Epoch: 95 \t Training Loss: 3.484833\n",
      "Epoch: 95 \t Validation precision@k5: 0.7104, accuracy@k5: 0.3694\n",
      "Epoch: 95 \t Validation precision@k10: 0.6625, accuracy@k10: 0.5561\n",
      "Epoch: 95 \t Validation precision@k15: 0.6928, accuracy@k15: 0.6660\n",
      "Epoch: 95 \t Validation precision@k20: 0.7472, accuracy@k20: 0.7427\n",
      "Epoch: 95 \t Validation precision@k25: 0.7955, accuracy@k25: 0.7952\n",
      "Epoch: 95 \t Validation precision@k30: 0.8380, accuracy@k30: 0.8380\n",
      "CPU: 22.62\n",
      "RAM %: 57.5\n",
      "Epoch: 96 \t Training Loss: 3.484283\n",
      "Epoch: 96 \t Validation precision@k5: 0.7107, accuracy@k5: 0.3694\n",
      "Epoch: 96 \t Validation precision@k10: 0.6602, accuracy@k10: 0.5542\n",
      "Epoch: 96 \t Validation precision@k15: 0.6945, accuracy@k15: 0.6676\n",
      "Epoch: 96 \t Validation precision@k20: 0.7466, accuracy@k20: 0.7419\n",
      "Epoch: 96 \t Validation precision@k25: 0.7948, accuracy@k25: 0.7945\n",
      "Epoch: 96 \t Validation precision@k30: 0.8379, accuracy@k30: 0.8379\n",
      "CPU: 22.62\n",
      "RAM %: 57.5\n",
      "Epoch: 97 \t Training Loss: 3.484347\n",
      "Epoch: 97 \t Validation precision@k5: 0.7045, accuracy@k5: 0.3663\n",
      "Epoch: 97 \t Validation precision@k10: 0.6609, accuracy@k10: 0.5550\n",
      "Epoch: 97 \t Validation precision@k15: 0.6936, accuracy@k15: 0.6665\n",
      "Epoch: 97 \t Validation precision@k20: 0.7447, accuracy@k20: 0.7401\n",
      "Epoch: 97 \t Validation precision@k25: 0.7958, accuracy@k25: 0.7956\n",
      "Epoch: 97 \t Validation precision@k30: 0.8381, accuracy@k30: 0.8381\n",
      "CPU: 22.60\n",
      "RAM %: 57.7\n",
      "Epoch: 98 \t Training Loss: 3.484439\n",
      "Epoch: 98 \t Validation precision@k5: 0.7072, accuracy@k5: 0.3674\n",
      "Epoch: 98 \t Validation precision@k10: 0.6594, accuracy@k10: 0.5537\n",
      "Epoch: 98 \t Validation precision@k15: 0.6932, accuracy@k15: 0.6663\n",
      "Epoch: 98 \t Validation precision@k20: 0.7439, accuracy@k20: 0.7392\n",
      "Epoch: 98 \t Validation precision@k25: 0.7957, accuracy@k25: 0.7954\n",
      "Epoch: 98 \t Validation precision@k30: 0.8391, accuracy@k30: 0.8391\n",
      "CPU: 22.76\n",
      "RAM %: 57.8\n",
      "Epoch: 99 \t Training Loss: 3.484065\n",
      "Epoch: 99 \t Validation precision@k5: 0.7116, accuracy@k5: 0.3694\n",
      "Epoch: 99 \t Validation precision@k10: 0.6590, accuracy@k10: 0.5533\n",
      "Epoch: 99 \t Validation precision@k15: 0.6924, accuracy@k15: 0.6657\n",
      "Epoch: 99 \t Validation precision@k20: 0.7454, accuracy@k20: 0.7408\n",
      "Epoch: 99 \t Validation precision@k25: 0.7950, accuracy@k25: 0.7947\n",
      "Epoch: 99 \t Validation precision@k30: 0.8378, accuracy@k30: 0.8378\n",
      "CPU: 22.73\n",
      "RAM %: 57.7\n",
      "Epoch: 100 \t Training Loss: 3.484170\n",
      "Epoch: 100 \t Validation precision@k5: 0.7059, accuracy@k5: 0.3674\n",
      "Epoch: 100 \t Validation precision@k10: 0.6620, accuracy@k10: 0.5553\n",
      "Epoch: 100 \t Validation precision@k15: 0.6940, accuracy@k15: 0.6671\n",
      "Epoch: 100 \t Validation precision@k20: 0.7466, accuracy@k20: 0.7420\n",
      "Epoch: 100 \t Validation precision@k25: 0.7967, accuracy@k25: 0.7964\n",
      "Epoch: 100 \t Validation precision@k30: 0.8381, accuracy@k30: 0.8381\n",
      "CPU: 22.67\n",
      "RAM %: 57.7\n",
      "Max CPU usage: 22.7569580078125\tMax RAM usage: 57.8\n",
      "CPU times: user 8min 18s, sys: 1min 51s, total: 10min 9s\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "%time train(baseline_mlp, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d43a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation precision@k5: 0.6879, accuracy@k5: 0.3490\n",
      "Validation precision@k10: 0.6526, accuracy@k10: 0.5466\n",
      "Validation precision@k15: 0.6849, accuracy@k15: 0.6604\n",
      "Validation precision@k20: 0.7417, accuracy@k20: 0.7379\n",
      "Validation precision@k25: 0.7922, accuracy@k25: 0.7920\n",
      "Validation precision@k30: 0.8375, accuracy@k30: 0.8375\n"
     ]
    }
   ],
   "source": [
    "for k in range(5, 31, 5):\n",
    "    precision_k, accuracy_k = eval_model(baseline_mlp, test_loader, k=k)\n",
    "    print(f'Validation precision@k{k}: {precision_k:.4f}, accuracy@k{k}: {accuracy_k:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2c8764",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(baseline_mlp, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CHECKPOINT_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaselineMLP_100.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(baseline_mlp, os.path.join(CHECKPOINT_PATH, \"BaselineMLP_100.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccc030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4h",
   "language": "python",
   "name": "dl4h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
