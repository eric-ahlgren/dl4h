{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1a324384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "31efc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_DATA_PATH = \"/Users/ericahlgren/Documents/UIUC/CS598/Project/data/mimic-iii-clinical-database-1.4\"\n",
    "ICU_CSV = \"icu_diag_merge.csv\"\n",
    "OUTPUT_TEXT = \"data/icd_long_title.txt\"\n",
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7aac7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_df = pd.read_csv(os.path.join(MIMIC_DATA_PATH, ICU_CSV))\n",
    "targs = pickle.load(open(os.path.join(DATA_PATH,'targets.pkl'), 'rb'))\n",
    "seqs = pickle.load(open(os.path.join(DATA_PATH,'text_seqs.pkl'), 'rb'))\n",
    "num_seqs = pickle.load(open(os.path.join(DATA_PATH,'seqs.pkl'), 'rb'))\n",
    "codes = pickle.load(open(os.path.join(DATA_PATH,'icd9.pkl'), 'rb'))\n",
    "text = pickle.load(open(os.path.join(DATA_PATH,'icd9_text.pkl'), 'rb'))\n",
    "categories = pickle.load(open(os.path.join(DATA_PATH,'categories.pkl'), 'rb'))\n",
    "sub_categories = pickle.load(open(os.path.join(DATA_PATH,'subcategories.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4a61bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_df.to_csv(OUTPUT_TEXT, columns=[\"LONG_TITLE_REPL\"], header=False, index=False, sep='\\n')\n",
    "#icu_df.to_csv(OUTPUT_TEXT, columns=[\"ICD_SUBCATEGORY_DESC_REPL\"], header=False, index=False, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "addb0549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  3165\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:  142244 lr:  0.000000 avg.loss:  0.783721 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "ft_model = fasttext.train_unsupervised(OUTPUT_TEXT, model='skipgram', dim=300, minCount=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c3069c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, text):\n",
    "\n",
    "        self.x = text\n",
    "        self.y = [i for i in range(len(text))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return(len(self.x))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return (self.x[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "58d1d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "77d7c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n",
    "        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "    \"\"\"\n",
    "    text, indices = zip(*data)\n",
    "    word_embed_dim = 300\n",
    "\n",
    "    y = torch.tensor(indices, dtype=torch.long)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    num_codes = len(text)\n",
    "    num_words = [len(words.split()) for words in text]\n",
    "\n",
    "    max_num_words = max(max(num_words), 4)\n",
    "\n",
    "    global ft_model\n",
    "#     x = torch.zeros((num_codes, word_embed_dim * max_num_words), dtype=torch.float)\n",
    "#     x_masks = torch.zeros((num_codes, word_embed_dim * max_num_words), dtype=torch.bool)\n",
    "#     for i, code in enumerate(text):\n",
    "#         for j, word in enumerate(code.split()):\n",
    "#             word_embed = ft_model[word]\n",
    "#             x[i, j*300:j*300+300] = torch.tensor(word_embed, dtype=torch.float)\n",
    "#             x_masks[i, j*300:j*300+300] = 1\n",
    "    x = torch.zeros((num_codes, max_num_words, word_embed_dim), dtype=torch.float)\n",
    "    x_masks = torch.zeros((num_codes, max_num_words, word_embed_dim), dtype=torch.bool)\n",
    "    for i, code in enumerate(text):\n",
    "        for j, word in enumerate(code.split()):\n",
    "            word_embed = ft_model[word]\n",
    "            x[i,j] = torch.tensor(word_embed, dtype=torch.float)\n",
    "            x_masks[i,j] = torch.ones(word_embed_dim)\n",
    "\n",
    "    \n",
    "    return x, y, x_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a8dc4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dataset, collate_fn):\n",
    "    \n",
    "    '''\n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader: train and validation dataloaders\n",
    "    \n",
    "    Note that you need to pass the collate function to the data loader `collate_fn()`.\n",
    "    '''\n",
    "    \n",
    "    batch_size = 100\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               collate_fn=collate_fn,\n",
    "                                               shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=4903,\n",
    "                                               collate_fn=collate_fn,\n",
    "                                               shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader = load_data(dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "846866e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_conv2d(outputs, masks):\n",
    "    masks = masks.any(dim=2)\n",
    "    masks = masks.unsqueeze(1)\n",
    "    masks = masks.repeat(1,100,1)\n",
    "    x = []\n",
    "    for mat in outputs:\n",
    "        outmat = mat.clone()\n",
    "        dim = outmat.shape[2]\n",
    "        outmat[~masks[:,:,:dim]] = 0\n",
    "        x.append(outmat)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bfcde57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingCNN(\n",
       "  (embed): Embedding(4903, 300)\n",
       "  (conv1): Conv2d(1, 100, kernel_size=(2, 300), stride=(1, 1))\n",
       "  (conv2): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "  (conv3): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(2, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=300, out_features=4903, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingCNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_descriptions, embedding_dim, num_class, num_kernel, kernel_sizes):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            hidden_dim: the hidden dimension\n",
    "        \"\"\"\n",
    "        self.embed = nn.Embedding(num_descriptions, embedding_dim)\n",
    "        self.conv1 = nn.Conv2d(1, num_kernel, (2, embedding_dim))\n",
    "        self.conv2 = nn.Conv2d(1, num_kernel, (3, embedding_dim))\n",
    "        self.conv3 = nn.Conv2d(1, num_kernel, (4, embedding_dim))\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, num_kernel, (K, embedding_dim)) for K in kernel_sizes]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * num_kernel, num_descriptions)\n",
    "\n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            g: the output tensor from RNN-alpha of shape (batch_size, seq_length, hidden_dim) \n",
    "        \n",
    "        Outputs:\n",
    "            alpha: the corresponding attention weights of shape (batch_size, seq_length, 1)\n",
    "        \"\"\"\n",
    "#         import pdb; pdb.set_trace()\n",
    "#         x = self.embed(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = mask_conv2d(x, masks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "        x = torch.cat(x, 1)\n",
    "        x_train = self.dropout(x)\n",
    "        logit = self.fc(x_train)\n",
    "        return logit, x\n",
    "\n",
    "embedding_cnn = EmbeddingCNN(\n",
    "    num_descriptions=len(codes), embedding_dim=300, num_class=len(codes),\n",
    "    num_kernel=100, kernel_sizes=[2,3,4])\n",
    "embedding_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "32fa97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(embedding_cnn.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.Adadelta(baseline_retain.parameters(), weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e991d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, n_epochs, n_class):\n",
    "    \"\"\" \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    #base_cpu, base_ram = print_cpu_usage()\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for feature, target, masks in train_loader:\n",
    "#             import pdb; pdb.set_trace()\n",
    "            optimizer.zero_grad()\n",
    "            logit, embedding = model(feature, masks)\n",
    "\n",
    "#             y_mh = indices_to_multihot(target, masks, logit)\n",
    "#             y_hat = F.one_hot(target, n_class)\n",
    "            loss = criterion(logit, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print(f'Epoch: {epoch+1} \\t Training Loss: {train_loss:.6f}')\n",
    "#         eval_model(model, train_loader)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "03f1f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        val_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall precision score\n",
    "        recall: overall recall score\n",
    "        f1: overall f1 score\n",
    "        roc_auc: overall roc_auc score\n",
    "        \n",
    "    \"\"\"\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    all_precision = []\n",
    "    all_accuracy = []\n",
    "    \n",
    "    model.eval()\n",
    "#     import pdb; pdb.set_trace()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_total = 0\n",
    "        for feature, target, masks in test_loader:\n",
    "            logit, embedding = model(feature, masks)\n",
    "            y_hat = F.softmax(logit, dim=-1)\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            n_correct += (pred == target).sum()\n",
    "            n_total += pred.shape[0]\n",
    "        success = n_correct / n_total\n",
    "        print(f'{n_correct}/{n_total} correct \\t success rate: {success:.4f}')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1256cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_multihot(indices, masks, y_hat):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    #indices = indices[masks.any(dim=1)]\n",
    "    multihot = torch.zeros_like(y_hat, dtype=torch.float)\n",
    "    for idx, row in enumerate(indices):\n",
    "        y_idx = row[masks[idx]].unique()\n",
    "        multihot[idx] = F.one_hot(y_idx, y_hat.shape[1]).sum(0).float()\n",
    "    return multihot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6d4af40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4695, 4555, 4691], [4695, 4555, 4691]]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "972345ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 8.448616\n",
      "Epoch: 2 \t Training Loss: 8.132655\n",
      "Epoch: 3 \t Training Loss: 7.329388\n",
      "Epoch: 4 \t Training Loss: 5.963246\n",
      "Epoch: 5 \t Training Loss: 4.663459\n",
      "Epoch: 6 \t Training Loss: 3.687683\n",
      "Epoch: 7 \t Training Loss: 2.982101\n",
      "Epoch: 8 \t Training Loss: 2.478072\n",
      "Epoch: 9 \t Training Loss: 2.076313\n",
      "Epoch: 10 \t Training Loss: 1.887517\n",
      "Epoch: 11 \t Training Loss: 1.640090\n",
      "Epoch: 12 \t Training Loss: 1.481388\n",
      "Epoch: 13 \t Training Loss: 1.353482\n",
      "Epoch: 14 \t Training Loss: 1.239966\n",
      "Epoch: 15 \t Training Loss: 1.158452\n",
      "Epoch: 16 \t Training Loss: 1.039990\n",
      "Epoch: 17 \t Training Loss: 1.017113\n",
      "Epoch: 18 \t Training Loss: 0.959317\n",
      "Epoch: 19 \t Training Loss: 0.884966\n",
      "Epoch: 20 \t Training Loss: 0.922540\n",
      "Epoch: 21 \t Training Loss: 0.804284\n",
      "Epoch: 22 \t Training Loss: 0.732477\n",
      "Epoch: 23 \t Training Loss: 0.698252\n",
      "Epoch: 24 \t Training Loss: 0.651712\n",
      "Epoch: 25 \t Training Loss: 0.644411\n",
      "Epoch: 26 \t Training Loss: 0.615422\n",
      "Epoch: 27 \t Training Loss: 0.579622\n",
      "Epoch: 28 \t Training Loss: 0.560954\n",
      "Epoch: 29 \t Training Loss: 0.567301\n",
      "Epoch: 30 \t Training Loss: 0.550339\n",
      "Epoch: 31 \t Training Loss: 0.523084\n",
      "Epoch: 32 \t Training Loss: 0.509747\n",
      "Epoch: 33 \t Training Loss: 0.488334\n",
      "Epoch: 34 \t Training Loss: 0.487382\n",
      "Epoch: 35 \t Training Loss: 0.428451\n",
      "Epoch: 36 \t Training Loss: 0.450395\n",
      "Epoch: 37 \t Training Loss: 0.396846\n",
      "Epoch: 38 \t Training Loss: 0.389765\n",
      "Epoch: 39 \t Training Loss: 0.381493\n",
      "Epoch: 40 \t Training Loss: 0.385567\n",
      "Epoch: 41 \t Training Loss: 0.404224\n",
      "Epoch: 42 \t Training Loss: 0.366345\n",
      "Epoch: 43 \t Training Loss: 0.348484\n",
      "Epoch: 44 \t Training Loss: 0.340497\n",
      "Epoch: 45 \t Training Loss: 0.301883\n",
      "Epoch: 46 \t Training Loss: 0.287354\n",
      "Epoch: 47 \t Training Loss: 0.311369\n",
      "Epoch: 48 \t Training Loss: 0.313560\n",
      "Epoch: 49 \t Training Loss: 0.296884\n",
      "Epoch: 50 \t Training Loss: 0.271815\n",
      "Epoch: 51 \t Training Loss: 0.269748\n",
      "Epoch: 52 \t Training Loss: 0.255972\n",
      "Epoch: 53 \t Training Loss: 0.243910\n",
      "Epoch: 54 \t Training Loss: 0.264422\n",
      "Epoch: 55 \t Training Loss: 0.257031\n",
      "Epoch: 56 \t Training Loss: 0.233983\n",
      "Epoch: 57 \t Training Loss: 0.256742\n",
      "Epoch: 58 \t Training Loss: 0.240676\n",
      "Epoch: 59 \t Training Loss: 0.268992\n",
      "Epoch: 60 \t Training Loss: 0.255186\n",
      "Epoch: 61 \t Training Loss: 0.215958\n",
      "Epoch: 62 \t Training Loss: 0.192673\n",
      "Epoch: 63 \t Training Loss: 0.257753\n",
      "Epoch: 64 \t Training Loss: 0.237756\n",
      "Epoch: 65 \t Training Loss: 0.197080\n",
      "Epoch: 66 \t Training Loss: 0.201494\n",
      "Epoch: 67 \t Training Loss: 0.195958\n",
      "Epoch: 68 \t Training Loss: 0.199415\n",
      "Epoch: 69 \t Training Loss: 0.202835\n",
      "Epoch: 70 \t Training Loss: 0.196521\n",
      "Epoch: 71 \t Training Loss: 0.200168\n",
      "Epoch: 72 \t Training Loss: 0.196843\n",
      "Epoch: 73 \t Training Loss: 0.181080\n",
      "Epoch: 74 \t Training Loss: 0.171158\n",
      "Epoch: 75 \t Training Loss: 0.171844\n",
      "Epoch: 76 \t Training Loss: 0.168061\n",
      "Epoch: 77 \t Training Loss: 0.205576\n",
      "Epoch: 78 \t Training Loss: 0.179707\n",
      "Epoch: 79 \t Training Loss: 0.157393\n",
      "Epoch: 80 \t Training Loss: 0.166239\n",
      "Epoch: 81 \t Training Loss: 0.152156\n",
      "Epoch: 82 \t Training Loss: 0.162165\n",
      "Epoch: 83 \t Training Loss: 0.142990\n",
      "Epoch: 84 \t Training Loss: 0.153405\n",
      "Epoch: 85 \t Training Loss: 0.142951\n",
      "Epoch: 86 \t Training Loss: 0.135196\n",
      "Epoch: 87 \t Training Loss: 0.129643\n",
      "Epoch: 88 \t Training Loss: 0.126497\n",
      "Epoch: 89 \t Training Loss: 0.125755\n",
      "Epoch: 90 \t Training Loss: 0.119696\n",
      "Epoch: 91 \t Training Loss: 0.131295\n",
      "Epoch: 92 \t Training Loss: 0.142815\n",
      "Epoch: 93 \t Training Loss: 0.160020\n",
      "Epoch: 94 \t Training Loss: 0.142418\n",
      "Epoch: 95 \t Training Loss: 0.139258\n",
      "Epoch: 96 \t Training Loss: 0.119609\n",
      "Epoch: 97 \t Training Loss: 0.127562\n",
      "Epoch: 98 \t Training Loss: 0.119410\n",
      "Epoch: 99 \t Training Loss: 0.112561\n",
      "Epoch: 100 \t Training Loss: 0.123899\n",
      "CPU times: user 11min 59s, sys: 1min 21s, total: 13min 21s\n",
      "Wall time: 10min 29s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "%time train(embedding_cnn, train_loader, n_epochs, len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "803336bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4840/4903 correct \t success rate: 0.9872\n"
     ]
    }
   ],
   "source": [
    "embedding = eval_model(embedding_cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "00da3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = embedding.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "87286abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0415, 0.0000,  ..., 2.1525, 2.3754, 0.0000],\n",
       "        [0.0000, 0.9073, 0.9623,  ..., 0.0000, 0.2491, 0.0000],\n",
       "        [2.2889, 1.4867, 0.4477,  ..., 5.4431, 2.1662, 0.8727],\n",
       "        ...,\n",
       "        [2.3640, 1.5446, 0.0000,  ..., 2.2595, 1.3269, 0.0000],\n",
       "        [0.3830, 1.6254, 0.8770,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38338927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 4903])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1a694216",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(E1, os.path.join(DATA_PATH, 'embedding_matrix.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d7abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4h",
   "language": "python",
   "name": "dl4h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
