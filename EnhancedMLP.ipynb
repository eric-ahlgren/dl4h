{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07324f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define data path\n",
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1156a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = pickle.load(open(os.path.join(DATA_PATH,'pids.pkl'), 'rb'))\n",
    "vids = pickle.load(open(os.path.join(DATA_PATH,'vids.pkl'), 'rb'))\n",
    "targets = pickle.load(open(os.path.join(DATA_PATH,'targets.pkl'), 'rb'))\n",
    "prob_targets = pickle.load(open(os.path.join(DATA_PATH,'prob_targets.pkl'), 'rb'))\n",
    "prob_targets_allvisits = pickle.load(open(os.path.join(DATA_PATH,'prob_targets_allvisits.pkl'), 'rb'))\n",
    "seqs = pickle.load(open(os.path.join(DATA_PATH,'seqs.pkl'), 'rb'))\n",
    "diags = pickle.load(open(os.path.join(DATA_PATH,'diags.pkl'), 'rb'))\n",
    "categories = pickle.load(open(os.path.join(DATA_PATH,'categories.pkl'), 'rb'))\n",
    "sub_categories = pickle.load(open(os.path.join(DATA_PATH,'subcategories.pkl'), 'rb'))\n",
    "codes = pickle.load(open(os.path.join(DATA_PATH,'icd9.pkl'), 'rb'))\n",
    "assert len(pids) == len(vids) == len(targets) == len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadc956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.load(os.path.join(DATA_PATH, 'embedding_matrix.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4bc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, targets):\n",
    "        self.x = seqs\n",
    "        self.y = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.x))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206aa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(seqs, prob_targets_allvisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b5cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# total visits excluding last visit per patient, max # diagnosis codes) of type torch.long\n",
    "        x_masks: a tensor of shape (# total visits excluding last visit per patient, max # diagnosis codes) of type torch.bool\n",
    "        y: a tensor of shape (# total visits excluding first visit per patient, num higher level categories to predict) of type torch.float\n",
    "    \"\"\"\n",
    "    sequences, targets = zip(*data)\n",
    "\n",
    "#     y = torch.tensor(targets, dtype=torch.float)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "    num_categories = len(targets[0][0])\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    sum_visits = sum(num_visits)\n",
    "    \n",
    "    x = torch.zeros((sum_visits - num_patients, max_num_codes), dtype=torch.long)\n",
    "    y = torch.zeros((sum_visits - num_patients, num_categories), dtype=torch.float)\n",
    "    x_masks = torch.zeros((sum_visits - num_patients, max_num_codes), dtype=torch.bool)\n",
    "\n",
    "#     for i_patient, patient in enumerate(sequences):   \n",
    "#         for j_visit, visit in enumerate(patient):\n",
    "#             \"\"\"\n",
    "#             TODO: update `x`, `rev_x`, `masks`, and `rev_masks`\n",
    "#             \"\"\" \n",
    "#             x[i_patient, j_visit] = torch.Tensor(visit)\n",
    "#             #x_masks[i_patient, j_visit] = torch.Tensor(np.ones(num_codes, dtype=int))\n",
    "#             x_masks[i_patient, j_visit] = 1\n",
    "#     import pdb; pdb.set_trace()\n",
    "    n = 0\n",
    "    for i,patient in enumerate(sequences):\n",
    "        for j,visit in enumerate(patient):\n",
    "            if j == len(patient) - 1:\n",
    "                break\n",
    "            for k,code in enumerate(visit):\n",
    "                x[n,k] = code\n",
    "                x_masks[n,k] = 1\n",
    "            n+=1\n",
    "    n = 0\n",
    "    for i,patient in enumerate(targets):\n",
    "        for j,visit in enumerate(patient):\n",
    "            if j == len(patient) - 1:\n",
    "                break\n",
    "            y[n] = torch.tensor(patient[j+1])\n",
    "            n += 1\n",
    "    \n",
    "    \n",
    "    return x, x_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7834769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(len(dataset)*0.75)\n",
    "test_split = int(len(dataset)*0.15)\n",
    "val_split = int(len(dataset)*0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e400730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6561\n",
      "Length of test dataset: 1312\n",
      "Length of val dataset: 875\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_split = int(len(dataset)*0.75)\n",
    "test_split = int(len(dataset)*0.15)\n",
    "\n",
    "lengths = [train_split, test_split, len(dataset) - (train_split + test_split)]\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of test dataset:\", len(test_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e1a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, test_dataset, val_dataset, collate_fn):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        test dataset: test dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, test_loader, val_loader: train, test and validation dataloaders\n",
    "    '''\n",
    "    \n",
    "    batch_size = 100\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               collate_fn=collate_fn,\n",
    "                                               shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             collate_fn=collate_fn,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader, val_loader = load_data(train_dataset, test_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27668422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_embeddings_with_mask(x, masks):\n",
    "    \"\"\"\n",
    "    Mask select the embeddings for true visits (not padding visits) and then sum the embeddings for each visit up.\n",
    "\n",
    "    Arguments:\n",
    "        x: the embeddings of diagnosis sequence of shape (batch_size, # visits, # diagnosis codes, embedding_dim)\n",
    "        masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        sum_embeddings: the sum of embeddings of shape (batch_size, # visits, embedding_dim)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x * masks.unsqueeze(-1)\n",
    "    x = torch.sum(x, dim = -2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d1d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_multihot(indices, masks, dim):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #indices = indices[masks.any(dim=1)]\n",
    "    multihot = torch.zeros((indices.shape[0], dim), dtype=torch.float)\n",
    "    for idx, row in enumerate(indices):\n",
    "        y_idx = row[masks[idx]].unique()\n",
    "        multihot[idx] = F.one_hot(y_idx.to(torch.int64), multihot.shape[1]).sum(0)\n",
    "    return multihot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "637c36f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding.weight', Parameter containing:\n",
      "tensor([[0.1408, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0120],\n",
      "        [0.8244, 0.0000, 4.8920,  ..., 0.5002, 0.0000, 4.2985],\n",
      "        [1.4374, 0.2580, 0.1317,  ..., 2.3848, 2.0505, 0.0000],\n",
      "        ...,\n",
      "        [0.8518, 0.0000, 0.3237,  ..., 0.9934, 0.5658, 0.1184],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1696, 2.2176, 0.0000,  ..., 2.6231, 0.6750, 1.3424]],\n",
      "       requires_grad=True))\n",
      "('embedding.weight', Parameter containing:\n",
      "tensor([[0.1408, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0120],\n",
      "        [0.8244, 0.0000, 4.8920,  ..., 0.5002, 0.0000, 4.2985],\n",
      "        [1.4374, 0.2580, 0.1317,  ..., 2.3848, 2.0505, 0.0000],\n",
      "        ...,\n",
      "        [0.8518, 0.0000, 0.3237,  ..., 0.9934, 0.5658, 0.1184],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1696, 2.2176, 0.0000,  ..., 2.6231, 0.6750, 1.3424]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnhancedMLP(\n",
       "  (embedding): Linear(in_features=4903, out_features=300, bias=True)\n",
       "  (fc): Linear(in_features=300, out_features=184, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnhancedMLP(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_codes, num_categories, embedding_matrix):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            num_codes: total number of diagnosis codes\n",
    "            num_categories: number of higher level categories to predict\n",
    "            embedding_matrix: learned embedding matrix of icd9 descriptions\n",
    "        \"\"\"\n",
    "#         self.padding_idx = 0\n",
    "        \n",
    "        #self.embedding = nn.Embedding(num_codes, embedding_dim=128, padding_idx=0)\n",
    "        self.embedding = nn.Linear(4903, 300)\n",
    "        self.embedding.weight.data = embedding_matrix\n",
    "        self.fc = nn.Linear(300, num_categories)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: the diagnosis sequence of shape (batch_size, # visits, # diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "        Outputs:\n",
    "            logits: logits of shape (batch_size, # diagnosis codes)\n",
    "        \"\"\"\n",
    "#         import pdb; pdb.set_trace()\n",
    "#         num_codes = self.embedding.weight.shape[0]\n",
    "#         x = indices_to_multihot(x, masks, num_codes)\n",
    "#         x[~masks] = self.padding_idx\n",
    "#         x[masks] += 1\n",
    "        x = indices_to_multihot(x, masks, 4903)\n",
    "        x = self.embedding(x)\n",
    "        x = torch.tanh(x)\n",
    "#         x = x.sum(dim=1)\n",
    "        #x = sum_embeddings_with_mask(x, masks)\n",
    "        logits = self.fc(x)\n",
    "#         logits = logits.mean(dim=1)\n",
    "#         probs = self.softmax(logits)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# load the model here, set embedding_matrix to requires_grad=False (only learn bias vector)\n",
    "enhanced_mlp = EnhancedMLP(num_codes = len(codes), num_categories=len(sub_categories), embedding_matrix=embedding_matrix)\n",
    "for param in enhanced_mlp.named_parameters():\n",
    "    if param[0] == \"embedding.weight\":\n",
    "        print(param)\n",
    "        param[1].requires_grad = False\n",
    "        print(param)\n",
    "enhanced_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375a279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(baseline_mlp.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adadelta(enhanced_mlp.parameters(), weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, k=15, n=-1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model: the EnhancedMLP model\n",
    "        test_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        precision_k: visit-level precison@k\n",
    "        accuracy_k: code-level accuracy@k\n",
    "    \"\"\"\n",
    "    y_pred = torch.LongTensor()\n",
    "#     y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    all_precision = []\n",
    "    all_accuracy = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, masks, y in test_loader:\n",
    "#             import pdb; pdb.set_trace()\n",
    "            n_eval = y.shape[0] - 1 if n == -1 else n\n",
    "            y_hat = model(x, masks)\n",
    "            y_hat = F.softmax(y_hat, dim=-1)\n",
    "#             num_labels = y_hat.shape[1]\n",
    "#             num_categories = torch.count_nonzero(y, dim=1)\n",
    "            nz_rows, nz_cols = torch.nonzero(y, as_tuple=True)\n",
    "            k_correct = 0\n",
    "#             predictions = 0\n",
    "            total_precision = 0\n",
    "            total_accuracy = 0\n",
    "            for i in range(n_eval):\n",
    "                visit_correct = 0\n",
    "                y_true = nz_cols[nz_rows == i]\n",
    "                _, y_pred = torch.topk(y_hat[i], k)\n",
    "#                 for v in y_pred:\n",
    "#                     if v in y_true:\n",
    "#                         visit_correct += 1\n",
    "                for v in y_true:\n",
    "                    if v in y_pred:\n",
    "                        visit_correct += 1\n",
    "#                 predictions += len(y_true)\n",
    "                visit_precision = visit_correct / min(k, len(y_true))\n",
    "                visit_accuracy = visit_correct / len(y_true)\n",
    "                #print(f'visit {i}: precision: {visit_precision:0.2f} accuracy: {visit_accuracy:0.2f}')\n",
    "                k_correct += visit_correct\n",
    "                total_precision += visit_precision\n",
    "                total_accuracy += visit_accuracy\n",
    "            #import pdb; pdb.set_trace()\n",
    "#             precision_k = precision / k\n",
    "#             accuracy_k = k_correct / predictions\n",
    "            precision_k = total_precision / n_eval\n",
    "            accuracy_k = total_accuracy / n_eval\n",
    "            all_precision.append(precision_k)\n",
    "            all_accuracy.append(accuracy_k)\n",
    "            \n",
    "#             y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
    "#             y_hat = (y_hat > 0.5).int()\n",
    "#             y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "#             y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    total_precision_k = np.mean(all_precision)\n",
    "    total_accuracy_k = np.mean(all_accuracy)\n",
    "    return total_precision_k, total_accuracy_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a85ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    base_cpu, base_ram = print_cpu_usage()\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for x, masks, y in train_loader:\n",
    "\n",
    "            y_hat = model(x, masks)\n",
    "#             mask_idxs = masks.sum(dim=1) - 1\n",
    "#             y_hat = y_hat[range(len(masks)), mask_idxs]\n",
    "            loss = criterion(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print_cpu_usage()\n",
    "        print(f'Epoch: {epoch+1} \\t Training Loss: {train_loss:.6f}')\n",
    "        for k in range(5, 31, 5):\n",
    "            precision_k, accuracy_k = eval_model(model, test_loader, k=k)\n",
    "            print(f'Epoch: {epoch+1} \\t Validation precision@k{k}: {precision_k:.4f}, accuracy@k{k}: {accuracy_k:.4f}')\n",
    "    final_cpu, final_ram = print_cpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3097025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cpu_usage():\n",
    "    load = psutil.getloadavg()[2]\n",
    "    cpu_usage = (load/os.cpu_count()) * 100\n",
    "    ram = psutil.virtual_memory()[2]\n",
    "    print(f\"CPU: {cpu_usage:0.2f}\")\n",
    "    print(f\"RAM %: {ram}\")\n",
    "    return cpu_usage, ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1800d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 20.61\n",
      "RAM %: 65.0\n",
      "CPU: 20.68\n",
      "RAM %: 65.0\n",
      "Epoch: 1 \t Training Loss: 4.020759\n",
      "Epoch: 1 \t Validation precision@k5: 0.4250, accuracy@k5: 0.2092\n",
      "Epoch: 1 \t Validation precision@k10: 0.4575, accuracy@k10: 0.3798\n",
      "Epoch: 1 \t Validation precision@k15: 0.5303, accuracy@k15: 0.5113\n",
      "Epoch: 1 \t Validation precision@k20: 0.5996, accuracy@k20: 0.5969\n",
      "Epoch: 1 \t Validation precision@k25: 0.6772, accuracy@k25: 0.6770\n",
      "Epoch: 1 \t Validation precision@k30: 0.7372, accuracy@k30: 0.7372\n",
      "CPU: 20.91\n",
      "RAM %: 65.0\n",
      "Epoch: 2 \t Training Loss: 3.972974\n",
      "Epoch: 2 \t Validation precision@k5: 0.4807, accuracy@k5: 0.2372\n",
      "Epoch: 2 \t Validation precision@k10: 0.4761, accuracy@k10: 0.3974\n",
      "Epoch: 2 \t Validation precision@k15: 0.5397, accuracy@k15: 0.5213\n",
      "Epoch: 2 \t Validation precision@k20: 0.6237, accuracy@k20: 0.6209\n",
      "Epoch: 2 \t Validation precision@k25: 0.6743, accuracy@k25: 0.6742\n",
      "Epoch: 2 \t Validation precision@k30: 0.7389, accuracy@k30: 0.7389\n",
      "CPU: 21.00\n",
      "RAM %: 64.8\n",
      "Epoch: 3 \t Training Loss: 3.966880\n",
      "Epoch: 3 \t Validation precision@k5: 0.4284, accuracy@k5: 0.2108\n",
      "Epoch: 3 \t Validation precision@k10: 0.4681, accuracy@k10: 0.3919\n",
      "Epoch: 3 \t Validation precision@k15: 0.5415, accuracy@k15: 0.5232\n",
      "Epoch: 3 \t Validation precision@k20: 0.6266, accuracy@k20: 0.6240\n",
      "Epoch: 3 \t Validation precision@k25: 0.6966, accuracy@k25: 0.6965\n",
      "Epoch: 3 \t Validation precision@k30: 0.7571, accuracy@k30: 0.7571\n",
      "CPU: 20.94\n",
      "RAM %: 64.7\n",
      "Epoch: 4 \t Training Loss: 3.956502\n",
      "Epoch: 4 \t Validation precision@k5: 0.5143, accuracy@k5: 0.2511\n",
      "Epoch: 4 \t Validation precision@k10: 0.4953, accuracy@k10: 0.4135\n",
      "Epoch: 4 \t Validation precision@k15: 0.5420, accuracy@k15: 0.5234\n",
      "Epoch: 4 \t Validation precision@k20: 0.6021, accuracy@k20: 0.5995\n",
      "Epoch: 4 \t Validation precision@k25: 0.6699, accuracy@k25: 0.6698\n",
      "Epoch: 4 \t Validation precision@k30: 0.7468, accuracy@k30: 0.7468\n",
      "CPU: 20.98\n",
      "RAM %: 64.7\n",
      "Epoch: 5 \t Training Loss: 3.944258\n",
      "Epoch: 5 \t Validation precision@k5: 0.4846, accuracy@k5: 0.2384\n",
      "Epoch: 5 \t Validation precision@k10: 0.4815, accuracy@k10: 0.4029\n",
      "Epoch: 5 \t Validation precision@k15: 0.5397, accuracy@k15: 0.5208\n",
      "Epoch: 5 \t Validation precision@k20: 0.6149, accuracy@k20: 0.6122\n",
      "Epoch: 5 \t Validation precision@k25: 0.6938, accuracy@k25: 0.6937\n",
      "Epoch: 5 \t Validation precision@k30: 0.7498, accuracy@k30: 0.7498\n",
      "CPU: 21.00\n",
      "RAM %: 64.9\n",
      "Epoch: 6 \t Training Loss: 3.942393\n",
      "Epoch: 6 \t Validation precision@k5: 0.4462, accuracy@k5: 0.2232\n",
      "Epoch: 6 \t Validation precision@k10: 0.4533, accuracy@k10: 0.3791\n",
      "Epoch: 6 \t Validation precision@k15: 0.5417, accuracy@k15: 0.5232\n",
      "Epoch: 6 \t Validation precision@k20: 0.6158, accuracy@k20: 0.6131\n",
      "Epoch: 6 \t Validation precision@k25: 0.6849, accuracy@k25: 0.6848\n",
      "Epoch: 6 \t Validation precision@k30: 0.7506, accuracy@k30: 0.7506\n",
      "CPU: 21.12\n",
      "RAM %: 65.0\n",
      "Epoch: 7 \t Training Loss: 3.933478\n",
      "Epoch: 7 \t Validation precision@k5: 0.4908, accuracy@k5: 0.2453\n",
      "Epoch: 7 \t Validation precision@k10: 0.4765, accuracy@k10: 0.4011\n",
      "Epoch: 7 \t Validation precision@k15: 0.5394, accuracy@k15: 0.5219\n",
      "Epoch: 7 \t Validation precision@k20: 0.6211, accuracy@k20: 0.6185\n",
      "Epoch: 7 \t Validation precision@k25: 0.6887, accuracy@k25: 0.6886\n",
      "Epoch: 7 \t Validation precision@k30: 0.7510, accuracy@k30: 0.7510\n",
      "CPU: 21.41\n",
      "RAM %: 65.0\n",
      "Epoch: 8 \t Training Loss: 3.922964\n",
      "Epoch: 8 \t Validation precision@k5: 0.4580, accuracy@k5: 0.2240\n",
      "Epoch: 8 \t Validation precision@k10: 0.4816, accuracy@k10: 0.4042\n",
      "Epoch: 8 \t Validation precision@k15: 0.5489, accuracy@k15: 0.5301\n",
      "Epoch: 8 \t Validation precision@k20: 0.6319, accuracy@k20: 0.6292\n",
      "Epoch: 8 \t Validation precision@k25: 0.6993, accuracy@k25: 0.6992\n",
      "Epoch: 8 \t Validation precision@k30: 0.7602, accuracy@k30: 0.7602\n",
      "CPU: 21.51\n",
      "RAM %: 64.9\n",
      "Epoch: 9 \t Training Loss: 3.921559\n",
      "Epoch: 9 \t Validation precision@k5: 0.4893, accuracy@k5: 0.2479\n",
      "Epoch: 9 \t Validation precision@k10: 0.4735, accuracy@k10: 0.3983\n",
      "Epoch: 9 \t Validation precision@k15: 0.5378, accuracy@k15: 0.5191\n",
      "Epoch: 9 \t Validation precision@k20: 0.6176, accuracy@k20: 0.6149\n",
      "Epoch: 9 \t Validation precision@k25: 0.6880, accuracy@k25: 0.6879\n",
      "Epoch: 9 \t Validation precision@k30: 0.7443, accuracy@k30: 0.7443\n",
      "CPU: 21.65\n",
      "RAM %: 65.0\n",
      "Epoch: 10 \t Training Loss: 3.914127\n",
      "Epoch: 10 \t Validation precision@k5: 0.4208, accuracy@k5: 0.2072\n",
      "Epoch: 10 \t Validation precision@k10: 0.4584, accuracy@k10: 0.3838\n",
      "Epoch: 10 \t Validation precision@k15: 0.5462, accuracy@k15: 0.5282\n",
      "Epoch: 10 \t Validation precision@k20: 0.6417, accuracy@k20: 0.6390\n",
      "Epoch: 10 \t Validation precision@k25: 0.7088, accuracy@k25: 0.7086\n",
      "Epoch: 10 \t Validation precision@k30: 0.7590, accuracy@k30: 0.7590\n",
      "CPU: 21.62\n",
      "RAM %: 64.5\n",
      "Epoch: 11 \t Training Loss: 3.911540\n",
      "Epoch: 11 \t Validation precision@k5: 0.4525, accuracy@k5: 0.2240\n",
      "Epoch: 11 \t Validation precision@k10: 0.4767, accuracy@k10: 0.4013\n",
      "Epoch: 11 \t Validation precision@k15: 0.5417, accuracy@k15: 0.5234\n",
      "Epoch: 11 \t Validation precision@k20: 0.6220, accuracy@k20: 0.6193\n",
      "Epoch: 11 \t Validation precision@k25: 0.6871, accuracy@k25: 0.6869\n",
      "Epoch: 11 \t Validation precision@k30: 0.7578, accuracy@k30: 0.7578\n",
      "CPU: 21.56\n",
      "RAM %: 64.9\n",
      "Epoch: 12 \t Training Loss: 3.907101\n",
      "Epoch: 12 \t Validation precision@k5: 0.5004, accuracy@k5: 0.2509\n",
      "Epoch: 12 \t Validation precision@k10: 0.4761, accuracy@k10: 0.3998\n",
      "Epoch: 12 \t Validation precision@k15: 0.5422, accuracy@k15: 0.5232\n",
      "Epoch: 12 \t Validation precision@k20: 0.6244, accuracy@k20: 0.6216\n",
      "Epoch: 12 \t Validation precision@k25: 0.7013, accuracy@k25: 0.7011\n",
      "Epoch: 12 \t Validation precision@k30: 0.7545, accuracy@k30: 0.7545\n",
      "CPU: 21.56\n",
      "RAM %: 65.0\n",
      "Epoch: 13 \t Training Loss: 3.906144\n",
      "Epoch: 13 \t Validation precision@k5: 0.4731, accuracy@k5: 0.2388\n",
      "Epoch: 13 \t Validation precision@k10: 0.4922, accuracy@k10: 0.4134\n",
      "Epoch: 13 \t Validation precision@k15: 0.5519, accuracy@k15: 0.5331\n",
      "Epoch: 13 \t Validation precision@k20: 0.6382, accuracy@k20: 0.6354\n",
      "Epoch: 13 \t Validation precision@k25: 0.7053, accuracy@k25: 0.7052\n",
      "Epoch: 13 \t Validation precision@k30: 0.7585, accuracy@k30: 0.7585\n",
      "CPU: 21.67\n",
      "RAM %: 64.9\n",
      "Epoch: 14 \t Training Loss: 3.899826\n",
      "Epoch: 14 \t Validation precision@k5: 0.4890, accuracy@k5: 0.2400\n",
      "Epoch: 14 \t Validation precision@k10: 0.4872, accuracy@k10: 0.4075\n",
      "Epoch: 14 \t Validation precision@k15: 0.5551, accuracy@k15: 0.5361\n",
      "Epoch: 14 \t Validation precision@k20: 0.6358, accuracy@k20: 0.6331\n",
      "Epoch: 14 \t Validation precision@k25: 0.7125, accuracy@k25: 0.7124\n",
      "Epoch: 14 \t Validation precision@k30: 0.7654, accuracy@k30: 0.7654\n",
      "CPU: 21.58\n",
      "RAM %: 65.0\n",
      "Epoch: 15 \t Training Loss: 3.899627\n",
      "Epoch: 15 \t Validation precision@k5: 0.4923, accuracy@k5: 0.2459\n",
      "Epoch: 15 \t Validation precision@k10: 0.4952, accuracy@k10: 0.4137\n",
      "Epoch: 15 \t Validation precision@k15: 0.5449, accuracy@k15: 0.5258\n",
      "Epoch: 15 \t Validation precision@k20: 0.6278, accuracy@k20: 0.6250\n",
      "Epoch: 15 \t Validation precision@k25: 0.7034, accuracy@k25: 0.7033\n",
      "Epoch: 15 \t Validation precision@k30: 0.7598, accuracy@k30: 0.7598\n",
      "CPU: 21.65\n",
      "RAM %: 64.7\n",
      "Epoch: 16 \t Training Loss: 3.892507\n",
      "Epoch: 16 \t Validation precision@k5: 0.4974, accuracy@k5: 0.2508\n",
      "Epoch: 16 \t Validation precision@k10: 0.5009, accuracy@k10: 0.4195\n",
      "Epoch: 16 \t Validation precision@k15: 0.5396, accuracy@k15: 0.5210\n",
      "Epoch: 16 \t Validation precision@k20: 0.6151, accuracy@k20: 0.6125\n",
      "Epoch: 16 \t Validation precision@k25: 0.6914, accuracy@k25: 0.6912\n",
      "Epoch: 16 \t Validation precision@k30: 0.7520, accuracy@k30: 0.7520\n",
      "CPU: 21.69\n",
      "RAM %: 64.8\n",
      "Epoch: 17 \t Training Loss: 3.892539\n",
      "Epoch: 17 \t Validation precision@k5: 0.4523, accuracy@k5: 0.2260\n",
      "Epoch: 17 \t Validation precision@k10: 0.4758, accuracy@k10: 0.3985\n",
      "Epoch: 17 \t Validation precision@k15: 0.5418, accuracy@k15: 0.5236\n",
      "Epoch: 17 \t Validation precision@k20: 0.6311, accuracy@k20: 0.6285\n",
      "Epoch: 17 \t Validation precision@k25: 0.7027, accuracy@k25: 0.7026\n",
      "Epoch: 17 \t Validation precision@k30: 0.7562, accuracy@k30: 0.7562\n",
      "CPU: 21.71\n",
      "RAM %: 64.8\n",
      "Epoch: 18 \t Training Loss: 3.891074\n",
      "Epoch: 18 \t Validation precision@k5: 0.4711, accuracy@k5: 0.2357\n",
      "Epoch: 18 \t Validation precision@k10: 0.4897, accuracy@k10: 0.4104\n",
      "Epoch: 18 \t Validation precision@k15: 0.5603, accuracy@k15: 0.5416\n",
      "Epoch: 18 \t Validation precision@k20: 0.6366, accuracy@k20: 0.6339\n",
      "Epoch: 18 \t Validation precision@k25: 0.7051, accuracy@k25: 0.7050\n",
      "Epoch: 18 \t Validation precision@k30: 0.7591, accuracy@k30: 0.7591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 21.85\n",
      "RAM %: 65.0\n",
      "Epoch: 19 \t Training Loss: 3.886271\n",
      "Epoch: 19 \t Validation precision@k5: 0.5118, accuracy@k5: 0.2583\n",
      "Epoch: 19 \t Validation precision@k10: 0.5080, accuracy@k10: 0.4262\n",
      "Epoch: 19 \t Validation precision@k15: 0.5591, accuracy@k15: 0.5403\n",
      "Epoch: 19 \t Validation precision@k20: 0.6296, accuracy@k20: 0.6269\n",
      "Epoch: 19 \t Validation precision@k25: 0.6955, accuracy@k25: 0.6953\n",
      "Epoch: 19 \t Validation precision@k30: 0.7565, accuracy@k30: 0.7565\n",
      "CPU: 21.85\n",
      "RAM %: 65.0\n",
      "Epoch: 20 \t Training Loss: 3.882404\n",
      "Epoch: 20 \t Validation precision@k5: 0.4461, accuracy@k5: 0.2275\n",
      "Epoch: 20 \t Validation precision@k10: 0.4925, accuracy@k10: 0.4129\n",
      "Epoch: 20 \t Validation precision@k15: 0.5541, accuracy@k15: 0.5356\n",
      "Epoch: 20 \t Validation precision@k20: 0.6268, accuracy@k20: 0.6242\n",
      "Epoch: 20 \t Validation precision@k25: 0.6882, accuracy@k25: 0.6881\n",
      "Epoch: 20 \t Validation precision@k30: 0.7418, accuracy@k30: 0.7418\n",
      "CPU: 21.84\n",
      "RAM %: 64.9\n",
      "Epoch: 21 \t Training Loss: 3.884828\n",
      "Epoch: 21 \t Validation precision@k5: 0.4754, accuracy@k5: 0.2366\n",
      "Epoch: 21 \t Validation precision@k10: 0.4966, accuracy@k10: 0.4163\n",
      "Epoch: 21 \t Validation precision@k15: 0.5598, accuracy@k15: 0.5410\n",
      "Epoch: 21 \t Validation precision@k20: 0.6374, accuracy@k20: 0.6346\n",
      "Epoch: 21 \t Validation precision@k25: 0.7076, accuracy@k25: 0.7075\n",
      "Epoch: 21 \t Validation precision@k30: 0.7617, accuracy@k30: 0.7617\n",
      "CPU: 21.84\n",
      "RAM %: 65.0\n",
      "Epoch: 22 \t Training Loss: 3.884854\n",
      "Epoch: 22 \t Validation precision@k5: 0.4588, accuracy@k5: 0.2319\n",
      "Epoch: 22 \t Validation precision@k10: 0.4588, accuracy@k10: 0.3867\n",
      "Epoch: 22 \t Validation precision@k15: 0.5424, accuracy@k15: 0.5243\n",
      "Epoch: 22 \t Validation precision@k20: 0.6380, accuracy@k20: 0.6353\n",
      "Epoch: 22 \t Validation precision@k25: 0.7051, accuracy@k25: 0.7050\n",
      "Epoch: 22 \t Validation precision@k30: 0.7507, accuracy@k30: 0.7507\n",
      "CPU: 21.84\n",
      "RAM %: 65.0\n",
      "Epoch: 23 \t Training Loss: 3.881471\n",
      "Epoch: 23 \t Validation precision@k5: 0.5000, accuracy@k5: 0.2519\n",
      "Epoch: 23 \t Validation precision@k10: 0.4983, accuracy@k10: 0.4193\n",
      "Epoch: 23 \t Validation precision@k15: 0.5617, accuracy@k15: 0.5431\n",
      "Epoch: 23 \t Validation precision@k20: 0.6391, accuracy@k20: 0.6363\n",
      "Epoch: 23 \t Validation precision@k25: 0.7110, accuracy@k25: 0.7109\n",
      "Epoch: 23 \t Validation precision@k30: 0.7597, accuracy@k30: 0.7597\n",
      "CPU: 21.89\n",
      "RAM %: 65.1\n",
      "Epoch: 24 \t Training Loss: 3.882565\n",
      "Epoch: 24 \t Validation precision@k5: 0.4960, accuracy@k5: 0.2499\n",
      "Epoch: 24 \t Validation precision@k10: 0.5000, accuracy@k10: 0.4195\n",
      "Epoch: 24 \t Validation precision@k15: 0.5641, accuracy@k15: 0.5450\n",
      "Epoch: 24 \t Validation precision@k20: 0.6402, accuracy@k20: 0.6375\n",
      "Epoch: 24 \t Validation precision@k25: 0.7004, accuracy@k25: 0.7002\n",
      "Epoch: 24 \t Validation precision@k30: 0.7564, accuracy@k30: 0.7564\n",
      "CPU: 21.85\n",
      "RAM %: 65.0\n",
      "Epoch: 25 \t Training Loss: 3.877448\n",
      "Epoch: 25 \t Validation precision@k5: 0.4589, accuracy@k5: 0.2310\n",
      "Epoch: 25 \t Validation precision@k10: 0.4713, accuracy@k10: 0.3955\n",
      "Epoch: 25 \t Validation precision@k15: 0.5542, accuracy@k15: 0.5357\n",
      "Epoch: 25 \t Validation precision@k20: 0.6334, accuracy@k20: 0.6306\n",
      "Epoch: 25 \t Validation precision@k25: 0.7059, accuracy@k25: 0.7058\n",
      "Epoch: 25 \t Validation precision@k30: 0.7620, accuracy@k30: 0.7620\n",
      "CPU: 21.85\n",
      "RAM %: 65.0\n",
      "Epoch: 26 \t Training Loss: 3.874903\n",
      "Epoch: 26 \t Validation precision@k5: 0.5149, accuracy@k5: 0.2563\n",
      "Epoch: 26 \t Validation precision@k10: 0.4980, accuracy@k10: 0.4156\n",
      "Epoch: 26 \t Validation precision@k15: 0.5482, accuracy@k15: 0.5296\n",
      "Epoch: 26 \t Validation precision@k20: 0.6205, accuracy@k20: 0.6178\n",
      "Epoch: 26 \t Validation precision@k25: 0.6922, accuracy@k25: 0.6920\n",
      "Epoch: 26 \t Validation precision@k30: 0.7541, accuracy@k30: 0.7541\n",
      "CPU: 21.87\n",
      "RAM %: 65.0\n",
      "Epoch: 27 \t Training Loss: 3.877377\n",
      "Epoch: 27 \t Validation precision@k5: 0.4344, accuracy@k5: 0.2201\n",
      "Epoch: 27 \t Validation precision@k10: 0.4867, accuracy@k10: 0.4097\n",
      "Epoch: 27 \t Validation precision@k15: 0.5483, accuracy@k15: 0.5300\n",
      "Epoch: 27 \t Validation precision@k20: 0.6384, accuracy@k20: 0.6357\n",
      "Epoch: 27 \t Validation precision@k25: 0.6992, accuracy@k25: 0.6991\n",
      "Epoch: 27 \t Validation precision@k30: 0.7537, accuracy@k30: 0.7537\n",
      "CPU: 21.83\n",
      "RAM %: 64.9\n",
      "Epoch: 28 \t Training Loss: 3.877287\n",
      "Epoch: 28 \t Validation precision@k5: 0.4762, accuracy@k5: 0.2378\n",
      "Epoch: 28 \t Validation precision@k10: 0.4655, accuracy@k10: 0.3916\n",
      "Epoch: 28 \t Validation precision@k15: 0.5391, accuracy@k15: 0.5209\n",
      "Epoch: 28 \t Validation precision@k20: 0.6265, accuracy@k20: 0.6238\n",
      "Epoch: 28 \t Validation precision@k25: 0.7013, accuracy@k25: 0.7011\n",
      "Epoch: 28 \t Validation precision@k30: 0.7500, accuracy@k30: 0.7500\n",
      "CPU: 21.76\n",
      "RAM %: 65.0\n",
      "Epoch: 29 \t Training Loss: 3.874563\n",
      "Epoch: 29 \t Validation precision@k5: 0.5022, accuracy@k5: 0.2524\n",
      "Epoch: 29 \t Validation precision@k10: 0.4893, accuracy@k10: 0.4118\n",
      "Epoch: 29 \t Validation precision@k15: 0.5483, accuracy@k15: 0.5302\n",
      "Epoch: 29 \t Validation precision@k20: 0.6403, accuracy@k20: 0.6376\n",
      "Epoch: 29 \t Validation precision@k25: 0.7079, accuracy@k25: 0.7078\n",
      "Epoch: 29 \t Validation precision@k30: 0.7597, accuracy@k30: 0.7597\n",
      "CPU: 21.89\n",
      "RAM %: 65.0\n",
      "Epoch: 30 \t Training Loss: 3.870818\n",
      "Epoch: 30 \t Validation precision@k5: 0.4999, accuracy@k5: 0.2494\n",
      "Epoch: 30 \t Validation precision@k10: 0.4827, accuracy@k10: 0.4044\n",
      "Epoch: 30 \t Validation precision@k15: 0.5509, accuracy@k15: 0.5328\n",
      "Epoch: 30 \t Validation precision@k20: 0.6272, accuracy@k20: 0.6246\n",
      "Epoch: 30 \t Validation precision@k25: 0.6976, accuracy@k25: 0.6975\n",
      "Epoch: 30 \t Validation precision@k30: 0.7554, accuracy@k30: 0.7554\n",
      "CPU: 21.99\n",
      "RAM %: 65.0\n",
      "Epoch: 31 \t Training Loss: 3.872936\n",
      "Epoch: 31 \t Validation precision@k5: 0.4960, accuracy@k5: 0.2446\n",
      "Epoch: 31 \t Validation precision@k10: 0.4747, accuracy@k10: 0.3965\n",
      "Epoch: 31 \t Validation precision@k15: 0.5403, accuracy@k15: 0.5215\n",
      "Epoch: 31 \t Validation precision@k20: 0.6317, accuracy@k20: 0.6290\n",
      "Epoch: 31 \t Validation precision@k25: 0.7079, accuracy@k25: 0.7078\n",
      "Epoch: 31 \t Validation precision@k30: 0.7644, accuracy@k30: 0.7644\n",
      "CPU: 22.28\n",
      "RAM %: 65.0\n",
      "Epoch: 32 \t Training Loss: 3.871997\n",
      "Epoch: 32 \t Validation precision@k5: 0.4898, accuracy@k5: 0.2480\n",
      "Epoch: 32 \t Validation precision@k10: 0.4989, accuracy@k10: 0.4187\n",
      "Epoch: 32 \t Validation precision@k15: 0.5571, accuracy@k15: 0.5379\n",
      "Epoch: 32 \t Validation precision@k20: 0.6273, accuracy@k20: 0.6245\n",
      "Epoch: 32 \t Validation precision@k25: 0.6983, accuracy@k25: 0.6982\n",
      "Epoch: 32 \t Validation precision@k30: 0.7574, accuracy@k30: 0.7574\n",
      "CPU: 22.33\n",
      "RAM %: 64.8\n",
      "Epoch: 33 \t Training Loss: 3.867399\n",
      "Epoch: 33 \t Validation precision@k5: 0.4806, accuracy@k5: 0.2419\n",
      "Epoch: 33 \t Validation precision@k10: 0.4912, accuracy@k10: 0.4129\n",
      "Epoch: 33 \t Validation precision@k15: 0.5622, accuracy@k15: 0.5436\n",
      "Epoch: 33 \t Validation precision@k20: 0.6361, accuracy@k20: 0.6334\n",
      "Epoch: 33 \t Validation precision@k25: 0.7023, accuracy@k25: 0.7022\n",
      "Epoch: 33 \t Validation precision@k30: 0.7626, accuracy@k30: 0.7626\n",
      "CPU: 22.29\n",
      "RAM %: 63.8\n",
      "Epoch: 34 \t Training Loss: 3.864862\n",
      "Epoch: 34 \t Validation precision@k5: 0.4894, accuracy@k5: 0.2454\n",
      "Epoch: 34 \t Validation precision@k10: 0.4843, accuracy@k10: 0.4071\n",
      "Epoch: 34 \t Validation precision@k15: 0.5604, accuracy@k15: 0.5413\n",
      "Epoch: 34 \t Validation precision@k20: 0.6415, accuracy@k20: 0.6388\n",
      "Epoch: 34 \t Validation precision@k25: 0.7119, accuracy@k25: 0.7117\n",
      "Epoch: 34 \t Validation precision@k30: 0.7694, accuracy@k30: 0.7694\n",
      "CPU: 22.30\n",
      "RAM %: 65.0\n",
      "Epoch: 35 \t Training Loss: 3.868674\n",
      "Epoch: 35 \t Validation precision@k5: 0.4957, accuracy@k5: 0.2512\n",
      "Epoch: 35 \t Validation precision@k10: 0.4819, accuracy@k10: 0.4051\n",
      "Epoch: 35 \t Validation precision@k15: 0.5538, accuracy@k15: 0.5354\n",
      "Epoch: 35 \t Validation precision@k20: 0.6329, accuracy@k20: 0.6302\n",
      "Epoch: 35 \t Validation precision@k25: 0.7060, accuracy@k25: 0.7059\n",
      "Epoch: 35 \t Validation precision@k30: 0.7647, accuracy@k30: 0.7647\n",
      "CPU: 22.26\n",
      "RAM %: 64.7\n",
      "Epoch: 36 \t Training Loss: 3.865190\n",
      "Epoch: 36 \t Validation precision@k5: 0.5195, accuracy@k5: 0.2561\n",
      "Epoch: 36 \t Validation precision@k10: 0.4969, accuracy@k10: 0.4155\n",
      "Epoch: 36 \t Validation precision@k15: 0.5469, accuracy@k15: 0.5278\n",
      "Epoch: 36 \t Validation precision@k20: 0.6271, accuracy@k20: 0.6244\n",
      "Epoch: 36 \t Validation precision@k25: 0.6953, accuracy@k25: 0.6952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 \t Validation precision@k30: 0.7605, accuracy@k30: 0.7605\n",
      "CPU: 22.47\n",
      "RAM %: 64.8\n",
      "Epoch: 37 \t Training Loss: 3.862666\n",
      "Epoch: 37 \t Validation precision@k5: 0.5114, accuracy@k5: 0.2554\n",
      "Epoch: 37 \t Validation precision@k10: 0.4947, accuracy@k10: 0.4143\n",
      "Epoch: 37 \t Validation precision@k15: 0.5625, accuracy@k15: 0.5433\n",
      "Epoch: 37 \t Validation precision@k20: 0.6366, accuracy@k20: 0.6339\n",
      "Epoch: 37 \t Validation precision@k25: 0.7140, accuracy@k25: 0.7139\n",
      "Epoch: 37 \t Validation precision@k30: 0.7634, accuracy@k30: 0.7634\n",
      "CPU: 22.52\n",
      "RAM %: 64.9\n",
      "Epoch: 38 \t Training Loss: 3.864873\n",
      "Epoch: 38 \t Validation precision@k5: 0.5138, accuracy@k5: 0.2604\n",
      "Epoch: 38 \t Validation precision@k10: 0.5026, accuracy@k10: 0.4222\n",
      "Epoch: 38 \t Validation precision@k15: 0.5586, accuracy@k15: 0.5399\n",
      "Epoch: 38 \t Validation precision@k20: 0.6383, accuracy@k20: 0.6356\n",
      "Epoch: 38 \t Validation precision@k25: 0.7111, accuracy@k25: 0.7110\n",
      "Epoch: 38 \t Validation precision@k30: 0.7657, accuracy@k30: 0.7657\n",
      "CPU: 22.47\n",
      "RAM %: 64.9\n",
      "Epoch: 39 \t Training Loss: 3.856157\n",
      "Epoch: 39 \t Validation precision@k5: 0.4682, accuracy@k5: 0.2373\n",
      "Epoch: 39 \t Validation precision@k10: 0.4807, accuracy@k10: 0.4035\n",
      "Epoch: 39 \t Validation precision@k15: 0.5536, accuracy@k15: 0.5344\n",
      "Epoch: 39 \t Validation precision@k20: 0.6309, accuracy@k20: 0.6281\n",
      "Epoch: 39 \t Validation precision@k25: 0.6944, accuracy@k25: 0.6943\n",
      "Epoch: 39 \t Validation precision@k30: 0.7470, accuracy@k30: 0.7470\n",
      "CPU: 22.39\n",
      "RAM %: 64.2\n",
      "Epoch: 40 \t Training Loss: 3.862858\n",
      "Epoch: 40 \t Validation precision@k5: 0.5155, accuracy@k5: 0.2565\n",
      "Epoch: 40 \t Validation precision@k10: 0.4952, accuracy@k10: 0.4138\n",
      "Epoch: 40 \t Validation precision@k15: 0.5517, accuracy@k15: 0.5326\n",
      "Epoch: 40 \t Validation precision@k20: 0.6460, accuracy@k20: 0.6433\n",
      "Epoch: 40 \t Validation precision@k25: 0.7075, accuracy@k25: 0.7073\n",
      "Epoch: 40 \t Validation precision@k30: 0.7584, accuracy@k30: 0.7584\n",
      "CPU: 22.48\n",
      "RAM %: 64.8\n",
      "Epoch: 41 \t Training Loss: 3.861936\n",
      "Epoch: 41 \t Validation precision@k5: 0.4625, accuracy@k5: 0.2334\n",
      "Epoch: 41 \t Validation precision@k10: 0.4663, accuracy@k10: 0.3928\n",
      "Epoch: 41 \t Validation precision@k15: 0.5394, accuracy@k15: 0.5214\n",
      "Epoch: 41 \t Validation precision@k20: 0.6331, accuracy@k20: 0.6304\n",
      "Epoch: 41 \t Validation precision@k25: 0.7094, accuracy@k25: 0.7092\n",
      "Epoch: 41 \t Validation precision@k30: 0.7626, accuracy@k30: 0.7626\n",
      "CPU: 22.50\n",
      "RAM %: 64.9\n",
      "Epoch: 42 \t Training Loss: 3.857353\n",
      "Epoch: 42 \t Validation precision@k5: 0.4463, accuracy@k5: 0.2286\n",
      "Epoch: 42 \t Validation precision@k10: 0.4696, accuracy@k10: 0.3959\n",
      "Epoch: 42 \t Validation precision@k15: 0.5439, accuracy@k15: 0.5259\n",
      "Epoch: 42 \t Validation precision@k20: 0.6377, accuracy@k20: 0.6350\n",
      "Epoch: 42 \t Validation precision@k25: 0.7114, accuracy@k25: 0.7113\n",
      "Epoch: 42 \t Validation precision@k30: 0.7623, accuracy@k30: 0.7623\n",
      "CPU: 22.62\n",
      "RAM %: 64.9\n",
      "Epoch: 43 \t Training Loss: 3.855931\n",
      "Epoch: 43 \t Validation precision@k5: 0.4842, accuracy@k5: 0.2470\n",
      "Epoch: 43 \t Validation precision@k10: 0.4864, accuracy@k10: 0.4099\n",
      "Epoch: 43 \t Validation precision@k15: 0.5524, accuracy@k15: 0.5340\n",
      "Epoch: 43 \t Validation precision@k20: 0.6351, accuracy@k20: 0.6324\n",
      "Epoch: 43 \t Validation precision@k25: 0.7055, accuracy@k25: 0.7054\n",
      "Epoch: 43 \t Validation precision@k30: 0.7581, accuracy@k30: 0.7581\n",
      "CPU: 23.05\n",
      "RAM %: 64.9\n",
      "Epoch: 44 \t Training Loss: 3.865786\n",
      "Epoch: 44 \t Validation precision@k5: 0.5262, accuracy@k5: 0.2663\n",
      "Epoch: 44 \t Validation precision@k10: 0.4977, accuracy@k10: 0.4187\n",
      "Epoch: 44 \t Validation precision@k15: 0.5440, accuracy@k15: 0.5259\n",
      "Epoch: 44 \t Validation precision@k20: 0.6280, accuracy@k20: 0.6253\n",
      "Epoch: 44 \t Validation precision@k25: 0.6991, accuracy@k25: 0.6989\n",
      "Epoch: 44 \t Validation precision@k30: 0.7581, accuracy@k30: 0.7581\n",
      "CPU: 23.07\n",
      "RAM %: 64.9\n",
      "Epoch: 45 \t Training Loss: 3.857655\n",
      "Epoch: 45 \t Validation precision@k5: 0.5162, accuracy@k5: 0.2573\n",
      "Epoch: 45 \t Validation precision@k10: 0.5045, accuracy@k10: 0.4234\n",
      "Epoch: 45 \t Validation precision@k15: 0.5602, accuracy@k15: 0.5413\n",
      "Epoch: 45 \t Validation precision@k20: 0.6351, accuracy@k20: 0.6324\n",
      "Epoch: 45 \t Validation precision@k25: 0.7038, accuracy@k25: 0.7037\n",
      "Epoch: 45 \t Validation precision@k30: 0.7623, accuracy@k30: 0.7623\n",
      "CPU: 23.11\n",
      "RAM %: 64.2\n",
      "Epoch: 46 \t Training Loss: 3.858845\n",
      "Epoch: 46 \t Validation precision@k5: 0.4862, accuracy@k5: 0.2480\n",
      "Epoch: 46 \t Validation precision@k10: 0.4739, accuracy@k10: 0.4002\n",
      "Epoch: 46 \t Validation precision@k15: 0.5453, accuracy@k15: 0.5274\n",
      "Epoch: 46 \t Validation precision@k20: 0.6275, accuracy@k20: 0.6249\n",
      "Epoch: 46 \t Validation precision@k25: 0.7037, accuracy@k25: 0.7035\n",
      "Epoch: 46 \t Validation precision@k30: 0.7598, accuracy@k30: 0.7598\n",
      "CPU: 23.24\n",
      "RAM %: 64.1\n",
      "Epoch: 47 \t Training Loss: 3.859417\n",
      "Epoch: 47 \t Validation precision@k5: 0.5286, accuracy@k5: 0.2673\n",
      "Epoch: 47 \t Validation precision@k10: 0.5021, accuracy@k10: 0.4217\n",
      "Epoch: 47 \t Validation precision@k15: 0.5612, accuracy@k15: 0.5423\n",
      "Epoch: 47 \t Validation precision@k20: 0.6447, accuracy@k20: 0.6420\n",
      "Epoch: 47 \t Validation precision@k25: 0.7119, accuracy@k25: 0.7118\n",
      "Epoch: 47 \t Validation precision@k30: 0.7667, accuracy@k30: 0.7667\n",
      "CPU: 23.26\n",
      "RAM %: 64.6\n",
      "Epoch: 48 \t Training Loss: 3.856901\n",
      "Epoch: 48 \t Validation precision@k5: 0.5040, accuracy@k5: 0.2562\n",
      "Epoch: 48 \t Validation precision@k10: 0.4801, accuracy@k10: 0.4041\n",
      "Epoch: 48 \t Validation precision@k15: 0.5485, accuracy@k15: 0.5301\n",
      "Epoch: 48 \t Validation precision@k20: 0.6298, accuracy@k20: 0.6271\n",
      "Epoch: 48 \t Validation precision@k25: 0.7064, accuracy@k25: 0.7063\n",
      "Epoch: 48 \t Validation precision@k30: 0.7605, accuracy@k30: 0.7605\n",
      "CPU: 23.24\n",
      "RAM %: 64.5\n",
      "Epoch: 49 \t Training Loss: 3.850807\n",
      "Epoch: 49 \t Validation precision@k5: 0.5361, accuracy@k5: 0.2686\n",
      "Epoch: 49 \t Validation precision@k10: 0.5003, accuracy@k10: 0.4200\n",
      "Epoch: 49 \t Validation precision@k15: 0.5609, accuracy@k15: 0.5424\n",
      "Epoch: 49 \t Validation precision@k20: 0.6353, accuracy@k20: 0.6326\n",
      "Epoch: 49 \t Validation precision@k25: 0.7039, accuracy@k25: 0.7037\n",
      "Epoch: 49 \t Validation precision@k30: 0.7563, accuracy@k30: 0.7563\n",
      "CPU: 23.40\n",
      "RAM %: 64.4\n",
      "Epoch: 50 \t Training Loss: 3.857053\n",
      "Epoch: 50 \t Validation precision@k5: 0.4803, accuracy@k5: 0.2440\n",
      "Epoch: 50 \t Validation precision@k10: 0.4884, accuracy@k10: 0.4121\n",
      "Epoch: 50 \t Validation precision@k15: 0.5529, accuracy@k15: 0.5345\n",
      "Epoch: 50 \t Validation precision@k20: 0.6325, accuracy@k20: 0.6298\n",
      "Epoch: 50 \t Validation precision@k25: 0.7045, accuracy@k25: 0.7044\n",
      "Epoch: 50 \t Validation precision@k30: 0.7625, accuracy@k30: 0.7625\n",
      "CPU: 23.27\n",
      "RAM %: 64.4\n",
      "Epoch: 51 \t Training Loss: 3.854054\n",
      "Epoch: 51 \t Validation precision@k5: 0.5348, accuracy@k5: 0.2683\n",
      "Epoch: 51 \t Validation precision@k10: 0.4949, accuracy@k10: 0.4147\n",
      "Epoch: 51 \t Validation precision@k15: 0.5596, accuracy@k15: 0.5405\n",
      "Epoch: 51 \t Validation precision@k20: 0.6330, accuracy@k20: 0.6304\n",
      "Epoch: 51 \t Validation precision@k25: 0.7002, accuracy@k25: 0.7000\n",
      "Epoch: 51 \t Validation precision@k30: 0.7567, accuracy@k30: 0.7567\n",
      "CPU: 23.24\n",
      "RAM %: 64.2\n",
      "Epoch: 52 \t Training Loss: 3.853000\n",
      "Epoch: 52 \t Validation precision@k5: 0.4592, accuracy@k5: 0.2343\n",
      "Epoch: 52 \t Validation precision@k10: 0.5089, accuracy@k10: 0.4276\n",
      "Epoch: 52 \t Validation precision@k15: 0.5710, accuracy@k15: 0.5517\n",
      "Epoch: 52 \t Validation precision@k20: 0.6336, accuracy@k20: 0.6309\n",
      "Epoch: 52 \t Validation precision@k25: 0.6997, accuracy@k25: 0.6995\n",
      "Epoch: 52 \t Validation precision@k30: 0.7551, accuracy@k30: 0.7551\n",
      "CPU: 23.22\n",
      "RAM %: 64.4\n",
      "Epoch: 53 \t Training Loss: 3.851268\n",
      "Epoch: 53 \t Validation precision@k5: 0.5239, accuracy@k5: 0.2628\n",
      "Epoch: 53 \t Validation precision@k10: 0.5052, accuracy@k10: 0.4241\n",
      "Epoch: 53 \t Validation precision@k15: 0.5630, accuracy@k15: 0.5443\n",
      "Epoch: 53 \t Validation precision@k20: 0.6377, accuracy@k20: 0.6350\n",
      "Epoch: 53 \t Validation precision@k25: 0.7051, accuracy@k25: 0.7049\n",
      "Epoch: 53 \t Validation precision@k30: 0.7639, accuracy@k30: 0.7639\n",
      "CPU: 23.35\n",
      "RAM %: 64.3\n",
      "Epoch: 54 \t Training Loss: 3.849497\n",
      "Epoch: 54 \t Validation precision@k5: 0.5355, accuracy@k5: 0.2681\n",
      "Epoch: 54 \t Validation precision@k10: 0.4949, accuracy@k10: 0.4148\n",
      "Epoch: 54 \t Validation precision@k15: 0.5426, accuracy@k15: 0.5242\n",
      "Epoch: 54 \t Validation precision@k20: 0.6267, accuracy@k20: 0.6240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 \t Validation precision@k25: 0.7084, accuracy@k25: 0.7082\n",
      "Epoch: 54 \t Validation precision@k30: 0.7635, accuracy@k30: 0.7635\n",
      "CPU: 23.29\n",
      "RAM %: 64.4\n",
      "Epoch: 55 \t Training Loss: 3.852606\n",
      "Epoch: 55 \t Validation precision@k5: 0.5128, accuracy@k5: 0.2583\n",
      "Epoch: 55 \t Validation precision@k10: 0.5064, accuracy@k10: 0.4245\n",
      "Epoch: 55 \t Validation precision@k15: 0.5681, accuracy@k15: 0.5487\n",
      "Epoch: 55 \t Validation precision@k20: 0.6423, accuracy@k20: 0.6395\n",
      "Epoch: 55 \t Validation precision@k25: 0.7116, accuracy@k25: 0.7115\n",
      "Epoch: 55 \t Validation precision@k30: 0.7677, accuracy@k30: 0.7677\n",
      "CPU: 23.23\n",
      "RAM %: 64.4\n",
      "Epoch: 56 \t Training Loss: 3.854883\n",
      "Epoch: 56 \t Validation precision@k5: 0.5191, accuracy@k5: 0.2621\n",
      "Epoch: 56 \t Validation precision@k10: 0.4958, accuracy@k10: 0.4183\n",
      "Epoch: 56 \t Validation precision@k15: 0.5522, accuracy@k15: 0.5343\n",
      "Epoch: 56 \t Validation precision@k20: 0.6299, accuracy@k20: 0.6273\n",
      "Epoch: 56 \t Validation precision@k25: 0.7034, accuracy@k25: 0.7033\n",
      "Epoch: 56 \t Validation precision@k30: 0.7624, accuracy@k30: 0.7624\n",
      "CPU: 23.17\n",
      "RAM %: 64.4\n",
      "Epoch: 57 \t Training Loss: 3.856167\n",
      "Epoch: 57 \t Validation precision@k5: 0.5147, accuracy@k5: 0.2612\n",
      "Epoch: 57 \t Validation precision@k10: 0.5075, accuracy@k10: 0.4264\n",
      "Epoch: 57 \t Validation precision@k15: 0.5557, accuracy@k15: 0.5369\n",
      "Epoch: 57 \t Validation precision@k20: 0.6176, accuracy@k20: 0.6149\n",
      "Epoch: 57 \t Validation precision@k25: 0.6949, accuracy@k25: 0.6947\n",
      "Epoch: 57 \t Validation precision@k30: 0.7565, accuracy@k30: 0.7565\n",
      "CPU: 23.08\n",
      "RAM %: 64.5\n",
      "Epoch: 58 \t Training Loss: 3.849065\n",
      "Epoch: 58 \t Validation precision@k5: 0.5212, accuracy@k5: 0.2607\n",
      "Epoch: 58 \t Validation precision@k10: 0.5003, accuracy@k10: 0.4194\n",
      "Epoch: 58 \t Validation precision@k15: 0.5602, accuracy@k15: 0.5413\n",
      "Epoch: 58 \t Validation precision@k20: 0.6449, accuracy@k20: 0.6422\n",
      "Epoch: 58 \t Validation precision@k25: 0.7080, accuracy@k25: 0.7078\n",
      "Epoch: 58 \t Validation precision@k30: 0.7584, accuracy@k30: 0.7584\n",
      "CPU: 22.99\n",
      "RAM %: 64.5\n",
      "Epoch: 59 \t Training Loss: 3.851437\n",
      "Epoch: 59 \t Validation precision@k5: 0.5300, accuracy@k5: 0.2676\n",
      "Epoch: 59 \t Validation precision@k10: 0.5049, accuracy@k10: 0.4254\n",
      "Epoch: 59 \t Validation precision@k15: 0.5581, accuracy@k15: 0.5395\n",
      "Epoch: 59 \t Validation precision@k20: 0.6345, accuracy@k20: 0.6318\n",
      "Epoch: 59 \t Validation precision@k25: 0.7026, accuracy@k25: 0.7025\n",
      "Epoch: 59 \t Validation precision@k30: 0.7597, accuracy@k30: 0.7597\n",
      "CPU: 22.99\n",
      "RAM %: 64.5\n",
      "Epoch: 60 \t Training Loss: 3.849073\n",
      "Epoch: 60 \t Validation precision@k5: 0.5021, accuracy@k5: 0.2536\n",
      "Epoch: 60 \t Validation precision@k10: 0.5125, accuracy@k10: 0.4303\n",
      "Epoch: 60 \t Validation precision@k15: 0.5665, accuracy@k15: 0.5471\n",
      "Epoch: 60 \t Validation precision@k20: 0.6334, accuracy@k20: 0.6306\n",
      "Epoch: 60 \t Validation precision@k25: 0.7080, accuracy@k25: 0.7079\n",
      "Epoch: 60 \t Validation precision@k30: 0.7642, accuracy@k30: 0.7642\n",
      "CPU: 23.05\n",
      "RAM %: 64.5\n",
      "Epoch: 61 \t Training Loss: 3.850118\n",
      "Epoch: 61 \t Validation precision@k5: 0.4653, accuracy@k5: 0.2350\n",
      "Epoch: 61 \t Validation precision@k10: 0.4903, accuracy@k10: 0.4118\n",
      "Epoch: 61 \t Validation precision@k15: 0.5581, accuracy@k15: 0.5397\n",
      "Epoch: 61 \t Validation precision@k20: 0.6419, accuracy@k20: 0.6392\n",
      "Epoch: 61 \t Validation precision@k25: 0.7095, accuracy@k25: 0.7093\n",
      "Epoch: 61 \t Validation precision@k30: 0.7621, accuracy@k30: 0.7621\n",
      "CPU: 22.99\n",
      "RAM %: 64.5\n",
      "Epoch: 62 \t Training Loss: 3.851407\n",
      "Epoch: 62 \t Validation precision@k5: 0.5169, accuracy@k5: 0.2633\n",
      "Epoch: 62 \t Validation precision@k10: 0.5077, accuracy@k10: 0.4264\n",
      "Epoch: 62 \t Validation precision@k15: 0.5610, accuracy@k15: 0.5420\n",
      "Epoch: 62 \t Validation precision@k20: 0.6302, accuracy@k20: 0.6276\n",
      "Epoch: 62 \t Validation precision@k25: 0.7008, accuracy@k25: 0.7006\n",
      "Epoch: 62 \t Validation precision@k30: 0.7535, accuracy@k30: 0.7535\n",
      "CPU: 22.93\n",
      "RAM %: 64.5\n",
      "Epoch: 63 \t Training Loss: 3.852903\n",
      "Epoch: 63 \t Validation precision@k5: 0.5031, accuracy@k5: 0.2541\n",
      "Epoch: 63 \t Validation precision@k10: 0.5082, accuracy@k10: 0.4274\n",
      "Epoch: 63 \t Validation precision@k15: 0.5596, accuracy@k15: 0.5407\n",
      "Epoch: 63 \t Validation precision@k20: 0.6259, accuracy@k20: 0.6232\n",
      "Epoch: 63 \t Validation precision@k25: 0.6987, accuracy@k25: 0.6986\n",
      "Epoch: 63 \t Validation precision@k30: 0.7608, accuracy@k30: 0.7608\n",
      "CPU: 22.84\n",
      "RAM %: 64.5\n",
      "Epoch: 64 \t Training Loss: 3.847935\n",
      "Epoch: 64 \t Validation precision@k5: 0.4766, accuracy@k5: 0.2418\n",
      "Epoch: 64 \t Validation precision@k10: 0.4973, accuracy@k10: 0.4187\n",
      "Epoch: 64 \t Validation precision@k15: 0.5629, accuracy@k15: 0.5440\n",
      "Epoch: 64 \t Validation precision@k20: 0.6382, accuracy@k20: 0.6355\n",
      "Epoch: 64 \t Validation precision@k25: 0.7104, accuracy@k25: 0.7103\n",
      "Epoch: 64 \t Validation precision@k30: 0.7623, accuracy@k30: 0.7623\n",
      "CPU: 22.93\n",
      "RAM %: 64.5\n",
      "Epoch: 65 \t Training Loss: 3.851638\n",
      "Epoch: 65 \t Validation precision@k5: 0.5074, accuracy@k5: 0.2588\n",
      "Epoch: 65 \t Validation precision@k10: 0.4979, accuracy@k10: 0.4196\n",
      "Epoch: 65 \t Validation precision@k15: 0.5706, accuracy@k15: 0.5517\n",
      "Epoch: 65 \t Validation precision@k20: 0.6444, accuracy@k20: 0.6416\n",
      "Epoch: 65 \t Validation precision@k25: 0.7073, accuracy@k25: 0.7072\n",
      "Epoch: 65 \t Validation precision@k30: 0.7664, accuracy@k30: 0.7664\n",
      "CPU: 22.80\n",
      "RAM %: 63.7\n",
      "Epoch: 66 \t Training Loss: 3.852549\n",
      "Epoch: 66 \t Validation precision@k5: 0.5177, accuracy@k5: 0.2640\n",
      "Epoch: 66 \t Validation precision@k10: 0.5030, accuracy@k10: 0.4228\n",
      "Epoch: 66 \t Validation precision@k15: 0.5568, accuracy@k15: 0.5379\n",
      "Epoch: 66 \t Validation precision@k20: 0.6317, accuracy@k20: 0.6290\n",
      "Epoch: 66 \t Validation precision@k25: 0.6994, accuracy@k25: 0.6993\n",
      "Epoch: 66 \t Validation precision@k30: 0.7561, accuracy@k30: 0.7561\n",
      "CPU: 22.85\n",
      "RAM %: 64.3\n",
      "Epoch: 67 \t Training Loss: 3.846366\n",
      "Epoch: 67 \t Validation precision@k5: 0.4591, accuracy@k5: 0.2342\n",
      "Epoch: 67 \t Validation precision@k10: 0.4606, accuracy@k10: 0.3872\n",
      "Epoch: 67 \t Validation precision@k15: 0.5422, accuracy@k15: 0.5239\n",
      "Epoch: 67 \t Validation precision@k20: 0.6274, accuracy@k20: 0.6247\n",
      "Epoch: 67 \t Validation precision@k25: 0.7024, accuracy@k25: 0.7022\n",
      "Epoch: 67 \t Validation precision@k30: 0.7638, accuracy@k30: 0.7638\n",
      "CPU: 22.73\n",
      "RAM %: 64.4\n",
      "Epoch: 68 \t Training Loss: 3.845602\n",
      "Epoch: 68 \t Validation precision@k5: 0.5148, accuracy@k5: 0.2626\n",
      "Epoch: 68 \t Validation precision@k10: 0.4874, accuracy@k10: 0.4104\n",
      "Epoch: 68 \t Validation precision@k15: 0.5548, accuracy@k15: 0.5364\n",
      "Epoch: 68 \t Validation precision@k20: 0.6350, accuracy@k20: 0.6324\n",
      "Epoch: 68 \t Validation precision@k25: 0.7014, accuracy@k25: 0.7012\n",
      "Epoch: 68 \t Validation precision@k30: 0.7499, accuracy@k30: 0.7499\n",
      "CPU: 22.68\n",
      "RAM %: 64.4\n",
      "Epoch: 69 \t Training Loss: 3.852411\n",
      "Epoch: 69 \t Validation precision@k5: 0.4928, accuracy@k5: 0.2505\n",
      "Epoch: 69 \t Validation precision@k10: 0.4838, accuracy@k10: 0.4085\n",
      "Epoch: 69 \t Validation precision@k15: 0.5635, accuracy@k15: 0.5452\n",
      "Epoch: 69 \t Validation precision@k20: 0.6405, accuracy@k20: 0.6378\n",
      "Epoch: 69 \t Validation precision@k25: 0.7084, accuracy@k25: 0.7083\n",
      "Epoch: 69 \t Validation precision@k30: 0.7624, accuracy@k30: 0.7624\n",
      "CPU: 22.66\n",
      "RAM %: 64.5\n",
      "Epoch: 70 \t Training Loss: 3.848652\n",
      "Epoch: 70 \t Validation precision@k5: 0.5250, accuracy@k5: 0.2668\n",
      "Epoch: 70 \t Validation precision@k10: 0.5056, accuracy@k10: 0.4249\n",
      "Epoch: 70 \t Validation precision@k15: 0.5614, accuracy@k15: 0.5423\n",
      "Epoch: 70 \t Validation precision@k20: 0.6335, accuracy@k20: 0.6308\n",
      "Epoch: 70 \t Validation precision@k25: 0.7046, accuracy@k25: 0.7045\n",
      "Epoch: 70 \t Validation precision@k30: 0.7600, accuracy@k30: 0.7600\n",
      "CPU: 22.53\n",
      "RAM %: 64.5\n",
      "Epoch: 71 \t Training Loss: 3.849541\n",
      "Epoch: 71 \t Validation precision@k5: 0.5050, accuracy@k5: 0.2566\n",
      "Epoch: 71 \t Validation precision@k10: 0.4978, accuracy@k10: 0.4196\n",
      "Epoch: 71 \t Validation precision@k15: 0.5624, accuracy@k15: 0.5440\n",
      "Epoch: 71 \t Validation precision@k20: 0.6347, accuracy@k20: 0.6320\n",
      "Epoch: 71 \t Validation precision@k25: 0.7039, accuracy@k25: 0.7038\n",
      "Epoch: 71 \t Validation precision@k30: 0.7597, accuracy@k30: 0.7597\n",
      "CPU: 22.51\n",
      "RAM %: 63.8\n",
      "Epoch: 72 \t Training Loss: 3.846170\n",
      "Epoch: 72 \t Validation precision@k5: 0.4719, accuracy@k5: 0.2396\n",
      "Epoch: 72 \t Validation precision@k10: 0.4870, accuracy@k10: 0.4097\n",
      "Epoch: 72 \t Validation precision@k15: 0.5596, accuracy@k15: 0.5413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 \t Validation precision@k20: 0.6437, accuracy@k20: 0.6410\n",
      "Epoch: 72 \t Validation precision@k25: 0.7145, accuracy@k25: 0.7144\n",
      "Epoch: 72 \t Validation precision@k30: 0.7600, accuracy@k30: 0.7600\n",
      "CPU: 22.46\n",
      "RAM %: 64.3\n",
      "Epoch: 73 \t Training Loss: 3.851617\n",
      "Epoch: 73 \t Validation precision@k5: 0.4777, accuracy@k5: 0.2450\n",
      "Epoch: 73 \t Validation precision@k10: 0.5014, accuracy@k10: 0.4227\n",
      "Epoch: 73 \t Validation precision@k15: 0.5665, accuracy@k15: 0.5479\n",
      "Epoch: 73 \t Validation precision@k20: 0.6399, accuracy@k20: 0.6372\n",
      "Epoch: 73 \t Validation precision@k25: 0.7096, accuracy@k25: 0.7095\n",
      "Epoch: 73 \t Validation precision@k30: 0.7668, accuracy@k30: 0.7668\n",
      "CPU: 22.38\n",
      "RAM %: 64.6\n",
      "Epoch: 74 \t Training Loss: 3.848106\n",
      "Epoch: 74 \t Validation precision@k5: 0.5062, accuracy@k5: 0.2600\n",
      "Epoch: 74 \t Validation precision@k10: 0.4933, accuracy@k10: 0.4162\n",
      "Epoch: 74 \t Validation precision@k15: 0.5489, accuracy@k15: 0.5309\n",
      "Epoch: 74 \t Validation precision@k20: 0.6263, accuracy@k20: 0.6236\n",
      "Epoch: 74 \t Validation precision@k25: 0.6978, accuracy@k25: 0.6977\n",
      "Epoch: 74 \t Validation precision@k30: 0.7593, accuracy@k30: 0.7593\n",
      "CPU: 22.35\n",
      "RAM %: 64.6\n",
      "Epoch: 75 \t Training Loss: 3.846049\n",
      "Epoch: 75 \t Validation precision@k5: 0.4757, accuracy@k5: 0.2388\n",
      "Epoch: 75 \t Validation precision@k10: 0.4860, accuracy@k10: 0.4080\n",
      "Epoch: 75 \t Validation precision@k15: 0.5457, accuracy@k15: 0.5275\n",
      "Epoch: 75 \t Validation precision@k20: 0.6343, accuracy@k20: 0.6316\n",
      "Epoch: 75 \t Validation precision@k25: 0.7023, accuracy@k25: 0.7021\n",
      "Epoch: 75 \t Validation precision@k30: 0.7572, accuracy@k30: 0.7572\n",
      "CPU: 22.49\n",
      "RAM %: 64.5\n",
      "Epoch: 76 \t Training Loss: 3.850638\n",
      "Epoch: 76 \t Validation precision@k5: 0.5061, accuracy@k5: 0.2552\n",
      "Epoch: 76 \t Validation precision@k10: 0.5145, accuracy@k10: 0.4316\n",
      "Epoch: 76 \t Validation precision@k15: 0.5659, accuracy@k15: 0.5466\n",
      "Epoch: 76 \t Validation precision@k20: 0.6377, accuracy@k20: 0.6349\n",
      "Epoch: 76 \t Validation precision@k25: 0.7039, accuracy@k25: 0.7037\n",
      "Epoch: 76 \t Validation precision@k30: 0.7593, accuracy@k30: 0.7593\n",
      "CPU: 22.37\n",
      "RAM %: 64.5\n",
      "Epoch: 77 \t Training Loss: 3.848960\n",
      "Epoch: 77 \t Validation precision@k5: 0.5061, accuracy@k5: 0.2554\n",
      "Epoch: 77 \t Validation precision@k10: 0.5110, accuracy@k10: 0.4291\n",
      "Epoch: 77 \t Validation precision@k15: 0.5622, accuracy@k15: 0.5432\n",
      "Epoch: 77 \t Validation precision@k20: 0.6340, accuracy@k20: 0.6313\n",
      "Epoch: 77 \t Validation precision@k25: 0.7038, accuracy@k25: 0.7036\n",
      "Epoch: 77 \t Validation precision@k30: 0.7596, accuracy@k30: 0.7596\n",
      "CPU: 22.38\n",
      "RAM %: 64.5\n",
      "Epoch: 78 \t Training Loss: 3.846341\n",
      "Epoch: 78 \t Validation precision@k5: 0.4779, accuracy@k5: 0.2365\n",
      "Epoch: 78 \t Validation precision@k10: 0.4879, accuracy@k10: 0.4088\n",
      "Epoch: 78 \t Validation precision@k15: 0.5612, accuracy@k15: 0.5421\n",
      "Epoch: 78 \t Validation precision@k20: 0.6391, accuracy@k20: 0.6363\n",
      "Epoch: 78 \t Validation precision@k25: 0.7037, accuracy@k25: 0.7036\n",
      "Epoch: 78 \t Validation precision@k30: 0.7628, accuracy@k30: 0.7628\n",
      "CPU: 22.38\n",
      "RAM %: 64.5\n",
      "Epoch: 79 \t Training Loss: 3.845461\n",
      "Epoch: 79 \t Validation precision@k5: 0.4775, accuracy@k5: 0.2426\n",
      "Epoch: 79 \t Validation precision@k10: 0.4806, accuracy@k10: 0.4062\n",
      "Epoch: 79 \t Validation precision@k15: 0.5593, accuracy@k15: 0.5411\n",
      "Epoch: 79 \t Validation precision@k20: 0.6444, accuracy@k20: 0.6417\n",
      "Epoch: 79 \t Validation precision@k25: 0.7128, accuracy@k25: 0.7127\n",
      "Epoch: 79 \t Validation precision@k30: 0.7662, accuracy@k30: 0.7662\n",
      "CPU: 22.37\n",
      "RAM %: 64.5\n",
      "Epoch: 80 \t Training Loss: 3.847761\n",
      "Epoch: 80 \t Validation precision@k5: 0.4560, accuracy@k5: 0.2320\n",
      "Epoch: 80 \t Validation precision@k10: 0.4628, accuracy@k10: 0.3913\n",
      "Epoch: 80 \t Validation precision@k15: 0.5474, accuracy@k15: 0.5294\n",
      "Epoch: 80 \t Validation precision@k20: 0.6288, accuracy@k20: 0.6261\n",
      "Epoch: 80 \t Validation precision@k25: 0.7029, accuracy@k25: 0.7027\n",
      "Epoch: 80 \t Validation precision@k30: 0.7647, accuracy@k30: 0.7647\n",
      "CPU: 22.35\n",
      "RAM %: 64.5\n",
      "Epoch: 81 \t Training Loss: 3.847243\n",
      "Epoch: 81 \t Validation precision@k5: 0.5031, accuracy@k5: 0.2551\n",
      "Epoch: 81 \t Validation precision@k10: 0.5062, accuracy@k10: 0.4263\n",
      "Epoch: 81 \t Validation precision@k15: 0.5652, accuracy@k15: 0.5465\n",
      "Epoch: 81 \t Validation precision@k20: 0.6382, accuracy@k20: 0.6355\n",
      "Epoch: 81 \t Validation precision@k25: 0.7036, accuracy@k25: 0.7035\n",
      "Epoch: 81 \t Validation precision@k30: 0.7621, accuracy@k30: 0.7621\n",
      "CPU: 22.42\n",
      "RAM %: 64.6\n",
      "Epoch: 82 \t Training Loss: 3.842331\n",
      "Epoch: 82 \t Validation precision@k5: 0.5039, accuracy@k5: 0.2547\n",
      "Epoch: 82 \t Validation precision@k10: 0.5057, accuracy@k10: 0.4243\n",
      "Epoch: 82 \t Validation precision@k15: 0.5676, accuracy@k15: 0.5484\n",
      "Epoch: 82 \t Validation precision@k20: 0.6429, accuracy@k20: 0.6402\n",
      "Epoch: 82 \t Validation precision@k25: 0.7108, accuracy@k25: 0.7107\n",
      "Epoch: 82 \t Validation precision@k30: 0.7638, accuracy@k30: 0.7638\n",
      "CPU: 22.48\n",
      "RAM %: 64.5\n",
      "Epoch: 83 \t Training Loss: 3.845983\n",
      "Epoch: 83 \t Validation precision@k5: 0.4585, accuracy@k5: 0.2348\n",
      "Epoch: 83 \t Validation precision@k10: 0.4929, accuracy@k10: 0.4149\n",
      "Epoch: 83 \t Validation precision@k15: 0.5595, accuracy@k15: 0.5411\n",
      "Epoch: 83 \t Validation precision@k20: 0.6411, accuracy@k20: 0.6384\n",
      "Epoch: 83 \t Validation precision@k25: 0.7114, accuracy@k25: 0.7113\n",
      "Epoch: 83 \t Validation precision@k30: 0.7630, accuracy@k30: 0.7630\n",
      "CPU: 22.42\n",
      "RAM %: 64.6\n",
      "Epoch: 84 \t Training Loss: 3.844077\n",
      "Epoch: 84 \t Validation precision@k5: 0.5163, accuracy@k5: 0.2636\n",
      "Epoch: 84 \t Validation precision@k10: 0.4979, accuracy@k10: 0.4200\n",
      "Epoch: 84 \t Validation precision@k15: 0.5577, accuracy@k15: 0.5393\n",
      "Epoch: 84 \t Validation precision@k20: 0.6318, accuracy@k20: 0.6291\n",
      "Epoch: 84 \t Validation precision@k25: 0.7050, accuracy@k25: 0.7049\n",
      "Epoch: 84 \t Validation precision@k30: 0.7608, accuracy@k30: 0.7608\n",
      "CPU: 22.37\n",
      "RAM %: 64.6\n",
      "Epoch: 85 \t Training Loss: 3.840481\n",
      "Epoch: 85 \t Validation precision@k5: 0.4861, accuracy@k5: 0.2473\n",
      "Epoch: 85 \t Validation precision@k10: 0.5057, accuracy@k10: 0.4246\n",
      "Epoch: 85 \t Validation precision@k15: 0.5664, accuracy@k15: 0.5473\n",
      "Epoch: 85 \t Validation precision@k20: 0.6363, accuracy@k20: 0.6335\n",
      "Epoch: 85 \t Validation precision@k25: 0.6979, accuracy@k25: 0.6977\n",
      "Epoch: 85 \t Validation precision@k30: 0.7605, accuracy@k30: 0.7605\n",
      "CPU: 22.43\n",
      "RAM %: 64.6\n",
      "Epoch: 86 \t Training Loss: 3.844842\n",
      "Epoch: 86 \t Validation precision@k5: 0.4754, accuracy@k5: 0.2426\n",
      "Epoch: 86 \t Validation precision@k10: 0.5112, accuracy@k10: 0.4304\n",
      "Epoch: 86 \t Validation precision@k15: 0.5546, accuracy@k15: 0.5359\n",
      "Epoch: 86 \t Validation precision@k20: 0.6280, accuracy@k20: 0.6253\n",
      "Epoch: 86 \t Validation precision@k25: 0.7105, accuracy@k25: 0.7104\n",
      "Epoch: 86 \t Validation precision@k30: 0.7666, accuracy@k30: 0.7666\n",
      "CPU: 22.45\n",
      "RAM %: 64.5\n",
      "Epoch: 87 \t Training Loss: 3.841169\n",
      "Epoch: 87 \t Validation precision@k5: 0.4853, accuracy@k5: 0.2464\n",
      "Epoch: 87 \t Validation precision@k10: 0.5022, accuracy@k10: 0.4219\n",
      "Epoch: 87 \t Validation precision@k15: 0.5669, accuracy@k15: 0.5479\n",
      "Epoch: 87 \t Validation precision@k20: 0.6478, accuracy@k20: 0.6451\n",
      "Epoch: 87 \t Validation precision@k25: 0.7130, accuracy@k25: 0.7129\n",
      "Epoch: 87 \t Validation precision@k30: 0.7652, accuracy@k30: 0.7652\n",
      "CPU: 22.43\n",
      "RAM %: 64.0\n",
      "Epoch: 88 \t Training Loss: 3.841891\n",
      "Epoch: 88 \t Validation precision@k5: 0.4907, accuracy@k5: 0.2503\n",
      "Epoch: 88 \t Validation precision@k10: 0.4853, accuracy@k10: 0.4084\n",
      "Epoch: 88 \t Validation precision@k15: 0.5476, accuracy@k15: 0.5296\n",
      "Epoch: 88 \t Validation precision@k20: 0.6396, accuracy@k20: 0.6369\n",
      "Epoch: 88 \t Validation precision@k25: 0.7079, accuracy@k25: 0.7078\n",
      "Epoch: 88 \t Validation precision@k30: 0.7656, accuracy@k30: 0.7656\n",
      "CPU: 22.37\n",
      "RAM %: 64.5\n",
      "Epoch: 89 \t Training Loss: 3.845644\n",
      "Epoch: 89 \t Validation precision@k5: 0.5126, accuracy@k5: 0.2574\n",
      "Epoch: 89 \t Validation precision@k10: 0.5002, accuracy@k10: 0.4207\n",
      "Epoch: 89 \t Validation precision@k15: 0.5480, accuracy@k15: 0.5295\n",
      "Epoch: 89 \t Validation precision@k20: 0.6330, accuracy@k20: 0.6302\n",
      "Epoch: 89 \t Validation precision@k25: 0.6999, accuracy@k25: 0.6998\n",
      "Epoch: 89 \t Validation precision@k30: 0.7540, accuracy@k30: 0.7540\n",
      "CPU: 22.55\n",
      "RAM %: 64.6\n",
      "Epoch: 90 \t Training Loss: 3.845233\n",
      "Epoch: 90 \t Validation precision@k5: 0.4621, accuracy@k5: 0.2358\n",
      "Epoch: 90 \t Validation precision@k10: 0.4743, accuracy@k10: 0.4001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 \t Validation precision@k15: 0.5475, accuracy@k15: 0.5294\n",
      "Epoch: 90 \t Validation precision@k20: 0.6342, accuracy@k20: 0.6316\n",
      "Epoch: 90 \t Validation precision@k25: 0.7027, accuracy@k25: 0.7026\n",
      "Epoch: 90 \t Validation precision@k30: 0.7594, accuracy@k30: 0.7594\n",
      "CPU: 22.54\n",
      "RAM %: 64.7\n",
      "Epoch: 91 \t Training Loss: 3.844197\n",
      "Epoch: 91 \t Validation precision@k5: 0.4952, accuracy@k5: 0.2523\n",
      "Epoch: 91 \t Validation precision@k10: 0.4952, accuracy@k10: 0.4171\n",
      "Epoch: 91 \t Validation precision@k15: 0.5639, accuracy@k15: 0.5448\n",
      "Epoch: 91 \t Validation precision@k20: 0.6457, accuracy@k20: 0.6430\n",
      "Epoch: 91 \t Validation precision@k25: 0.7107, accuracy@k25: 0.7106\n",
      "Epoch: 91 \t Validation precision@k30: 0.7607, accuracy@k30: 0.7607\n",
      "CPU: 22.66\n",
      "RAM %: 64.6\n",
      "Epoch: 92 \t Training Loss: 3.841235\n",
      "Epoch: 92 \t Validation precision@k5: 0.5221, accuracy@k5: 0.2626\n",
      "Epoch: 92 \t Validation precision@k10: 0.5051, accuracy@k10: 0.4266\n",
      "Epoch: 92 \t Validation precision@k15: 0.5581, accuracy@k15: 0.5400\n",
      "Epoch: 92 \t Validation precision@k20: 0.6437, accuracy@k20: 0.6410\n",
      "Epoch: 92 \t Validation precision@k25: 0.7137, accuracy@k25: 0.7136\n",
      "Epoch: 92 \t Validation precision@k30: 0.7659, accuracy@k30: 0.7659\n",
      "CPU: 22.72\n",
      "RAM %: 64.6\n",
      "Epoch: 93 \t Training Loss: 3.843288\n",
      "Epoch: 93 \t Validation precision@k5: 0.5022, accuracy@k5: 0.2572\n",
      "Epoch: 93 \t Validation precision@k10: 0.4932, accuracy@k10: 0.4153\n",
      "Epoch: 93 \t Validation precision@k15: 0.5432, accuracy@k15: 0.5252\n",
      "Epoch: 93 \t Validation precision@k20: 0.6216, accuracy@k20: 0.6190\n",
      "Epoch: 93 \t Validation precision@k25: 0.6932, accuracy@k25: 0.6931\n",
      "Epoch: 93 \t Validation precision@k30: 0.7496, accuracy@k30: 0.7496\n",
      "CPU: 22.74\n",
      "RAM %: 64.5\n",
      "Epoch: 94 \t Training Loss: 3.843588\n",
      "Epoch: 94 \t Validation precision@k5: 0.5057, accuracy@k5: 0.2511\n",
      "Epoch: 94 \t Validation precision@k10: 0.4935, accuracy@k10: 0.4136\n",
      "Epoch: 94 \t Validation precision@k15: 0.5510, accuracy@k15: 0.5326\n",
      "Epoch: 94 \t Validation precision@k20: 0.6368, accuracy@k20: 0.6341\n",
      "Epoch: 94 \t Validation precision@k25: 0.7063, accuracy@k25: 0.7061\n",
      "Epoch: 94 \t Validation precision@k30: 0.7601, accuracy@k30: 0.7601\n",
      "CPU: 22.68\n",
      "RAM %: 62.8\n",
      "Epoch: 95 \t Training Loss: 3.848090\n",
      "Epoch: 95 \t Validation precision@k5: 0.4735, accuracy@k5: 0.2421\n",
      "Epoch: 95 \t Validation precision@k10: 0.4958, accuracy@k10: 0.4174\n",
      "Epoch: 95 \t Validation precision@k15: 0.5676, accuracy@k15: 0.5487\n",
      "Epoch: 95 \t Validation precision@k20: 0.6346, accuracy@k20: 0.6320\n",
      "Epoch: 95 \t Validation precision@k25: 0.6974, accuracy@k25: 0.6973\n",
      "Epoch: 95 \t Validation precision@k30: 0.7516, accuracy@k30: 0.7516\n",
      "CPU: 22.71\n",
      "RAM %: 63.0\n",
      "Epoch: 96 \t Training Loss: 3.840458\n",
      "Epoch: 96 \t Validation precision@k5: 0.4566, accuracy@k5: 0.2334\n",
      "Epoch: 96 \t Validation precision@k10: 0.4718, accuracy@k10: 0.3990\n",
      "Epoch: 96 \t Validation precision@k15: 0.5462, accuracy@k15: 0.5282\n",
      "Epoch: 96 \t Validation precision@k20: 0.6308, accuracy@k20: 0.6281\n",
      "Epoch: 96 \t Validation precision@k25: 0.7129, accuracy@k25: 0.7127\n",
      "Epoch: 96 \t Validation precision@k30: 0.7649, accuracy@k30: 0.7649\n",
      "CPU: 22.73\n",
      "RAM %: 63.1\n",
      "Epoch: 97 \t Training Loss: 3.840554\n",
      "Epoch: 97 \t Validation precision@k5: 0.4788, accuracy@k5: 0.2437\n",
      "Epoch: 97 \t Validation precision@k10: 0.4762, accuracy@k10: 0.4019\n",
      "Epoch: 97 \t Validation precision@k15: 0.5446, accuracy@k15: 0.5268\n",
      "Epoch: 97 \t Validation precision@k20: 0.6249, accuracy@k20: 0.6223\n",
      "Epoch: 97 \t Validation precision@k25: 0.7053, accuracy@k25: 0.7051\n",
      "Epoch: 97 \t Validation precision@k30: 0.7622, accuracy@k30: 0.7622\n",
      "CPU: 22.67\n",
      "RAM %: 63.3\n",
      "Epoch: 98 \t Training Loss: 3.840982\n",
      "Epoch: 98 \t Validation precision@k5: 0.4841, accuracy@k5: 0.2480\n",
      "Epoch: 98 \t Validation precision@k10: 0.5038, accuracy@k10: 0.4238\n",
      "Epoch: 98 \t Validation precision@k15: 0.5655, accuracy@k15: 0.5465\n",
      "Epoch: 98 \t Validation precision@k20: 0.6406, accuracy@k20: 0.6378\n",
      "Epoch: 98 \t Validation precision@k25: 0.7045, accuracy@k25: 0.7044\n",
      "Epoch: 98 \t Validation precision@k30: 0.7612, accuracy@k30: 0.7612\n",
      "CPU: 22.66\n",
      "RAM %: 63.0\n",
      "Epoch: 99 \t Training Loss: 3.847756\n",
      "Epoch: 99 \t Validation precision@k5: 0.5144, accuracy@k5: 0.2583\n",
      "Epoch: 99 \t Validation precision@k10: 0.5087, accuracy@k10: 0.4264\n",
      "Epoch: 99 \t Validation precision@k15: 0.5616, accuracy@k15: 0.5426\n",
      "Epoch: 99 \t Validation precision@k20: 0.6330, accuracy@k20: 0.6303\n",
      "Epoch: 99 \t Validation precision@k25: 0.7032, accuracy@k25: 0.7030\n",
      "Epoch: 99 \t Validation precision@k30: 0.7614, accuracy@k30: 0.7614\n",
      "CPU: 22.90\n",
      "RAM %: 63.7\n",
      "Epoch: 100 \t Training Loss: 3.844815\n",
      "Epoch: 100 \t Validation precision@k5: 0.4834, accuracy@k5: 0.2441\n",
      "Epoch: 100 \t Validation precision@k10: 0.4908, accuracy@k10: 0.4120\n",
      "Epoch: 100 \t Validation precision@k15: 0.5571, accuracy@k15: 0.5385\n",
      "Epoch: 100 \t Validation precision@k20: 0.6355, accuracy@k20: 0.6327\n",
      "Epoch: 100 \t Validation precision@k25: 0.7124, accuracy@k25: 0.7122\n",
      "Epoch: 100 \t Validation precision@k30: 0.7658, accuracy@k30: 0.7658\n",
      "CPU: 22.90\n",
      "RAM %: 63.7\n",
      "CPU times: user 13min 28s, sys: 5min 13s, total: 18min 41s\n",
      "Wall time: 13min 41s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "%time train(enhanced_mlp, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d43a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation precision@k5: 0.4926, accuracy@k5: 0.2505\n",
      "Validation precision@k10: 0.4911, accuracy@k10: 0.4096\n",
      "Validation precision@k15: 0.5512, accuracy@k15: 0.5302\n",
      "Validation precision@k20: 0.6261, accuracy@k20: 0.6222\n",
      "Validation precision@k25: 0.7001, accuracy@k25: 0.6999\n",
      "Validation precision@k30: 0.7492, accuracy@k30: 0.7492\n"
     ]
    }
   ],
   "source": [
    "for k in range(5, 31, 5):\n",
    "    precision_k, accuracy_k = eval_model(enhanced_mlp, test_loader, k=k)\n",
    "    print(f'Validation precision@k{k}: {precision_k:.4f}, accuracy@k{k}: {accuracy_k:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02c32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4h",
   "language": "python",
   "name": "dl4h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
