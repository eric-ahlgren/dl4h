{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07324f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define data path\n",
    "DATA_PATH = \"data/\"\n",
    "CHECKPOINT_PATH = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1156a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = pickle.load(open(os.path.join(DATA_PATH,'pids.pkl'), 'rb'))\n",
    "vids = pickle.load(open(os.path.join(DATA_PATH,'vids.pkl'), 'rb'))\n",
    "targets = pickle.load(open(os.path.join(DATA_PATH,'targets.pkl'), 'rb'))\n",
    "prob_targets = pickle.load(open(os.path.join(DATA_PATH,'prob_targets.pkl'), 'rb'))\n",
    "prob_targets_allvisits = pickle.load(open(os.path.join(DATA_PATH,'prob_targets_allvisits.pkl'), 'rb'))\n",
    "seqs = pickle.load(open(os.path.join(DATA_PATH,'seqs.pkl'), 'rb'))\n",
    "diags = pickle.load(open(os.path.join(DATA_PATH,'diags.pkl'), 'rb'))\n",
    "categories = pickle.load(open(os.path.join(DATA_PATH,'categories.pkl'), 'rb'))\n",
    "sub_categories = pickle.load(open(os.path.join(DATA_PATH,'subcategories.pkl'), 'rb'))\n",
    "codes = pickle.load(open(os.path.join(DATA_PATH,'icd9.pkl'), 'rb'))\n",
    "assert len(pids) == len(vids) == len(targets) == len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dadc956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.load(os.path.join(DATA_PATH, 'embedding_matrix.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4bc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, seqs, targets):\n",
    "        self.x = seqs\n",
    "        self.y = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.x))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "206aa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(seqs, prob_targets_allvisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b5cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# total visits excluding last visit per patient, max # diagnosis codes) of\n",
    "            type torch.long\n",
    "        x_masks: a tensor of shape (# total visits excluding last visit per patient, max # diagnosis codes)\n",
    "            of type torch.bool\n",
    "        y: a tensor of shape (# total visits excluding first visit per patient, num higher level categories\n",
    "            to predict) of type torch.float\n",
    "    \"\"\"\n",
    "    sequences, targets = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "    num_categories = len(targets[0][0])\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    sum_visits = sum(num_visits)\n",
    "    \n",
    "    x = torch.zeros((sum_visits - num_patients, max_num_codes), dtype=torch.long)\n",
    "    y = torch.zeros((sum_visits - num_patients, num_categories), dtype=torch.float)\n",
    "    x_masks = torch.zeros((sum_visits - num_patients, max_num_codes), dtype=torch.bool)\n",
    "\n",
    "    n = 0\n",
    "    for i,patient in enumerate(sequences):\n",
    "        for j,visit in enumerate(patient):\n",
    "            if j == len(patient) - 1:\n",
    "                break\n",
    "            for k,code in enumerate(visit):\n",
    "                x[n,k] = code\n",
    "                x_masks[n,k] = 1\n",
    "            n+=1\n",
    "    n = 0\n",
    "    for i,patient in enumerate(targets):\n",
    "        for j,visit in enumerate(patient):\n",
    "            if j == len(patient) - 1:\n",
    "                break\n",
    "            y[n] = torch.tensor(patient[j+1])\n",
    "            n += 1\n",
    "    \n",
    "    \n",
    "    return x, x_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7834769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(len(dataset)*0.75)\n",
    "test_split = int(len(dataset)*0.15)\n",
    "val_split = int(len(dataset)*0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e400730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6561\n",
      "Length of test dataset: 1312\n",
      "Length of val dataset: 875\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_split = int(len(dataset)*0.75)\n",
    "test_split = int(len(dataset)*0.15)\n",
    "\n",
    "lengths = [train_split, test_split, len(dataset) - (train_split + test_split)]\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of test dataset:\", len(test_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21e1a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dataset, test_dataset, val_dataset, collate_fn):\n",
    "    '''\n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        test dataset: test dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, test_loader, val_loader: train, test and validation dataloaders\n",
    "    '''\n",
    "    batch_size = 100\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               collate_fn=collate_fn,\n",
    "                                               shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             collate_fn=collate_fn,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader, val_loader = load_data(train_dataset, test_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4d1d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_multihot(indices, masks, dim):\n",
    "    multihot = torch.zeros((indices.shape[0], dim), dtype=torch.float)\n",
    "    for idx, row in enumerate(indices):\n",
    "        y_idx = row[masks[idx]].unique()\n",
    "        multihot[idx] = F.one_hot(y_idx.to(torch.int64), multihot.shape[1]).sum(0)\n",
    "    return multihot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "637c36f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedMLP(\n",
       "  (embedding): Linear(in_features=4903, out_features=300, bias=True)\n",
       "  (fc): Linear(in_features=300, out_features=184, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnhancedMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, num_categories, embedding_matrix):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            num_codes: total number of diagnosis codes\n",
    "            num_categories: number of higher level categories to predict\n",
    "            embedding_matrix: learned embedding matrix of icd9 descriptions\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Linear(4903, 300)\n",
    "        self.embedding.weight.data = embedding_matrix\n",
    "        self.fc = nn.Linear(300, num_categories)\n",
    "    \n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: the diagnosis sequence of shape (batch_size, # visits, # diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "        Outputs:\n",
    "            logits: logits of shape (batch_size, # diagnosis codes)\n",
    "        \"\"\"\n",
    "        x = indices_to_multihot(x, masks, 4903)\n",
    "        x = self.embedding(x)\n",
    "        x = torch.tanh(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "    \n",
    "# load the model here\n",
    "enhanced_mlp = EnhancedMLP(num_codes = len(codes), num_categories=len(sub_categories), embedding_matrix=embedding_matrix)\n",
    "enhanced_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "375a279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(baseline_mlp.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adadelta(enhanced_mlp.parameters(), weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bc112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, k=15, n=-1):    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model: the EnhancedMLP model\n",
    "        test_loader: validation dataloader\n",
    "        k: value for top k predictions\n",
    "        n: num of records to evaluate in the batch, value -1 evaulates all records\n",
    "        \n",
    "    Outputs:\n",
    "        precision_k: visit-level precison@k\n",
    "        accuracy_k: code-level accuracy@k\n",
    "    \"\"\"\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    all_precision = []\n",
    "    all_accuracy = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, masks, y in test_loader:\n",
    "            n_eval = y.shape[0] - 1 if n == -1 else n\n",
    "            y_hat = model(x, masks)\n",
    "            y_hat = F.softmax(y_hat, dim=-1)\n",
    "            nz_rows, nz_cols = torch.nonzero(y, as_tuple=True)\n",
    "            k_correct = 0\n",
    "            total_precision = 0\n",
    "            total_accuracy = 0\n",
    "            for i in range(n_eval):\n",
    "                visit_correct = 0\n",
    "                y_true = nz_cols[nz_rows == i]\n",
    "                _, y_pred = torch.topk(y_hat[i], k)\n",
    "                    \n",
    "                for v in y_true:\n",
    "                    if v in y_pred:\n",
    "                        visit_correct += 1\n",
    "                        \n",
    "                visit_precision = visit_correct / min(k, len(y_true))\n",
    "                visit_accuracy = visit_correct / len(y_true)\n",
    "                k_correct += visit_correct\n",
    "                total_precision += visit_precision\n",
    "                total_accuracy += visit_accuracy\n",
    "\n",
    "            precision_k = total_precision / n_eval\n",
    "            accuracy_k = total_accuracy / n_eval\n",
    "            all_precision.append(precision_k)\n",
    "            all_accuracy.append(accuracy_k)\n",
    "            \n",
    "    total_precision_k = np.mean(all_precision)\n",
    "    total_accuracy_k = np.mean(all_accuracy)\n",
    "    return total_precision_k, total_accuracy_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17a85ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model: the EnhancedMLP model\n",
    "        train_loader: training dataloader\n",
    "        test_loader: validation dataloader\n",
    "        n_epochs: num epochs to train\n",
    "    \"\"\"\n",
    "    max_cpu, max_ram = print_cpu_usage()\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, y in train_loader:\n",
    "            y_hat = model(x, masks)\n",
    "            loss = criterion(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        cpu, ram = print_cpu_usage()\n",
    "        max_cpu = cpu if cpu > max_cpu else max_cpu\n",
    "        max_ram = ram if ram > max_ram else max_ram\n",
    "        print(f'Epoch: {epoch+1} \\t Training Loss: {train_loss:.6f}')\n",
    "        for k in range(5, 31, 5):\n",
    "            precision_k, accuracy_k = eval_model(model, test_loader, k=k)\n",
    "            print(f'Epoch: {epoch+1} \\t Validation precision@k{k}: {precision_k:.4f}, accuracy@k{k}: {accuracy_k:.4f}')\n",
    "    final_cpu, final_ram = print_cpu_usage()\n",
    "    print(f\"Max CPU usage: {max_cpu:.3f}\\tMax RAM % usage: {max_ram}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3097025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cpu_usage():\n",
    "    load = psutil.getloadavg()[2]\n",
    "    cpu_usage = (load/os.cpu_count()) * 100\n",
    "    ram = psutil.virtual_memory()[2]\n",
    "    print(f\"CPU: {cpu_usage:0.2f}\")\n",
    "    print(f\"RAM %: {ram}\")\n",
    "    return cpu_usage, ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1800d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 12.53\n",
      "RAM %: 57.0\n",
      "CPU: 12.60\n",
      "RAM %: 57.0\n",
      "Epoch: 1 \t Training Loss: 4.054320\n",
      "Epoch: 1 \t Validation precision@k5: 0.4018, accuracy@k5: 0.1895\n",
      "Epoch: 1 \t Validation precision@k10: 0.3749, accuracy@k10: 0.3063\n",
      "Epoch: 1 \t Validation precision@k15: 0.4664, accuracy@k15: 0.4474\n",
      "Epoch: 1 \t Validation precision@k20: 0.6029, accuracy@k20: 0.5993\n",
      "Epoch: 1 \t Validation precision@k25: 0.6707, accuracy@k25: 0.6704\n",
      "Epoch: 1 \t Validation precision@k30: 0.7468, accuracy@k30: 0.7468\n",
      "CPU: 13.00\n",
      "RAM %: 57.0\n",
      "Epoch: 2 \t Training Loss: 4.016588\n",
      "Epoch: 2 \t Validation precision@k5: 0.3892, accuracy@k5: 0.1892\n",
      "Epoch: 2 \t Validation precision@k10: 0.4677, accuracy@k10: 0.3874\n",
      "Epoch: 2 \t Validation precision@k15: 0.5084, accuracy@k15: 0.4899\n",
      "Epoch: 2 \t Validation precision@k20: 0.5947, accuracy@k20: 0.5912\n",
      "Epoch: 2 \t Validation precision@k25: 0.6644, accuracy@k25: 0.6642\n",
      "Epoch: 2 \t Validation precision@k30: 0.7134, accuracy@k30: 0.7134\n",
      "CPU: 13.10\n",
      "RAM %: 57.1\n",
      "Epoch: 3 \t Training Loss: 4.003275\n",
      "Epoch: 3 \t Validation precision@k5: 0.5095, accuracy@k5: 0.2477\n",
      "Epoch: 3 \t Validation precision@k10: 0.4574, accuracy@k10: 0.3802\n",
      "Epoch: 3 \t Validation precision@k15: 0.5193, accuracy@k15: 0.4997\n",
      "Epoch: 3 \t Validation precision@k20: 0.6198, accuracy@k20: 0.6161\n",
      "Epoch: 3 \t Validation precision@k25: 0.6896, accuracy@k25: 0.6893\n",
      "Epoch: 3 \t Validation precision@k30: 0.7386, accuracy@k30: 0.7386\n",
      "CPU: 13.09\n",
      "RAM %: 57.1\n",
      "Epoch: 4 \t Training Loss: 3.994640\n",
      "Epoch: 4 \t Validation precision@k5: 0.4976, accuracy@k5: 0.2447\n",
      "Epoch: 4 \t Validation precision@k10: 0.4609, accuracy@k10: 0.3810\n",
      "Epoch: 4 \t Validation precision@k15: 0.5427, accuracy@k15: 0.5216\n",
      "Epoch: 4 \t Validation precision@k20: 0.6268, accuracy@k20: 0.6231\n",
      "Epoch: 4 \t Validation precision@k25: 0.6786, accuracy@k25: 0.6783\n",
      "Epoch: 4 \t Validation precision@k30: 0.7298, accuracy@k30: 0.7298\n",
      "CPU: 13.12\n",
      "RAM %: 57.1\n",
      "Epoch: 5 \t Training Loss: 3.977498\n",
      "Epoch: 5 \t Validation precision@k5: 0.4542, accuracy@k5: 0.2193\n",
      "Epoch: 5 \t Validation precision@k10: 0.4311, accuracy@k10: 0.3551\n",
      "Epoch: 5 \t Validation precision@k15: 0.4992, accuracy@k15: 0.4798\n",
      "Epoch: 5 \t Validation precision@k20: 0.6056, accuracy@k20: 0.6021\n",
      "Epoch: 5 \t Validation precision@k25: 0.6716, accuracy@k25: 0.6714\n",
      "Epoch: 5 \t Validation precision@k30: 0.7375, accuracy@k30: 0.7375\n",
      "CPU: 13.36\n",
      "RAM %: 57.1\n",
      "Epoch: 6 \t Training Loss: 3.969002\n",
      "Epoch: 6 \t Validation precision@k5: 0.5351, accuracy@k5: 0.2665\n",
      "Epoch: 6 \t Validation precision@k10: 0.5074, accuracy@k10: 0.4238\n",
      "Epoch: 6 \t Validation precision@k15: 0.5487, accuracy@k15: 0.5287\n",
      "Epoch: 6 \t Validation precision@k20: 0.6066, accuracy@k20: 0.6032\n",
      "Epoch: 6 \t Validation precision@k25: 0.6752, accuracy@k25: 0.6750\n",
      "Epoch: 6 \t Validation precision@k30: 0.7305, accuracy@k30: 0.7305\n",
      "CPU: 13.42\n",
      "RAM %: 57.1\n",
      "Epoch: 7 \t Training Loss: 3.945020\n",
      "Epoch: 7 \t Validation precision@k5: 0.4424, accuracy@k5: 0.2246\n",
      "Epoch: 7 \t Validation precision@k10: 0.4621, accuracy@k10: 0.3855\n",
      "Epoch: 7 \t Validation precision@k15: 0.5406, accuracy@k15: 0.5202\n",
      "Epoch: 7 \t Validation precision@k20: 0.6340, accuracy@k20: 0.6303\n",
      "Epoch: 7 \t Validation precision@k25: 0.7060, accuracy@k25: 0.7057\n",
      "Epoch: 7 \t Validation precision@k30: 0.7556, accuracy@k30: 0.7556\n",
      "CPU: 13.45\n",
      "RAM %: 57.1\n",
      "Epoch: 8 \t Training Loss: 3.922978\n",
      "Epoch: 8 \t Validation precision@k5: 0.4863, accuracy@k5: 0.2455\n",
      "Epoch: 8 \t Validation precision@k10: 0.5095, accuracy@k10: 0.4263\n",
      "Epoch: 8 \t Validation precision@k15: 0.5501, accuracy@k15: 0.5298\n",
      "Epoch: 8 \t Validation precision@k20: 0.6231, accuracy@k20: 0.6194\n",
      "Epoch: 8 \t Validation precision@k25: 0.6922, accuracy@k25: 0.6919\n",
      "Epoch: 8 \t Validation precision@k30: 0.7515, accuracy@k30: 0.7515\n",
      "CPU: 13.47\n",
      "RAM %: 57.1\n",
      "Epoch: 9 \t Training Loss: 3.910943\n",
      "Epoch: 9 \t Validation precision@k5: 0.4820, accuracy@k5: 0.2424\n",
      "Epoch: 9 \t Validation precision@k10: 0.4886, accuracy@k10: 0.4060\n",
      "Epoch: 9 \t Validation precision@k15: 0.5318, accuracy@k15: 0.5123\n",
      "Epoch: 9 \t Validation precision@k20: 0.6020, accuracy@k20: 0.5987\n",
      "Epoch: 9 \t Validation precision@k25: 0.6755, accuracy@k25: 0.6753\n",
      "Epoch: 9 \t Validation precision@k30: 0.7457, accuracy@k30: 0.7457\n",
      "CPU: 13.47\n",
      "RAM %: 57.2\n",
      "Epoch: 10 \t Training Loss: 3.884910\n",
      "Epoch: 10 \t Validation precision@k5: 0.4978, accuracy@k5: 0.2483\n",
      "Epoch: 10 \t Validation precision@k10: 0.4998, accuracy@k10: 0.4163\n",
      "Epoch: 10 \t Validation precision@k15: 0.5515, accuracy@k15: 0.5307\n",
      "Epoch: 10 \t Validation precision@k20: 0.6246, accuracy@k20: 0.6209\n",
      "Epoch: 10 \t Validation precision@k25: 0.7003, accuracy@k25: 0.7001\n",
      "Epoch: 10 \t Validation precision@k30: 0.7606, accuracy@k30: 0.7606\n",
      "CPU: 13.57\n",
      "RAM %: 57.2\n",
      "Epoch: 11 \t Training Loss: 3.853425\n",
      "Epoch: 11 \t Validation precision@k5: 0.5086, accuracy@k5: 0.2599\n",
      "Epoch: 11 \t Validation precision@k10: 0.5159, accuracy@k10: 0.4311\n",
      "Epoch: 11 \t Validation precision@k15: 0.5602, accuracy@k15: 0.5395\n",
      "Epoch: 11 \t Validation precision@k20: 0.6290, accuracy@k20: 0.6253\n",
      "Epoch: 11 \t Validation precision@k25: 0.7043, accuracy@k25: 0.7040\n",
      "Epoch: 11 \t Validation precision@k30: 0.7623, accuracy@k30: 0.7623\n",
      "CPU: 13.55\n",
      "RAM %: 57.1\n",
      "Epoch: 12 \t Training Loss: 3.836039\n",
      "Epoch: 12 \t Validation precision@k5: 0.4842, accuracy@k5: 0.2434\n",
      "Epoch: 12 \t Validation precision@k10: 0.4913, accuracy@k10: 0.4092\n",
      "Epoch: 12 \t Validation precision@k15: 0.5718, accuracy@k15: 0.5506\n",
      "Epoch: 12 \t Validation precision@k20: 0.6492, accuracy@k20: 0.6455\n",
      "Epoch: 12 \t Validation precision@k25: 0.7147, accuracy@k25: 0.7145\n",
      "Epoch: 12 \t Validation precision@k30: 0.7698, accuracy@k30: 0.7698\n",
      "CPU: 13.64\n",
      "RAM %: 57.1\n",
      "Epoch: 13 \t Training Loss: 3.822931\n",
      "Epoch: 13 \t Validation precision@k5: 0.5074, accuracy@k5: 0.2611\n",
      "Epoch: 13 \t Validation precision@k10: 0.4828, accuracy@k10: 0.4071\n",
      "Epoch: 13 \t Validation precision@k15: 0.5344, accuracy@k15: 0.5158\n",
      "Epoch: 13 \t Validation precision@k20: 0.6134, accuracy@k20: 0.6101\n",
      "Epoch: 13 \t Validation precision@k25: 0.6804, accuracy@k25: 0.6801\n",
      "Epoch: 13 \t Validation precision@k30: 0.7445, accuracy@k30: 0.7445\n",
      "CPU: 13.77\n",
      "RAM %: 57.2\n",
      "Epoch: 14 \t Training Loss: 3.801541\n",
      "Epoch: 14 \t Validation precision@k5: 0.5911, accuracy@k5: 0.3015\n",
      "Epoch: 14 \t Validation precision@k10: 0.5482, accuracy@k10: 0.4587\n",
      "Epoch: 14 \t Validation precision@k15: 0.5855, accuracy@k15: 0.5642\n",
      "Epoch: 14 \t Validation precision@k20: 0.6486, accuracy@k20: 0.6449\n",
      "Epoch: 14 \t Validation precision@k25: 0.7150, accuracy@k25: 0.7147\n",
      "Epoch: 14 \t Validation precision@k30: 0.7680, accuracy@k30: 0.7680\n",
      "CPU: 13.94\n",
      "RAM %: 57.2\n",
      "Epoch: 15 \t Training Loss: 3.779504\n",
      "Epoch: 15 \t Validation precision@k5: 0.5528, accuracy@k5: 0.2817\n",
      "Epoch: 15 \t Validation precision@k10: 0.5395, accuracy@k10: 0.4511\n",
      "Epoch: 15 \t Validation precision@k15: 0.5878, accuracy@k15: 0.5664\n",
      "Epoch: 15 \t Validation precision@k20: 0.6553, accuracy@k20: 0.6517\n",
      "Epoch: 15 \t Validation precision@k25: 0.7100, accuracy@k25: 0.7097\n",
      "Epoch: 15 \t Validation precision@k30: 0.7616, accuracy@k30: 0.7616\n",
      "CPU: 14.32\n",
      "RAM %: 57.2\n",
      "Epoch: 16 \t Training Loss: 3.767793\n",
      "Epoch: 16 \t Validation precision@k5: 0.5203, accuracy@k5: 0.2686\n",
      "Epoch: 16 \t Validation precision@k10: 0.5287, accuracy@k10: 0.4454\n",
      "Epoch: 16 \t Validation precision@k15: 0.5795, accuracy@k15: 0.5589\n",
      "Epoch: 16 \t Validation precision@k20: 0.6539, accuracy@k20: 0.6503\n",
      "Epoch: 16 \t Validation precision@k25: 0.7252, accuracy@k25: 0.7249\n",
      "Epoch: 16 \t Validation precision@k30: 0.7785, accuracy@k30: 0.7785\n",
      "CPU: 14.48\n",
      "RAM %: 57.2\n",
      "Epoch: 17 \t Training Loss: 3.749829\n",
      "Epoch: 17 \t Validation precision@k5: 0.5745, accuracy@k5: 0.2936\n",
      "Epoch: 17 \t Validation precision@k10: 0.5565, accuracy@k10: 0.4666\n",
      "Epoch: 17 \t Validation precision@k15: 0.5954, accuracy@k15: 0.5741\n",
      "Epoch: 17 \t Validation precision@k20: 0.6535, accuracy@k20: 0.6499\n",
      "Epoch: 17 \t Validation precision@k25: 0.7111, accuracy@k25: 0.7108\n",
      "Epoch: 17 \t Validation precision@k30: 0.7635, accuracy@k30: 0.7635\n",
      "CPU: 14.53\n",
      "RAM %: 57.2\n",
      "Epoch: 18 \t Training Loss: 3.735592\n",
      "Epoch: 18 \t Validation precision@k5: 0.5914, accuracy@k5: 0.3035\n",
      "Epoch: 18 \t Validation precision@k10: 0.5488, accuracy@k10: 0.4605\n",
      "Epoch: 18 \t Validation precision@k15: 0.5895, accuracy@k15: 0.5683\n",
      "Epoch: 18 \t Validation precision@k20: 0.6639, accuracy@k20: 0.6601\n",
      "Epoch: 18 \t Validation precision@k25: 0.7259, accuracy@k25: 0.7257\n",
      "Epoch: 18 \t Validation precision@k30: 0.7782, accuracy@k30: 0.7782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 14.69\n",
      "RAM %: 57.1\n",
      "Epoch: 19 \t Training Loss: 3.725864\n",
      "Epoch: 19 \t Validation precision@k5: 0.5816, accuracy@k5: 0.2935\n",
      "Epoch: 19 \t Validation precision@k10: 0.5431, accuracy@k10: 0.4542\n",
      "Epoch: 19 \t Validation precision@k15: 0.5923, accuracy@k15: 0.5711\n",
      "Epoch: 19 \t Validation precision@k20: 0.6649, accuracy@k20: 0.6610\n",
      "Epoch: 19 \t Validation precision@k25: 0.7299, accuracy@k25: 0.7296\n",
      "Epoch: 19 \t Validation precision@k30: 0.7853, accuracy@k30: 0.7853\n",
      "CPU: 14.87\n",
      "RAM %: 57.4\n",
      "Epoch: 20 \t Training Loss: 3.709797\n",
      "Epoch: 20 \t Validation precision@k5: 0.5887, accuracy@k5: 0.3034\n",
      "Epoch: 20 \t Validation precision@k10: 0.5664, accuracy@k10: 0.4768\n",
      "Epoch: 20 \t Validation precision@k15: 0.6095, accuracy@k15: 0.5880\n",
      "Epoch: 20 \t Validation precision@k20: 0.6714, accuracy@k20: 0.6677\n",
      "Epoch: 20 \t Validation precision@k25: 0.7323, accuracy@k25: 0.7321\n",
      "Epoch: 20 \t Validation precision@k30: 0.7811, accuracy@k30: 0.7811\n",
      "CPU: 14.86\n",
      "RAM %: 57.4\n",
      "Epoch: 21 \t Training Loss: 3.695081\n",
      "Epoch: 21 \t Validation precision@k5: 0.6391, accuracy@k5: 0.3260\n",
      "Epoch: 21 \t Validation precision@k10: 0.5648, accuracy@k10: 0.4742\n",
      "Epoch: 21 \t Validation precision@k15: 0.6047, accuracy@k15: 0.5833\n",
      "Epoch: 21 \t Validation precision@k20: 0.6745, accuracy@k20: 0.6708\n",
      "Epoch: 21 \t Validation precision@k25: 0.7396, accuracy@k25: 0.7393\n",
      "Epoch: 21 \t Validation precision@k30: 0.7895, accuracy@k30: 0.7895\n",
      "CPU: 14.90\n",
      "RAM %: 57.4\n",
      "Epoch: 22 \t Training Loss: 3.678978\n",
      "Epoch: 22 \t Validation precision@k5: 0.6259, accuracy@k5: 0.3206\n",
      "Epoch: 22 \t Validation precision@k10: 0.5796, accuracy@k10: 0.4860\n",
      "Epoch: 22 \t Validation precision@k15: 0.6185, accuracy@k15: 0.5965\n",
      "Epoch: 22 \t Validation precision@k20: 0.6765, accuracy@k20: 0.6729\n",
      "Epoch: 22 \t Validation precision@k25: 0.7352, accuracy@k25: 0.7349\n",
      "Epoch: 22 \t Validation precision@k30: 0.7866, accuracy@k30: 0.7866\n",
      "CPU: 14.94\n",
      "RAM %: 57.4\n",
      "Epoch: 23 \t Training Loss: 3.668623\n",
      "Epoch: 23 \t Validation precision@k5: 0.5935, accuracy@k5: 0.3073\n",
      "Epoch: 23 \t Validation precision@k10: 0.5690, accuracy@k10: 0.4794\n",
      "Epoch: 23 \t Validation precision@k15: 0.6192, accuracy@k15: 0.5974\n",
      "Epoch: 23 \t Validation precision@k20: 0.6865, accuracy@k20: 0.6827\n",
      "Epoch: 23 \t Validation precision@k25: 0.7492, accuracy@k25: 0.7490\n",
      "Epoch: 23 \t Validation precision@k30: 0.7970, accuracy@k30: 0.7970\n",
      "CPU: 15.06\n",
      "RAM %: 57.4\n",
      "Epoch: 24 \t Training Loss: 3.655559\n",
      "Epoch: 24 \t Validation precision@k5: 0.6421, accuracy@k5: 0.3305\n",
      "Epoch: 24 \t Validation precision@k10: 0.5890, accuracy@k10: 0.4953\n",
      "Epoch: 24 \t Validation precision@k15: 0.6200, accuracy@k15: 0.5982\n",
      "Epoch: 24 \t Validation precision@k20: 0.6788, accuracy@k20: 0.6752\n",
      "Epoch: 24 \t Validation precision@k25: 0.7375, accuracy@k25: 0.7372\n",
      "Epoch: 24 \t Validation precision@k30: 0.7869, accuracy@k30: 0.7869\n",
      "CPU: 15.10\n",
      "RAM %: 57.4\n",
      "Epoch: 25 \t Training Loss: 3.639125\n",
      "Epoch: 25 \t Validation precision@k5: 0.6508, accuracy@k5: 0.3339\n",
      "Epoch: 25 \t Validation precision@k10: 0.5928, accuracy@k10: 0.4986\n",
      "Epoch: 25 \t Validation precision@k15: 0.6239, accuracy@k15: 0.6019\n",
      "Epoch: 25 \t Validation precision@k20: 0.6800, accuracy@k20: 0.6764\n",
      "Epoch: 25 \t Validation precision@k25: 0.7380, accuracy@k25: 0.7377\n",
      "Epoch: 25 \t Validation precision@k30: 0.7925, accuracy@k30: 0.7925\n",
      "CPU: 15.08\n",
      "RAM %: 57.4\n",
      "Epoch: 26 \t Training Loss: 3.632350\n",
      "Epoch: 26 \t Validation precision@k5: 0.6304, accuracy@k5: 0.3267\n",
      "Epoch: 26 \t Validation precision@k10: 0.5888, accuracy@k10: 0.4966\n",
      "Epoch: 26 \t Validation precision@k15: 0.6289, accuracy@k15: 0.6069\n",
      "Epoch: 26 \t Validation precision@k20: 0.6935, accuracy@k20: 0.6897\n",
      "Epoch: 26 \t Validation precision@k25: 0.7504, accuracy@k25: 0.7501\n",
      "Epoch: 26 \t Validation precision@k30: 0.7991, accuracy@k30: 0.7991\n",
      "CPU: 15.16\n",
      "RAM %: 57.3\n",
      "Epoch: 27 \t Training Loss: 3.621510\n",
      "Epoch: 27 \t Validation precision@k5: 0.6503, accuracy@k5: 0.3346\n",
      "Epoch: 27 \t Validation precision@k10: 0.6040, accuracy@k10: 0.5083\n",
      "Epoch: 27 \t Validation precision@k15: 0.6363, accuracy@k15: 0.6140\n",
      "Epoch: 27 \t Validation precision@k20: 0.6984, accuracy@k20: 0.6946\n",
      "Epoch: 27 \t Validation precision@k25: 0.7563, accuracy@k25: 0.7561\n",
      "Epoch: 27 \t Validation precision@k30: 0.8029, accuracy@k30: 0.8029\n",
      "CPU: 15.20\n",
      "RAM %: 57.3\n",
      "Epoch: 28 \t Training Loss: 3.610301\n",
      "Epoch: 28 \t Validation precision@k5: 0.6462, accuracy@k5: 0.3324\n",
      "Epoch: 28 \t Validation precision@k10: 0.6123, accuracy@k10: 0.5139\n",
      "Epoch: 28 \t Validation precision@k15: 0.6464, accuracy@k15: 0.6233\n",
      "Epoch: 28 \t Validation precision@k20: 0.7077, accuracy@k20: 0.7038\n",
      "Epoch: 28 \t Validation precision@k25: 0.7665, accuracy@k25: 0.7662\n",
      "Epoch: 28 \t Validation precision@k30: 0.8137, accuracy@k30: 0.8137\n",
      "CPU: 15.20\n",
      "RAM %: 57.3\n",
      "Epoch: 29 \t Training Loss: 3.602704\n",
      "Epoch: 29 \t Validation precision@k5: 0.6477, accuracy@k5: 0.3332\n",
      "Epoch: 29 \t Validation precision@k10: 0.6053, accuracy@k10: 0.5080\n",
      "Epoch: 29 \t Validation precision@k15: 0.6394, accuracy@k15: 0.6166\n",
      "Epoch: 29 \t Validation precision@k20: 0.7020, accuracy@k20: 0.6981\n",
      "Epoch: 29 \t Validation precision@k25: 0.7624, accuracy@k25: 0.7622\n",
      "Epoch: 29 \t Validation precision@k30: 0.8060, accuracy@k30: 0.8060\n",
      "CPU: 15.31\n",
      "RAM %: 57.4\n",
      "Epoch: 30 \t Training Loss: 3.591778\n",
      "Epoch: 30 \t Validation precision@k5: 0.6480, accuracy@k5: 0.3318\n",
      "Epoch: 30 \t Validation precision@k10: 0.6084, accuracy@k10: 0.5103\n",
      "Epoch: 30 \t Validation precision@k15: 0.6492, accuracy@k15: 0.6262\n",
      "Epoch: 30 \t Validation precision@k20: 0.7091, accuracy@k20: 0.7054\n",
      "Epoch: 30 \t Validation precision@k25: 0.7618, accuracy@k25: 0.7615\n",
      "Epoch: 30 \t Validation precision@k30: 0.8039, accuracy@k30: 0.8039\n",
      "CPU: 15.29\n",
      "RAM %: 57.4\n",
      "Epoch: 31 \t Training Loss: 3.580282\n",
      "Epoch: 31 \t Validation precision@k5: 0.6719, accuracy@k5: 0.3433\n",
      "Epoch: 31 \t Validation precision@k10: 0.6166, accuracy@k10: 0.5187\n",
      "Epoch: 31 \t Validation precision@k15: 0.6518, accuracy@k15: 0.6291\n",
      "Epoch: 31 \t Validation precision@k20: 0.7130, accuracy@k20: 0.7092\n",
      "Epoch: 31 \t Validation precision@k25: 0.7649, accuracy@k25: 0.7646\n",
      "Epoch: 31 \t Validation precision@k30: 0.8085, accuracy@k30: 0.8085\n",
      "CPU: 15.47\n",
      "RAM %: 57.4\n",
      "Epoch: 32 \t Training Loss: 3.572400\n",
      "Epoch: 32 \t Validation precision@k5: 0.6584, accuracy@k5: 0.3376\n",
      "Epoch: 32 \t Validation precision@k10: 0.6187, accuracy@k10: 0.5198\n",
      "Epoch: 32 \t Validation precision@k15: 0.6564, accuracy@k15: 0.6330\n",
      "Epoch: 32 \t Validation precision@k20: 0.7180, accuracy@k20: 0.7141\n",
      "Epoch: 32 \t Validation precision@k25: 0.7734, accuracy@k25: 0.7732\n",
      "Epoch: 32 \t Validation precision@k30: 0.8178, accuracy@k30: 0.8178\n",
      "CPU: 15.40\n",
      "RAM %: 57.4\n",
      "Epoch: 33 \t Training Loss: 3.566055\n",
      "Epoch: 33 \t Validation precision@k5: 0.6721, accuracy@k5: 0.3447\n",
      "Epoch: 33 \t Validation precision@k10: 0.6271, accuracy@k10: 0.5263\n",
      "Epoch: 33 \t Validation precision@k15: 0.6591, accuracy@k15: 0.6355\n",
      "Epoch: 33 \t Validation precision@k20: 0.7182, accuracy@k20: 0.7143\n",
      "Epoch: 33 \t Validation precision@k25: 0.7739, accuracy@k25: 0.7736\n",
      "Epoch: 33 \t Validation precision@k30: 0.8211, accuracy@k30: 0.8211\n",
      "CPU: 15.36\n",
      "RAM %: 57.3\n",
      "Epoch: 34 \t Training Loss: 3.557617\n",
      "Epoch: 34 \t Validation precision@k5: 0.6656, accuracy@k5: 0.3412\n",
      "Epoch: 34 \t Validation precision@k10: 0.6291, accuracy@k10: 0.5276\n",
      "Epoch: 34 \t Validation precision@k15: 0.6653, accuracy@k15: 0.6412\n",
      "Epoch: 34 \t Validation precision@k20: 0.7226, accuracy@k20: 0.7186\n",
      "Epoch: 34 \t Validation precision@k25: 0.7769, accuracy@k25: 0.7767\n",
      "Epoch: 34 \t Validation precision@k30: 0.8154, accuracy@k30: 0.8154\n",
      "CPU: 15.51\n",
      "RAM %: 57.3\n",
      "Epoch: 35 \t Training Loss: 3.546864\n",
      "Epoch: 35 \t Validation precision@k5: 0.6718, accuracy@k5: 0.3444\n",
      "Epoch: 35 \t Validation precision@k10: 0.6261, accuracy@k10: 0.5256\n",
      "Epoch: 35 \t Validation precision@k15: 0.6582, accuracy@k15: 0.6346\n",
      "Epoch: 35 \t Validation precision@k20: 0.7167, accuracy@k20: 0.7127\n",
      "Epoch: 35 \t Validation precision@k25: 0.7740, accuracy@k25: 0.7737\n",
      "Epoch: 35 \t Validation precision@k30: 0.8197, accuracy@k30: 0.8197\n",
      "CPU: 15.95\n",
      "RAM %: 57.3\n",
      "Epoch: 36 \t Training Loss: 3.542049\n",
      "Epoch: 36 \t Validation precision@k5: 0.6745, accuracy@k5: 0.3451\n",
      "Epoch: 36 \t Validation precision@k10: 0.6281, accuracy@k10: 0.5271\n",
      "Epoch: 36 \t Validation precision@k15: 0.6632, accuracy@k15: 0.6395\n",
      "Epoch: 36 \t Validation precision@k20: 0.7218, accuracy@k20: 0.7178\n",
      "Epoch: 36 \t Validation precision@k25: 0.7765, accuracy@k25: 0.7762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 \t Validation precision@k30: 0.8194, accuracy@k30: 0.8194\n",
      "CPU: 16.00\n",
      "RAM %: 52.6\n",
      "Epoch: 37 \t Training Loss: 3.537119\n",
      "Epoch: 37 \t Validation precision@k5: 0.6896, accuracy@k5: 0.3543\n",
      "Epoch: 37 \t Validation precision@k10: 0.6381, accuracy@k10: 0.5353\n",
      "Epoch: 37 \t Validation precision@k15: 0.6674, accuracy@k15: 0.6433\n",
      "Epoch: 37 \t Validation precision@k20: 0.7254, accuracy@k20: 0.7214\n",
      "Epoch: 37 \t Validation precision@k25: 0.7795, accuracy@k25: 0.7792\n",
      "Epoch: 37 \t Validation precision@k30: 0.8211, accuracy@k30: 0.8211\n",
      "CPU: 16.03\n",
      "RAM %: 52.7\n",
      "Epoch: 38 \t Training Loss: 3.529459\n",
      "Epoch: 38 \t Validation precision@k5: 0.6891, accuracy@k5: 0.3530\n",
      "Epoch: 38 \t Validation precision@k10: 0.6396, accuracy@k10: 0.5368\n",
      "Epoch: 38 \t Validation precision@k15: 0.6690, accuracy@k15: 0.6451\n",
      "Epoch: 38 \t Validation precision@k20: 0.7244, accuracy@k20: 0.7205\n",
      "Epoch: 38 \t Validation precision@k25: 0.7772, accuracy@k25: 0.7769\n",
      "Epoch: 38 \t Validation precision@k30: 0.8185, accuracy@k30: 0.8185\n",
      "CPU: 16.09\n",
      "RAM %: 52.8\n",
      "Epoch: 39 \t Training Loss: 3.524217\n",
      "Epoch: 39 \t Validation precision@k5: 0.6889, accuracy@k5: 0.3527\n",
      "Epoch: 39 \t Validation precision@k10: 0.6442, accuracy@k10: 0.5401\n",
      "Epoch: 39 \t Validation precision@k15: 0.6729, accuracy@k15: 0.6485\n",
      "Epoch: 39 \t Validation precision@k20: 0.7317, accuracy@k20: 0.7276\n",
      "Epoch: 39 \t Validation precision@k25: 0.7820, accuracy@k25: 0.7817\n",
      "Epoch: 39 \t Validation precision@k30: 0.8216, accuracy@k30: 0.8216\n",
      "CPU: 16.09\n",
      "RAM %: 53.2\n",
      "Epoch: 40 \t Training Loss: 3.519308\n",
      "Epoch: 40 \t Validation precision@k5: 0.6934, accuracy@k5: 0.3559\n",
      "Epoch: 40 \t Validation precision@k10: 0.6421, accuracy@k10: 0.5381\n",
      "Epoch: 40 \t Validation precision@k15: 0.6720, accuracy@k15: 0.6477\n",
      "Epoch: 40 \t Validation precision@k20: 0.7320, accuracy@k20: 0.7279\n",
      "Epoch: 40 \t Validation precision@k25: 0.7823, accuracy@k25: 0.7820\n",
      "Epoch: 40 \t Validation precision@k30: 0.8250, accuracy@k30: 0.8250\n",
      "CPU: 16.12\n",
      "RAM %: 53.0\n",
      "Epoch: 41 \t Training Loss: 3.513130\n",
      "Epoch: 41 \t Validation precision@k5: 0.6849, accuracy@k5: 0.3509\n",
      "Epoch: 41 \t Validation precision@k10: 0.6413, accuracy@k10: 0.5377\n",
      "Epoch: 41 \t Validation precision@k15: 0.6734, accuracy@k15: 0.6491\n",
      "Epoch: 41 \t Validation precision@k20: 0.7309, accuracy@k20: 0.7269\n",
      "Epoch: 41 \t Validation precision@k25: 0.7817, accuracy@k25: 0.7814\n",
      "Epoch: 41 \t Validation precision@k30: 0.8216, accuracy@k30: 0.8216\n",
      "CPU: 16.10\n",
      "RAM %: 53.1\n",
      "Epoch: 42 \t Training Loss: 3.510401\n",
      "Epoch: 42 \t Validation precision@k5: 0.6940, accuracy@k5: 0.3557\n",
      "Epoch: 42 \t Validation precision@k10: 0.6502, accuracy@k10: 0.5443\n",
      "Epoch: 42 \t Validation precision@k15: 0.6764, accuracy@k15: 0.6517\n",
      "Epoch: 42 \t Validation precision@k20: 0.7318, accuracy@k20: 0.7276\n",
      "Epoch: 42 \t Validation precision@k25: 0.7829, accuracy@k25: 0.7826\n",
      "Epoch: 42 \t Validation precision@k30: 0.8261, accuracy@k30: 0.8261\n",
      "CPU: 16.53\n",
      "RAM %: 53.1\n",
      "Epoch: 43 \t Training Loss: 3.505414\n",
      "Epoch: 43 \t Validation precision@k5: 0.6923, accuracy@k5: 0.3544\n",
      "Epoch: 43 \t Validation precision@k10: 0.6450, accuracy@k10: 0.5401\n",
      "Epoch: 43 \t Validation precision@k15: 0.6759, accuracy@k15: 0.6512\n",
      "Epoch: 43 \t Validation precision@k20: 0.7326, accuracy@k20: 0.7285\n",
      "Epoch: 43 \t Validation precision@k25: 0.7838, accuracy@k25: 0.7835\n",
      "Epoch: 43 \t Validation precision@k30: 0.8239, accuracy@k30: 0.8239\n",
      "CPU: 16.66\n",
      "RAM %: 53.1\n",
      "Epoch: 44 \t Training Loss: 3.500804\n",
      "Epoch: 44 \t Validation precision@k5: 0.7085, accuracy@k5: 0.3631\n",
      "Epoch: 44 \t Validation precision@k10: 0.6519, accuracy@k10: 0.5453\n",
      "Epoch: 44 \t Validation precision@k15: 0.6796, accuracy@k15: 0.6544\n",
      "Epoch: 44 \t Validation precision@k20: 0.7298, accuracy@k20: 0.7257\n",
      "Epoch: 44 \t Validation precision@k25: 0.7854, accuracy@k25: 0.7852\n",
      "Epoch: 44 \t Validation precision@k30: 0.8260, accuracy@k30: 0.8260\n",
      "CPU: 16.76\n",
      "RAM %: 53.1\n",
      "Epoch: 45 \t Training Loss: 3.497542\n",
      "Epoch: 45 \t Validation precision@k5: 0.7022, accuracy@k5: 0.3601\n",
      "Epoch: 45 \t Validation precision@k10: 0.6517, accuracy@k10: 0.5459\n",
      "Epoch: 45 \t Validation precision@k15: 0.6805, accuracy@k15: 0.6558\n",
      "Epoch: 45 \t Validation precision@k20: 0.7351, accuracy@k20: 0.7310\n",
      "Epoch: 45 \t Validation precision@k25: 0.7845, accuracy@k25: 0.7842\n",
      "Epoch: 45 \t Validation precision@k30: 0.8243, accuracy@k30: 0.8243\n",
      "CPU: 16.78\n",
      "RAM %: 53.1\n",
      "Epoch: 46 \t Training Loss: 3.495373\n",
      "Epoch: 46 \t Validation precision@k5: 0.7071, accuracy@k5: 0.3629\n",
      "Epoch: 46 \t Validation precision@k10: 0.6475, accuracy@k10: 0.5418\n",
      "Epoch: 46 \t Validation precision@k15: 0.6781, accuracy@k15: 0.6533\n",
      "Epoch: 46 \t Validation precision@k20: 0.7324, accuracy@k20: 0.7283\n",
      "Epoch: 46 \t Validation precision@k25: 0.7879, accuracy@k25: 0.7876\n",
      "Epoch: 46 \t Validation precision@k30: 0.8271, accuracy@k30: 0.8271\n",
      "CPU: 16.78\n",
      "RAM %: 53.1\n",
      "Epoch: 47 \t Training Loss: 3.493980\n",
      "Epoch: 47 \t Validation precision@k5: 0.7025, accuracy@k5: 0.3603\n",
      "Epoch: 47 \t Validation precision@k10: 0.6529, accuracy@k10: 0.5463\n",
      "Epoch: 47 \t Validation precision@k15: 0.6809, accuracy@k15: 0.6556\n",
      "Epoch: 47 \t Validation precision@k20: 0.7341, accuracy@k20: 0.7300\n",
      "Epoch: 47 \t Validation precision@k25: 0.7875, accuracy@k25: 0.7872\n",
      "Epoch: 47 \t Validation precision@k30: 0.8274, accuracy@k30: 0.8274\n",
      "CPU: 16.73\n",
      "RAM %: 53.1\n",
      "Epoch: 48 \t Training Loss: 3.490352\n",
      "Epoch: 48 \t Validation precision@k5: 0.6978, accuracy@k5: 0.3569\n",
      "Epoch: 48 \t Validation precision@k10: 0.6514, accuracy@k10: 0.5455\n",
      "Epoch: 48 \t Validation precision@k15: 0.6795, accuracy@k15: 0.6545\n",
      "Epoch: 48 \t Validation precision@k20: 0.7335, accuracy@k20: 0.7293\n",
      "Epoch: 48 \t Validation precision@k25: 0.7867, accuracy@k25: 0.7864\n",
      "Epoch: 48 \t Validation precision@k30: 0.8291, accuracy@k30: 0.8291\n",
      "CPU: 16.93\n",
      "RAM %: 53.2\n",
      "Epoch: 49 \t Training Loss: 3.488741\n",
      "Epoch: 49 \t Validation precision@k5: 0.7046, accuracy@k5: 0.3598\n",
      "Epoch: 49 \t Validation precision@k10: 0.6547, accuracy@k10: 0.5473\n",
      "Epoch: 49 \t Validation precision@k15: 0.6822, accuracy@k15: 0.6566\n",
      "Epoch: 49 \t Validation precision@k20: 0.7381, accuracy@k20: 0.7339\n",
      "Epoch: 49 \t Validation precision@k25: 0.7888, accuracy@k25: 0.7886\n",
      "Epoch: 49 \t Validation precision@k30: 0.8275, accuracy@k30: 0.8275\n",
      "CPU: 17.10\n",
      "RAM %: 53.3\n",
      "Epoch: 50 \t Training Loss: 3.486879\n",
      "Epoch: 50 \t Validation precision@k5: 0.7075, accuracy@k5: 0.3621\n",
      "Epoch: 50 \t Validation precision@k10: 0.6567, accuracy@k10: 0.5495\n",
      "Epoch: 50 \t Validation precision@k15: 0.6831, accuracy@k15: 0.6578\n",
      "Epoch: 50 \t Validation precision@k20: 0.7356, accuracy@k20: 0.7315\n",
      "Epoch: 50 \t Validation precision@k25: 0.7858, accuracy@k25: 0.7855\n",
      "Epoch: 50 \t Validation precision@k30: 0.8269, accuracy@k30: 0.8269\n",
      "CPU: 17.04\n",
      "RAM %: 53.2\n",
      "Epoch: 51 \t Training Loss: 3.484203\n",
      "Epoch: 51 \t Validation precision@k5: 0.7011, accuracy@k5: 0.3595\n",
      "Epoch: 51 \t Validation precision@k10: 0.6512, accuracy@k10: 0.5449\n",
      "Epoch: 51 \t Validation precision@k15: 0.6806, accuracy@k15: 0.6554\n",
      "Epoch: 51 \t Validation precision@k20: 0.7339, accuracy@k20: 0.7298\n",
      "Epoch: 51 \t Validation precision@k25: 0.7867, accuracy@k25: 0.7864\n",
      "Epoch: 51 \t Validation precision@k30: 0.8277, accuracy@k30: 0.8277\n",
      "CPU: 17.13\n",
      "RAM %: 53.3\n",
      "Epoch: 52 \t Training Loss: 3.482633\n",
      "Epoch: 52 \t Validation precision@k5: 0.6988, accuracy@k5: 0.3568\n",
      "Epoch: 52 \t Validation precision@k10: 0.6542, accuracy@k10: 0.5472\n",
      "Epoch: 52 \t Validation precision@k15: 0.6831, accuracy@k15: 0.6578\n",
      "Epoch: 52 \t Validation precision@k20: 0.7355, accuracy@k20: 0.7313\n",
      "Epoch: 52 \t Validation precision@k25: 0.7880, accuracy@k25: 0.7878\n",
      "Epoch: 52 \t Validation precision@k30: 0.8284, accuracy@k30: 0.8284\n",
      "CPU: 17.14\n",
      "RAM %: 53.3\n",
      "Epoch: 53 \t Training Loss: 3.482151\n",
      "Epoch: 53 \t Validation precision@k5: 0.7043, accuracy@k5: 0.3602\n",
      "Epoch: 53 \t Validation precision@k10: 0.6562, accuracy@k10: 0.5489\n",
      "Epoch: 53 \t Validation precision@k15: 0.6888, accuracy@k15: 0.6635\n",
      "Epoch: 53 \t Validation precision@k20: 0.7395, accuracy@k20: 0.7353\n",
      "Epoch: 53 \t Validation precision@k25: 0.7885, accuracy@k25: 0.7882\n",
      "Epoch: 53 \t Validation precision@k30: 0.8291, accuracy@k30: 0.8291\n",
      "CPU: 17.05\n",
      "RAM %: 53.4\n",
      "Epoch: 54 \t Training Loss: 3.479610\n",
      "Epoch: 54 \t Validation precision@k5: 0.7095, accuracy@k5: 0.3621\n",
      "Epoch: 54 \t Validation precision@k10: 0.6574, accuracy@k10: 0.5496\n",
      "Epoch: 54 \t Validation precision@k15: 0.6836, accuracy@k15: 0.6583\n",
      "Epoch: 54 \t Validation precision@k20: 0.7360, accuracy@k20: 0.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 \t Validation precision@k25: 0.7884, accuracy@k25: 0.7882\n",
      "Epoch: 54 \t Validation precision@k30: 0.8287, accuracy@k30: 0.8287\n",
      "CPU: 17.18\n",
      "RAM %: 53.5\n",
      "Epoch: 55 \t Training Loss: 3.477466\n",
      "Epoch: 55 \t Validation precision@k5: 0.7064, accuracy@k5: 0.3602\n",
      "Epoch: 55 \t Validation precision@k10: 0.6543, accuracy@k10: 0.5470\n",
      "Epoch: 55 \t Validation precision@k15: 0.6818, accuracy@k15: 0.6565\n",
      "Epoch: 55 \t Validation precision@k20: 0.7354, accuracy@k20: 0.7312\n",
      "Epoch: 55 \t Validation precision@k25: 0.7866, accuracy@k25: 0.7863\n",
      "Epoch: 55 \t Validation precision@k30: 0.8294, accuracy@k30: 0.8294\n",
      "CPU: 17.16\n",
      "RAM %: 53.5\n",
      "Epoch: 56 \t Training Loss: 3.477667\n",
      "Epoch: 56 \t Validation precision@k5: 0.7014, accuracy@k5: 0.3583\n",
      "Epoch: 56 \t Validation precision@k10: 0.6560, accuracy@k10: 0.5481\n",
      "Epoch: 56 \t Validation precision@k15: 0.6823, accuracy@k15: 0.6570\n",
      "Epoch: 56 \t Validation precision@k20: 0.7363, accuracy@k20: 0.7321\n",
      "Epoch: 56 \t Validation precision@k25: 0.7878, accuracy@k25: 0.7876\n",
      "Epoch: 56 \t Validation precision@k30: 0.8281, accuracy@k30: 0.8281\n",
      "CPU: 17.07\n",
      "RAM %: 53.6\n",
      "Epoch: 57 \t Training Loss: 3.477746\n",
      "Epoch: 57 \t Validation precision@k5: 0.7099, accuracy@k5: 0.3625\n",
      "Epoch: 57 \t Validation precision@k10: 0.6601, accuracy@k10: 0.5515\n",
      "Epoch: 57 \t Validation precision@k15: 0.6842, accuracy@k15: 0.6584\n",
      "Epoch: 57 \t Validation precision@k20: 0.7356, accuracy@k20: 0.7313\n",
      "Epoch: 57 \t Validation precision@k25: 0.7868, accuracy@k25: 0.7865\n",
      "Epoch: 57 \t Validation precision@k30: 0.8276, accuracy@k30: 0.8276\n",
      "CPU: 17.27\n",
      "RAM %: 53.6\n",
      "Epoch: 58 \t Training Loss: 3.475709\n",
      "Epoch: 58 \t Validation precision@k5: 0.7057, accuracy@k5: 0.3601\n",
      "Epoch: 58 \t Validation precision@k10: 0.6588, accuracy@k10: 0.5507\n",
      "Epoch: 58 \t Validation precision@k15: 0.6832, accuracy@k15: 0.6580\n",
      "Epoch: 58 \t Validation precision@k20: 0.7393, accuracy@k20: 0.7351\n",
      "Epoch: 58 \t Validation precision@k25: 0.7889, accuracy@k25: 0.7887\n",
      "Epoch: 58 \t Validation precision@k30: 0.8292, accuracy@k30: 0.8292\n",
      "CPU: 17.43\n",
      "RAM %: 53.7\n",
      "Epoch: 59 \t Training Loss: 3.474860\n",
      "Epoch: 59 \t Validation precision@k5: 0.7119, accuracy@k5: 0.3633\n",
      "Epoch: 59 \t Validation precision@k10: 0.6612, accuracy@k10: 0.5528\n",
      "Epoch: 59 \t Validation precision@k15: 0.6868, accuracy@k15: 0.6610\n",
      "Epoch: 59 \t Validation precision@k20: 0.7382, accuracy@k20: 0.7339\n",
      "Epoch: 59 \t Validation precision@k25: 0.7896, accuracy@k25: 0.7893\n",
      "Epoch: 59 \t Validation precision@k30: 0.8299, accuracy@k30: 0.8299\n",
      "CPU: 17.40\n",
      "RAM %: 53.7\n",
      "Epoch: 60 \t Training Loss: 3.474672\n",
      "Epoch: 60 \t Validation precision@k5: 0.7045, accuracy@k5: 0.3593\n",
      "Epoch: 60 \t Validation precision@k10: 0.6568, accuracy@k10: 0.5489\n",
      "Epoch: 60 \t Validation precision@k15: 0.6813, accuracy@k15: 0.6559\n",
      "Epoch: 60 \t Validation precision@k20: 0.7356, accuracy@k20: 0.7314\n",
      "Epoch: 60 \t Validation precision@k25: 0.7889, accuracy@k25: 0.7886\n",
      "Epoch: 60 \t Validation precision@k30: 0.8301, accuracy@k30: 0.8301\n",
      "CPU: 17.41\n",
      "RAM %: 53.7\n",
      "Epoch: 61 \t Training Loss: 3.475082\n",
      "Epoch: 61 \t Validation precision@k5: 0.7086, accuracy@k5: 0.3625\n",
      "Epoch: 61 \t Validation precision@k10: 0.6608, accuracy@k10: 0.5524\n",
      "Epoch: 61 \t Validation precision@k15: 0.6877, accuracy@k15: 0.6623\n",
      "Epoch: 61 \t Validation precision@k20: 0.7388, accuracy@k20: 0.7346\n",
      "Epoch: 61 \t Validation precision@k25: 0.7900, accuracy@k25: 0.7898\n",
      "Epoch: 61 \t Validation precision@k30: 0.8294, accuracy@k30: 0.8294\n",
      "CPU: 17.57\n",
      "RAM %: 53.8\n",
      "Epoch: 62 \t Training Loss: 3.472079\n",
      "Epoch: 62 \t Validation precision@k5: 0.7004, accuracy@k5: 0.3578\n",
      "Epoch: 62 \t Validation precision@k10: 0.6588, accuracy@k10: 0.5507\n",
      "Epoch: 62 \t Validation precision@k15: 0.6841, accuracy@k15: 0.6587\n",
      "Epoch: 62 \t Validation precision@k20: 0.7356, accuracy@k20: 0.7313\n",
      "Epoch: 62 \t Validation precision@k25: 0.7891, accuracy@k25: 0.7888\n",
      "Epoch: 62 \t Validation precision@k30: 0.8271, accuracy@k30: 0.8271\n",
      "CPU: 17.69\n",
      "RAM %: 53.7\n",
      "Epoch: 63 \t Training Loss: 3.473171\n",
      "Epoch: 63 \t Validation precision@k5: 0.7096, accuracy@k5: 0.3622\n",
      "Epoch: 63 \t Validation precision@k10: 0.6598, accuracy@k10: 0.5514\n",
      "Epoch: 63 \t Validation precision@k15: 0.6873, accuracy@k15: 0.6617\n",
      "Epoch: 63 \t Validation precision@k20: 0.7382, accuracy@k20: 0.7340\n",
      "Epoch: 63 \t Validation precision@k25: 0.7885, accuracy@k25: 0.7882\n",
      "Epoch: 63 \t Validation precision@k30: 0.8285, accuracy@k30: 0.8285\n",
      "CPU: 17.77\n",
      "RAM %: 53.7\n",
      "Epoch: 64 \t Training Loss: 3.472764\n",
      "Epoch: 64 \t Validation precision@k5: 0.7033, accuracy@k5: 0.3595\n",
      "Epoch: 64 \t Validation precision@k10: 0.6583, accuracy@k10: 0.5506\n",
      "Epoch: 64 \t Validation precision@k15: 0.6828, accuracy@k15: 0.6573\n",
      "Epoch: 64 \t Validation precision@k20: 0.7374, accuracy@k20: 0.7331\n",
      "Epoch: 64 \t Validation precision@k25: 0.7900, accuracy@k25: 0.7897\n",
      "Epoch: 64 \t Validation precision@k30: 0.8290, accuracy@k30: 0.8290\n",
      "CPU: 17.74\n",
      "RAM %: 53.7\n",
      "Epoch: 65 \t Training Loss: 3.471647\n",
      "Epoch: 65 \t Validation precision@k5: 0.7032, accuracy@k5: 0.3587\n",
      "Epoch: 65 \t Validation precision@k10: 0.6553, accuracy@k10: 0.5477\n",
      "Epoch: 65 \t Validation precision@k15: 0.6851, accuracy@k15: 0.6596\n",
      "Epoch: 65 \t Validation precision@k20: 0.7378, accuracy@k20: 0.7335\n",
      "Epoch: 65 \t Validation precision@k25: 0.7912, accuracy@k25: 0.7909\n",
      "Epoch: 65 \t Validation precision@k30: 0.8282, accuracy@k30: 0.8282\n",
      "CPU: 17.75\n",
      "RAM %: 53.8\n",
      "Epoch: 66 \t Training Loss: 3.471025\n",
      "Epoch: 66 \t Validation precision@k5: 0.7003, accuracy@k5: 0.3573\n",
      "Epoch: 66 \t Validation precision@k10: 0.6594, accuracy@k10: 0.5510\n",
      "Epoch: 66 \t Validation precision@k15: 0.6876, accuracy@k15: 0.6619\n",
      "Epoch: 66 \t Validation precision@k20: 0.7407, accuracy@k20: 0.7364\n",
      "Epoch: 66 \t Validation precision@k25: 0.7901, accuracy@k25: 0.7898\n",
      "Epoch: 66 \t Validation precision@k30: 0.8306, accuracy@k30: 0.8306\n",
      "CPU: 17.75\n",
      "RAM %: 54.1\n",
      "Epoch: 67 \t Training Loss: 3.471626\n",
      "Epoch: 67 \t Validation precision@k5: 0.6980, accuracy@k5: 0.3555\n",
      "Epoch: 67 \t Validation precision@k10: 0.6557, accuracy@k10: 0.5488\n",
      "Epoch: 67 \t Validation precision@k15: 0.6858, accuracy@k15: 0.6602\n",
      "Epoch: 67 \t Validation precision@k20: 0.7402, accuracy@k20: 0.7359\n",
      "Epoch: 67 \t Validation precision@k25: 0.7890, accuracy@k25: 0.7887\n",
      "Epoch: 67 \t Validation precision@k30: 0.8297, accuracy@k30: 0.8297\n",
      "CPU: 17.98\n",
      "RAM %: 55.5\n",
      "Epoch: 68 \t Training Loss: 3.470224\n",
      "Epoch: 68 \t Validation precision@k5: 0.7066, accuracy@k5: 0.3602\n",
      "Epoch: 68 \t Validation precision@k10: 0.6556, accuracy@k10: 0.5479\n",
      "Epoch: 68 \t Validation precision@k15: 0.6834, accuracy@k15: 0.6578\n",
      "Epoch: 68 \t Validation precision@k20: 0.7377, accuracy@k20: 0.7334\n",
      "Epoch: 68 \t Validation precision@k25: 0.7882, accuracy@k25: 0.7879\n",
      "Epoch: 68 \t Validation precision@k30: 0.8293, accuracy@k30: 0.8293\n",
      "CPU: 17.91\n",
      "RAM %: 53.3\n",
      "Epoch: 69 \t Training Loss: 3.469879\n",
      "Epoch: 69 \t Validation precision@k5: 0.7072, accuracy@k5: 0.3608\n",
      "Epoch: 69 \t Validation precision@k10: 0.6601, accuracy@k10: 0.5518\n",
      "Epoch: 69 \t Validation precision@k15: 0.6854, accuracy@k15: 0.6598\n",
      "Epoch: 69 \t Validation precision@k20: 0.7363, accuracy@k20: 0.7321\n",
      "Epoch: 69 \t Validation precision@k25: 0.7879, accuracy@k25: 0.7876\n",
      "Epoch: 69 \t Validation precision@k30: 0.8288, accuracy@k30: 0.8288\n",
      "CPU: 18.03\n",
      "RAM %: 53.2\n",
      "Epoch: 70 \t Training Loss: 3.470091\n",
      "Epoch: 70 \t Validation precision@k5: 0.7075, accuracy@k5: 0.3612\n",
      "Epoch: 70 \t Validation precision@k10: 0.6588, accuracy@k10: 0.5507\n",
      "Epoch: 70 \t Validation precision@k15: 0.6839, accuracy@k15: 0.6582\n",
      "Epoch: 70 \t Validation precision@k20: 0.7379, accuracy@k20: 0.7336\n",
      "Epoch: 70 \t Validation precision@k25: 0.7899, accuracy@k25: 0.7896\n",
      "Epoch: 70 \t Validation precision@k30: 0.8294, accuracy@k30: 0.8294\n",
      "CPU: 17.99\n",
      "RAM %: 53.2\n",
      "Epoch: 71 \t Training Loss: 3.469741\n",
      "Epoch: 71 \t Validation precision@k5: 0.7084, accuracy@k5: 0.3614\n",
      "Epoch: 71 \t Validation precision@k10: 0.6569, accuracy@k10: 0.5490\n",
      "Epoch: 71 \t Validation precision@k15: 0.6862, accuracy@k15: 0.6606\n",
      "Epoch: 71 \t Validation precision@k20: 0.7386, accuracy@k20: 0.7343\n",
      "Epoch: 71 \t Validation precision@k25: 0.7896, accuracy@k25: 0.7893\n",
      "Epoch: 71 \t Validation precision@k30: 0.8298, accuracy@k30: 0.8298\n",
      "CPU: 17.93\n",
      "RAM %: 53.2\n",
      "Epoch: 72 \t Training Loss: 3.469419\n",
      "Epoch: 72 \t Validation precision@k5: 0.7018, accuracy@k5: 0.3579\n",
      "Epoch: 72 \t Validation precision@k10: 0.6584, accuracy@k10: 0.5505\n",
      "Epoch: 72 \t Validation precision@k15: 0.6849, accuracy@k15: 0.6593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 \t Validation precision@k20: 0.7403, accuracy@k20: 0.7361\n",
      "Epoch: 72 \t Validation precision@k25: 0.7896, accuracy@k25: 0.7894\n",
      "Epoch: 72 \t Validation precision@k30: 0.8288, accuracy@k30: 0.8288\n",
      "CPU: 18.12\n",
      "RAM %: 53.3\n",
      "Epoch: 73 \t Training Loss: 3.469834\n",
      "Epoch: 73 \t Validation precision@k5: 0.7026, accuracy@k5: 0.3580\n",
      "Epoch: 73 \t Validation precision@k10: 0.6574, accuracy@k10: 0.5497\n",
      "Epoch: 73 \t Validation precision@k15: 0.6858, accuracy@k15: 0.6601\n",
      "Epoch: 73 \t Validation precision@k20: 0.7382, accuracy@k20: 0.7339\n",
      "Epoch: 73 \t Validation precision@k25: 0.7910, accuracy@k25: 0.7907\n",
      "Epoch: 73 \t Validation precision@k30: 0.8312, accuracy@k30: 0.8312\n",
      "CPU: 18.23\n",
      "RAM %: 53.4\n",
      "Epoch: 74 \t Training Loss: 3.469497\n",
      "Epoch: 74 \t Validation precision@k5: 0.7077, accuracy@k5: 0.3606\n",
      "Epoch: 74 \t Validation precision@k10: 0.6592, accuracy@k10: 0.5508\n",
      "Epoch: 74 \t Validation precision@k15: 0.6852, accuracy@k15: 0.6597\n",
      "Epoch: 74 \t Validation precision@k20: 0.7371, accuracy@k20: 0.7328\n",
      "Epoch: 74 \t Validation precision@k25: 0.7900, accuracy@k25: 0.7898\n",
      "Epoch: 74 \t Validation precision@k30: 0.8295, accuracy@k30: 0.8295\n",
      "CPU: 18.41\n",
      "RAM %: 53.5\n",
      "Epoch: 75 \t Training Loss: 3.467982\n",
      "Epoch: 75 \t Validation precision@k5: 0.7043, accuracy@k5: 0.3591\n",
      "Epoch: 75 \t Validation precision@k10: 0.6567, accuracy@k10: 0.5488\n",
      "Epoch: 75 \t Validation precision@k15: 0.6836, accuracy@k15: 0.6578\n",
      "Epoch: 75 \t Validation precision@k20: 0.7364, accuracy@k20: 0.7321\n",
      "Epoch: 75 \t Validation precision@k25: 0.7899, accuracy@k25: 0.7896\n",
      "Epoch: 75 \t Validation precision@k30: 0.8299, accuracy@k30: 0.8299\n",
      "CPU: 18.38\n",
      "RAM %: 53.5\n",
      "Epoch: 76 \t Training Loss: 3.469065\n",
      "Epoch: 76 \t Validation precision@k5: 0.7063, accuracy@k5: 0.3598\n",
      "Epoch: 76 \t Validation precision@k10: 0.6594, accuracy@k10: 0.5509\n",
      "Epoch: 76 \t Validation precision@k15: 0.6865, accuracy@k15: 0.6607\n",
      "Epoch: 76 \t Validation precision@k20: 0.7383, accuracy@k20: 0.7340\n",
      "Epoch: 76 \t Validation precision@k25: 0.7882, accuracy@k25: 0.7879\n",
      "Epoch: 76 \t Validation precision@k30: 0.8297, accuracy@k30: 0.8297\n",
      "CPU: 18.63\n",
      "RAM %: 53.6\n",
      "Epoch: 77 \t Training Loss: 3.469073\n",
      "Epoch: 77 \t Validation precision@k5: 0.7053, accuracy@k5: 0.3589\n",
      "Epoch: 77 \t Validation precision@k10: 0.6599, accuracy@k10: 0.5512\n",
      "Epoch: 77 \t Validation precision@k15: 0.6885, accuracy@k15: 0.6626\n",
      "Epoch: 77 \t Validation precision@k20: 0.7404, accuracy@k20: 0.7361\n",
      "Epoch: 77 \t Validation precision@k25: 0.7901, accuracy@k25: 0.7898\n",
      "Epoch: 77 \t Validation precision@k30: 0.8309, accuracy@k30: 0.8309\n",
      "CPU: 18.56\n",
      "RAM %: 53.6\n",
      "Epoch: 78 \t Training Loss: 3.469990\n",
      "Epoch: 78 \t Validation precision@k5: 0.7089, accuracy@k5: 0.3623\n",
      "Epoch: 78 \t Validation precision@k10: 0.6618, accuracy@k10: 0.5538\n",
      "Epoch: 78 \t Validation precision@k15: 0.6864, accuracy@k15: 0.6609\n",
      "Epoch: 78 \t Validation precision@k20: 0.7371, accuracy@k20: 0.7328\n",
      "Epoch: 78 \t Validation precision@k25: 0.7893, accuracy@k25: 0.7890\n",
      "Epoch: 78 \t Validation precision@k30: 0.8286, accuracy@k30: 0.8286\n",
      "CPU: 18.52\n",
      "RAM %: 53.6\n",
      "Epoch: 79 \t Training Loss: 3.467927\n",
      "Epoch: 79 \t Validation precision@k5: 0.7066, accuracy@k5: 0.3602\n",
      "Epoch: 79 \t Validation precision@k10: 0.6601, accuracy@k10: 0.5520\n",
      "Epoch: 79 \t Validation precision@k15: 0.6866, accuracy@k15: 0.6611\n",
      "Epoch: 79 \t Validation precision@k20: 0.7388, accuracy@k20: 0.7345\n",
      "Epoch: 79 \t Validation precision@k25: 0.7884, accuracy@k25: 0.7881\n",
      "Epoch: 79 \t Validation precision@k30: 0.8290, accuracy@k30: 0.8290\n",
      "CPU: 18.60\n",
      "RAM %: 53.6\n",
      "Epoch: 80 \t Training Loss: 3.467468\n",
      "Epoch: 80 \t Validation precision@k5: 0.7049, accuracy@k5: 0.3593\n",
      "Epoch: 80 \t Validation precision@k10: 0.6584, accuracy@k10: 0.5500\n",
      "Epoch: 80 \t Validation precision@k15: 0.6892, accuracy@k15: 0.6637\n",
      "Epoch: 80 \t Validation precision@k20: 0.7397, accuracy@k20: 0.7354\n",
      "Epoch: 80 \t Validation precision@k25: 0.7905, accuracy@k25: 0.7902\n",
      "Epoch: 80 \t Validation precision@k30: 0.8284, accuracy@k30: 0.8284\n",
      "CPU: 18.74\n",
      "RAM %: 53.7\n",
      "Epoch: 81 \t Training Loss: 3.467494\n",
      "Epoch: 81 \t Validation precision@k5: 0.7019, accuracy@k5: 0.3575\n",
      "Epoch: 81 \t Validation precision@k10: 0.6555, accuracy@k10: 0.5475\n",
      "Epoch: 81 \t Validation precision@k15: 0.6846, accuracy@k15: 0.6589\n",
      "Epoch: 81 \t Validation precision@k20: 0.7387, accuracy@k20: 0.7344\n",
      "Epoch: 81 \t Validation precision@k25: 0.7893, accuracy@k25: 0.7890\n",
      "Epoch: 81 \t Validation precision@k30: 0.8284, accuracy@k30: 0.8284\n",
      "CPU: 18.74\n",
      "RAM %: 53.7\n",
      "Epoch: 82 \t Training Loss: 3.466186\n",
      "Epoch: 82 \t Validation precision@k5: 0.7054, accuracy@k5: 0.3602\n",
      "Epoch: 82 \t Validation precision@k10: 0.6596, accuracy@k10: 0.5509\n",
      "Epoch: 82 \t Validation precision@k15: 0.6860, accuracy@k15: 0.6603\n",
      "Epoch: 82 \t Validation precision@k20: 0.7377, accuracy@k20: 0.7334\n",
      "Epoch: 82 \t Validation precision@k25: 0.7880, accuracy@k25: 0.7877\n",
      "Epoch: 82 \t Validation precision@k30: 0.8291, accuracy@k30: 0.8291\n",
      "CPU: 18.74\n",
      "RAM %: 53.8\n",
      "Epoch: 83 \t Training Loss: 3.464746\n",
      "Epoch: 83 \t Validation precision@k5: 0.7038, accuracy@k5: 0.3586\n",
      "Epoch: 83 \t Validation precision@k10: 0.6592, accuracy@k10: 0.5510\n",
      "Epoch: 83 \t Validation precision@k15: 0.6864, accuracy@k15: 0.6606\n",
      "Epoch: 83 \t Validation precision@k20: 0.7388, accuracy@k20: 0.7345\n",
      "Epoch: 83 \t Validation precision@k25: 0.7885, accuracy@k25: 0.7882\n",
      "Epoch: 83 \t Validation precision@k30: 0.8278, accuracy@k30: 0.8278\n",
      "CPU: 18.85\n",
      "RAM %: 53.8\n",
      "Epoch: 84 \t Training Loss: 3.466595\n",
      "Epoch: 84 \t Validation precision@k5: 0.7041, accuracy@k5: 0.3590\n",
      "Epoch: 84 \t Validation precision@k10: 0.6603, accuracy@k10: 0.5522\n",
      "Epoch: 84 \t Validation precision@k15: 0.6877, accuracy@k15: 0.6620\n",
      "Epoch: 84 \t Validation precision@k20: 0.7393, accuracy@k20: 0.7350\n",
      "Epoch: 84 \t Validation precision@k25: 0.7896, accuracy@k25: 0.7893\n",
      "Epoch: 84 \t Validation precision@k30: 0.8289, accuracy@k30: 0.8289\n",
      "CPU: 18.99\n",
      "RAM %: 53.7\n",
      "Epoch: 85 \t Training Loss: 3.466466\n",
      "Epoch: 85 \t Validation precision@k5: 0.7044, accuracy@k5: 0.3601\n",
      "Epoch: 85 \t Validation precision@k10: 0.6591, accuracy@k10: 0.5511\n",
      "Epoch: 85 \t Validation precision@k15: 0.6852, accuracy@k15: 0.6594\n",
      "Epoch: 85 \t Validation precision@k20: 0.7402, accuracy@k20: 0.7359\n",
      "Epoch: 85 \t Validation precision@k25: 0.7893, accuracy@k25: 0.7891\n",
      "Epoch: 85 \t Validation precision@k30: 0.8285, accuracy@k30: 0.8285\n",
      "CPU: 18.95\n",
      "RAM %: 53.7\n",
      "Epoch: 86 \t Training Loss: 3.464932\n",
      "Epoch: 86 \t Validation precision@k5: 0.7054, accuracy@k5: 0.3593\n",
      "Epoch: 86 \t Validation precision@k10: 0.6610, accuracy@k10: 0.5524\n",
      "Epoch: 86 \t Validation precision@k15: 0.6852, accuracy@k15: 0.6595\n",
      "Epoch: 86 \t Validation precision@k20: 0.7370, accuracy@k20: 0.7327\n",
      "Epoch: 86 \t Validation precision@k25: 0.7898, accuracy@k25: 0.7895\n",
      "Epoch: 86 \t Validation precision@k30: 0.8290, accuracy@k30: 0.8290\n",
      "CPU: 19.02\n",
      "RAM %: 53.7\n",
      "Epoch: 87 \t Training Loss: 3.466170\n",
      "Epoch: 87 \t Validation precision@k5: 0.7043, accuracy@k5: 0.3584\n",
      "Epoch: 87 \t Validation precision@k10: 0.6595, accuracy@k10: 0.5512\n",
      "Epoch: 87 \t Validation precision@k15: 0.6881, accuracy@k15: 0.6622\n",
      "Epoch: 87 \t Validation precision@k20: 0.7395, accuracy@k20: 0.7353\n",
      "Epoch: 87 \t Validation precision@k25: 0.7901, accuracy@k25: 0.7898\n",
      "Epoch: 87 \t Validation precision@k30: 0.8313, accuracy@k30: 0.8313\n",
      "CPU: 19.12\n",
      "RAM %: 53.7\n",
      "Epoch: 88 \t Training Loss: 3.464219\n",
      "Epoch: 88 \t Validation precision@k5: 0.7003, accuracy@k5: 0.3564\n",
      "Epoch: 88 \t Validation precision@k10: 0.6565, accuracy@k10: 0.5487\n",
      "Epoch: 88 \t Validation precision@k15: 0.6874, accuracy@k15: 0.6617\n",
      "Epoch: 88 \t Validation precision@k20: 0.7395, accuracy@k20: 0.7352\n",
      "Epoch: 88 \t Validation precision@k25: 0.7908, accuracy@k25: 0.7905\n",
      "Epoch: 88 \t Validation precision@k30: 0.8282, accuracy@k30: 0.8282\n",
      "CPU: 19.04\n",
      "RAM %: 53.7\n",
      "Epoch: 89 \t Training Loss: 3.466421\n",
      "Epoch: 89 \t Validation precision@k5: 0.7064, accuracy@k5: 0.3602\n",
      "Epoch: 89 \t Validation precision@k10: 0.6586, accuracy@k10: 0.5508\n",
      "Epoch: 89 \t Validation precision@k15: 0.6868, accuracy@k15: 0.6610\n",
      "Epoch: 89 \t Validation precision@k20: 0.7408, accuracy@k20: 0.7364\n",
      "Epoch: 89 \t Validation precision@k25: 0.7903, accuracy@k25: 0.7900\n",
      "Epoch: 89 \t Validation precision@k30: 0.8301, accuracy@k30: 0.8301\n",
      "CPU: 19.04\n",
      "RAM %: 53.8\n",
      "Epoch: 90 \t Training Loss: 3.466221\n",
      "Epoch: 90 \t Validation precision@k5: 0.7115, accuracy@k5: 0.3626\n",
      "Epoch: 90 \t Validation precision@k10: 0.6615, accuracy@k10: 0.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 \t Validation precision@k15: 0.6882, accuracy@k15: 0.6623\n",
      "Epoch: 90 \t Validation precision@k20: 0.7389, accuracy@k20: 0.7346\n",
      "Epoch: 90 \t Validation precision@k25: 0.7882, accuracy@k25: 0.7879\n",
      "Epoch: 90 \t Validation precision@k30: 0.8285, accuracy@k30: 0.8285\n",
      "CPU: 19.03\n",
      "RAM %: 53.9\n",
      "Epoch: 91 \t Training Loss: 3.466563\n",
      "Epoch: 91 \t Validation precision@k5: 0.7053, accuracy@k5: 0.3602\n",
      "Epoch: 91 \t Validation precision@k10: 0.6586, accuracy@k10: 0.5505\n",
      "Epoch: 91 \t Validation precision@k15: 0.6851, accuracy@k15: 0.6594\n",
      "Epoch: 91 \t Validation precision@k20: 0.7371, accuracy@k20: 0.7328\n",
      "Epoch: 91 \t Validation precision@k25: 0.7893, accuracy@k25: 0.7891\n",
      "Epoch: 91 \t Validation precision@k30: 0.8289, accuracy@k30: 0.8289\n",
      "CPU: 19.17\n",
      "RAM %: 54.0\n",
      "Epoch: 92 \t Training Loss: 3.465803\n",
      "Epoch: 92 \t Validation precision@k5: 0.7014, accuracy@k5: 0.3578\n",
      "Epoch: 92 \t Validation precision@k10: 0.6573, accuracy@k10: 0.5496\n",
      "Epoch: 92 \t Validation precision@k15: 0.6886, accuracy@k15: 0.6629\n",
      "Epoch: 92 \t Validation precision@k20: 0.7402, accuracy@k20: 0.7358\n",
      "Epoch: 92 \t Validation precision@k25: 0.7893, accuracy@k25: 0.7890\n",
      "Epoch: 92 \t Validation precision@k30: 0.8279, accuracy@k30: 0.8279\n",
      "CPU: 19.17\n",
      "RAM %: 54.0\n",
      "Epoch: 93 \t Training Loss: 3.465585\n",
      "Epoch: 93 \t Validation precision@k5: 0.7076, accuracy@k5: 0.3605\n",
      "Epoch: 93 \t Validation precision@k10: 0.6581, accuracy@k10: 0.5495\n",
      "Epoch: 93 \t Validation precision@k15: 0.6844, accuracy@k15: 0.6587\n",
      "Epoch: 93 \t Validation precision@k20: 0.7376, accuracy@k20: 0.7333\n",
      "Epoch: 93 \t Validation precision@k25: 0.7881, accuracy@k25: 0.7879\n",
      "Epoch: 93 \t Validation precision@k30: 0.8281, accuracy@k30: 0.8281\n",
      "CPU: 19.24\n",
      "RAM %: 54.1\n",
      "Epoch: 94 \t Training Loss: 3.464254\n",
      "Epoch: 94 \t Validation precision@k5: 0.7055, accuracy@k5: 0.3596\n",
      "Epoch: 94 \t Validation precision@k10: 0.6569, accuracy@k10: 0.5493\n",
      "Epoch: 94 \t Validation precision@k15: 0.6853, accuracy@k15: 0.6596\n",
      "Epoch: 94 \t Validation precision@k20: 0.7371, accuracy@k20: 0.7328\n",
      "Epoch: 94 \t Validation precision@k25: 0.7896, accuracy@k25: 0.7893\n",
      "Epoch: 94 \t Validation precision@k30: 0.8293, accuracy@k30: 0.8293\n",
      "CPU: 19.12\n",
      "RAM %: 54.1\n",
      "Epoch: 95 \t Training Loss: 3.465077\n",
      "Epoch: 95 \t Validation precision@k5: 0.7037, accuracy@k5: 0.3591\n",
      "Epoch: 95 \t Validation precision@k10: 0.6574, accuracy@k10: 0.5496\n",
      "Epoch: 95 \t Validation precision@k15: 0.6810, accuracy@k15: 0.6555\n",
      "Epoch: 95 \t Validation precision@k20: 0.7346, accuracy@k20: 0.7303\n",
      "Epoch: 95 \t Validation precision@k25: 0.7891, accuracy@k25: 0.7888\n",
      "Epoch: 95 \t Validation precision@k30: 0.8301, accuracy@k30: 0.8301\n",
      "CPU: 19.19\n",
      "RAM %: 54.1\n",
      "Epoch: 96 \t Training Loss: 3.465019\n",
      "Epoch: 96 \t Validation precision@k5: 0.7039, accuracy@k5: 0.3588\n",
      "Epoch: 96 \t Validation precision@k10: 0.6588, accuracy@k10: 0.5504\n",
      "Epoch: 96 \t Validation precision@k15: 0.6877, accuracy@k15: 0.6622\n",
      "Epoch: 96 \t Validation precision@k20: 0.7389, accuracy@k20: 0.7346\n",
      "Epoch: 96 \t Validation precision@k25: 0.7907, accuracy@k25: 0.7904\n",
      "Epoch: 96 \t Validation precision@k30: 0.8291, accuracy@k30: 0.8291\n",
      "CPU: 19.18\n",
      "RAM %: 54.2\n",
      "Epoch: 97 \t Training Loss: 3.465083\n",
      "Epoch: 97 \t Validation precision@k5: 0.7063, accuracy@k5: 0.3608\n",
      "Epoch: 97 \t Validation precision@k10: 0.6602, accuracy@k10: 0.5517\n",
      "Epoch: 97 \t Validation precision@k15: 0.6859, accuracy@k15: 0.6603\n",
      "Epoch: 97 \t Validation precision@k20: 0.7400, accuracy@k20: 0.7357\n",
      "Epoch: 97 \t Validation precision@k25: 0.7895, accuracy@k25: 0.7892\n",
      "Epoch: 97 \t Validation precision@k30: 0.8283, accuracy@k30: 0.8283\n",
      "CPU: 19.14\n",
      "RAM %: 54.1\n",
      "Epoch: 98 \t Training Loss: 3.464117\n",
      "Epoch: 98 \t Validation precision@k5: 0.7026, accuracy@k5: 0.3587\n",
      "Epoch: 98 \t Validation precision@k10: 0.6580, accuracy@k10: 0.5498\n",
      "Epoch: 98 \t Validation precision@k15: 0.6854, accuracy@k15: 0.6597\n",
      "Epoch: 98 \t Validation precision@k20: 0.7372, accuracy@k20: 0.7329\n",
      "Epoch: 98 \t Validation precision@k25: 0.7897, accuracy@k25: 0.7895\n",
      "Epoch: 98 \t Validation precision@k30: 0.8284, accuracy@k30: 0.8284\n",
      "CPU: 19.06\n",
      "RAM %: 54.2\n",
      "Epoch: 99 \t Training Loss: 3.464674\n",
      "Epoch: 99 \t Validation precision@k5: 0.7001, accuracy@k5: 0.3563\n",
      "Epoch: 99 \t Validation precision@k10: 0.6582, accuracy@k10: 0.5498\n",
      "Epoch: 99 \t Validation precision@k15: 0.6861, accuracy@k15: 0.6602\n",
      "Epoch: 99 \t Validation precision@k20: 0.7397, accuracy@k20: 0.7354\n",
      "Epoch: 99 \t Validation precision@k25: 0.7898, accuracy@k25: 0.7896\n",
      "Epoch: 99 \t Validation precision@k30: 0.8299, accuracy@k30: 0.8299\n",
      "CPU: 19.17\n",
      "RAM %: 54.2\n",
      "Epoch: 100 \t Training Loss: 3.464371\n",
      "Epoch: 100 \t Validation precision@k5: 0.7084, accuracy@k5: 0.3608\n",
      "Epoch: 100 \t Validation precision@k10: 0.6593, accuracy@k10: 0.5503\n",
      "Epoch: 100 \t Validation precision@k15: 0.6878, accuracy@k15: 0.6621\n",
      "Epoch: 100 \t Validation precision@k20: 0.7388, accuracy@k20: 0.7346\n",
      "Epoch: 100 \t Validation precision@k25: 0.7892, accuracy@k25: 0.7890\n",
      "Epoch: 100 \t Validation precision@k30: 0.8277, accuracy@k30: 0.8277\n",
      "CPU: 19.09\n",
      "RAM %: 54.2\n",
      "Max CPU usage: 19.235\tMax RAM % usage: 57.4\n",
      "CPU times: user 16min 47s, sys: 6min 3s, total: 22min 51s\n",
      "Wall time: 15min 8s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = \n",
    "%time train(enhanced_mlp, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d43a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation precision@k5: 0.7004, accuracy@k5: 0.3605\n",
      "Validation precision@k10: 0.6480, accuracy@k10: 0.5432\n",
      "Validation precision@k15: 0.6779, accuracy@k15: 0.6532\n",
      "Validation precision@k20: 0.7303, accuracy@k20: 0.7263\n",
      "Validation precision@k25: 0.7817, accuracy@k25: 0.7815\n",
      "Validation precision@k30: 0.8252, accuracy@k30: 0.8252\n"
     ]
    }
   ],
   "source": [
    "for k in range(5, 31, 5):\n",
    "    precision_k, accuracy_k = eval_model(enhanced_mlp, test_loader, k=k)\n",
    "    print(f'Validation precision@k{k}: {precision_k:.4f}, accuracy@k{k}: {accuracy_k:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a02c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enhanced_mlp, os.path.join(CHECKPOINT_PATH, \"EnhancedMLP_100.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13592e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4h",
   "language": "python",
   "name": "dl4h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
